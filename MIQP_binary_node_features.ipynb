{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install gurobipy\n",
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader  # Corrected import\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.nn import global_mean_pool  # For pooling in the decoder\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import random\n",
    "import matplotlib.pyplot as plt  # For plotting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_QP import my_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file QPLIB_0031.lp\n",
      "Reading time = 0.00 seconds\n",
      "obj: 32 rows, 60 columns, 120 nonzeros\n",
      "Set parameter MIPGap to value 0.01\n",
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (linux64 - \"Ubuntu 22.04.5 LTS\")\n",
      "\n",
      "CPU model: AMD EPYC 74F3 24-Core Processor, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 48 physical cores, 96 logical processors, using up to 32 threads\n",
      "\n",
      "Non-default parameters:\n",
      "MIPGap  0.01\n",
      "\n",
      "Optimize a model with 32 rows, 60 columns and 120 nonzeros\n",
      "Model fingerprint: 0x00d24133\n",
      "Model has 464 quadratic objective terms\n",
      "Variable types: 30 continuous, 30 integer (30 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  QObjective range [3e+01, 2e+04]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+00]\n",
      "Found heuristic solution: objective 3654.4800000\n",
      "Presolve time: 0.00s\n",
      "Presolved: 901 rows, 526 columns, 2321 nonzeros\n",
      "Presolved model has 30 quadratic constraint(s)\n",
      "Presolved model has 434 bilinear constraint(s)\n",
      "\n",
      "Solving non-convex MIQCP\n",
      "\n",
      "Variable types: 496 continuous, 30 integer (30 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 1 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                      31.9607000    0.00000   100%     -    0s\n",
      "*    0     0               0      31.9607000    0.00000   100%     -    0s\n",
      "H    0     0                      20.8607250    0.00000   100%     -    0s\n",
      "*    0     0               0      20.8607250    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0    2   20.86072    0.00000   100%     -    0s\n",
      "H    0     0                      18.2729563    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0    9   18.27296    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0    6   18.27296    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0    9   18.27296    0.00000   100%     -    0s\n",
      "H    0     0                      17.6415556    0.00000   100%     -    0s\n",
      "H    0     0                      17.4674945    0.00000   100%     -    0s\n",
      "H    0     0                      17.4402731    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0    6   17.44027    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0    6   17.44027    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0   10   17.44027    0.00000   100%     -    0s\n",
      "     0     0    0.08623    0  149   17.44027    0.08623   100%     -    0s\n",
      "     0     0    1.81173    0   10   17.44027    1.81173  89.6%     -    0s\n",
      "     0     0    1.81174    0   17   17.44027    1.81174  89.6%     -    0s\n",
      "     0     0    2.62598    0   33   17.44027    2.62598  84.9%     -    0s\n",
      "     0     0    3.56723    0   25   17.44027    3.56723  79.5%     -    0s\n",
      "     0     0    3.93799    0   10   17.44027    3.93799  77.4%     -    0s\n",
      "     0     0    4.38555    0   22   17.44027    4.38555  74.9%     -    0s\n",
      "     0     0    5.55565    0   22   17.44027    5.55565  68.1%     -    0s\n",
      "     0     0    7.15470    0   27   17.44027    7.15470  59.0%     -    0s\n",
      "     0     0    7.69619    0   20   17.44027    7.69619  55.9%     -    0s\n",
      "     0     0    7.73872    0   29   17.44027    7.73872  55.6%     -    0s\n",
      "     0     0    7.78685    0   29   17.44027    7.78685  55.4%     -    0s\n",
      "     0     0    7.79280    0   29   17.44027    7.79280  55.3%     -    0s\n",
      "     0     0    7.80101    0   29   17.44027    7.80101  55.3%     -    0s\n",
      "H    0     0                      16.3118000    7.80101  52.2%     -    0s\n",
      "     0     0    7.80101    0   29   16.31180    7.80101  52.2%     -    0s\n",
      "H    0     0                      16.2628544    7.80101  52.0%     -    0s\n",
      "H    0     0                      15.9880975    7.80101  51.2%     -    0s\n",
      "H    0     0                      15.7081129    7.80101  50.3%     -    0s\n",
      "     0     2    7.80101    0   29   15.70811    7.80101  50.3%     -    0s\n",
      "H 2033  1602                      15.6653635    8.60559  45.1%  12.3    0s\n",
      "H 2190  1602                      15.6644219    8.71024  44.4%  12.4    0s\n",
      "H 2280  1533                      15.5343914    8.74770  43.7%  12.4    0s\n",
      "H 2284  1442                      15.4851673    8.74770  43.5%  12.4    0s\n",
      "H 2286  1370                      15.4734961   11.00119  28.9%  12.4    0s\n",
      "H 2287  1303                      15.4657935   12.37306  20.0%  12.4    1s\n",
      "H 2301  1246                      15.4645115   14.66410  5.18%  12.3    3s\n",
      "H 2307  1187                      15.4637377   14.80641  4.25%  12.3    3s\n",
      "H 2307  1127                      15.4637351   14.80641  4.25%  12.3    3s\n",
      "H 2307  1070                      15.4637310   14.80641  4.25%  12.3    3s\n",
      "H 2307  1016                      15.4637310   14.80641  4.25%  12.3    3s\n",
      "  2314  1021   15.02181   10   17   15.46373   15.02181  2.86%  12.3    5s\n",
      "H 2317   971                      15.4635740   15.07409  2.52%  12.2    5s\n",
      "H 2317   922                      15.4631965   15.07409  2.52%  12.2    5s\n",
      "H 2321   878                      15.4601366   15.10487  2.30%  12.2    6s\n",
      "H 2321   834                      15.4597481   15.10487  2.30%  12.2    6s\n",
      "H 2321   791                      15.4595732   15.10487  2.29%  12.2    6s\n",
      "H 2321   751                      15.4593389   15.10487  2.29%  12.2    6s\n",
      "H 2321   713                      15.4592634   15.10487  2.29%  12.2    6s\n",
      "H 2321   676                      15.4592405   15.10487  2.29%  12.2    6s\n",
      "H 2338   653                      15.4547943   15.12569  2.13%  14.0    6s\n",
      "H 2338   620                      15.4515011   15.12569  2.11%  14.0    6s\n",
      "H 2338   589                      15.4511291   15.12569  2.11%  14.0    6s\n",
      "H 2340   561                      15.4417721   15.12569  2.05%  14.0    7s\n",
      "H 2340   532                      15.4399918   15.12569  2.04%  14.0    7s\n",
      "H 2340   506                      15.4399883   15.12569  2.04%  14.0    7s\n",
      "H 2340   480                      15.4399882   15.12569  2.04%  14.0    7s\n",
      "H 2340   456                      15.4399881   15.12569  2.04%  14.0    7s\n",
      "H 2340   433                      15.4399881   15.12569  2.04%  14.0    7s\n",
      "H 2340   411                      15.4397287   15.12569  2.03%  14.0    7s\n",
      "H 2340   391                      15.4396024   15.12569  2.03%  14.0    7s\n",
      "H 2340   371                      15.4395902   15.12569  2.03%  14.0    7s\n",
      "H 2340   352                      15.4395775   15.12569  2.03%  14.0    7s\n",
      "H 2340   335                      15.4395771   15.12569  2.03%  14.0    7s\n",
      "H 2340   318                      15.4395769   15.12569  2.03%  14.0    7s\n",
      "H 2340   302                      15.4394903   15.12569  2.03%  14.0    7s\n",
      "H 2340   287                      15.4394825   15.12569  2.03%  14.0    7s\n",
      "H 2340   272                      15.4394807   15.12569  2.03%  14.0    7s\n",
      "H 2340   258                      15.4394805   15.12569  2.03%  14.0    7s\n",
      "H 2340   245                      15.4394803   15.12569  2.03%  14.0    7s\n",
      "H 2340   233                      15.4393836   15.12569  2.03%  14.0    7s\n",
      "H 2340   221                      15.4393802   15.12569  2.03%  14.0    7s\n",
      "H 2340   210                      15.4393800   15.12569  2.03%  14.0    7s\n",
      "H 2346   203                      15.4393785   15.16849  1.75%  14.0    8s\n",
      "H 2355   198                      15.3902409   15.17832  1.38%  13.9    9s\n",
      "  2357   200   15.17832   19   17   15.39024   15.17832  1.38%  13.9   10s\n",
      "H 2362   194                      15.3868937   15.17832  1.36%  14.7   11s\n",
      "H 2364   185                      15.3868819   15.17832  1.36%  14.6   11s\n",
      "H 2368   179                      15.3865364   15.17832  1.35%  14.6   12s\n",
      "H 2368   170                      15.3865299   15.17832  1.35%  14.6   12s\n",
      "H 2368   161                      15.3865266   15.17832  1.35%  14.6   12s\n",
      "H 2368   153                      15.3864963   15.17832  1.35%  14.6   12s\n",
      "H 2368   145                      15.3864890   15.17832  1.35%  14.6   12s\n",
      "H 2368   138                      15.3864872   15.17832  1.35%  14.6   12s\n",
      "H 2368   131                      15.3864868   15.17832  1.35%  14.6   12s\n",
      "H 2368   124                      15.3864867   15.17832  1.35%  14.6   12s\n",
      "H 2373   121                      15.3864863   15.18129  1.33%  14.6   13s\n",
      "  2384   129   15.19918   21   17   15.38649   15.19918  1.22%  15.1   15s\n",
      "H 2388   125                      15.3864711   15.19918  1.22%  15.1   15s\n",
      "H 2396   125                      15.3864658   15.19918  1.22%  15.6   17s\n",
      "H 2398   120                      15.3864560   15.19918  1.22%  15.6   17s\n",
      "H 2398   113                      15.3864556   15.19918  1.22%  15.6   17s\n",
      "H 2398   108                      15.3864526   15.19918  1.22%  15.6   17s\n",
      "H 2398   102                      15.3864526   15.19918  1.22%  15.6   17s\n",
      "H 2399    98                      15.3864526   15.19918  1.22%  15.6   17s\n",
      "H 2415   104                      15.3864526   15.19918  1.22%  16.0   19s\n",
      "  2418   106   15.19918   20   17   15.38645   15.19918  1.22%  16.0   20s\n",
      "H 2463   132                      15.3864038   15.20098  1.21%  17.2   25s\n",
      "\n",
      "Cutting planes:\n",
      "  Flow cover: 4\n",
      "  RLT: 20\n",
      "  BQP: 4\n",
      "  PSD: 81\n",
      "\n",
      "Explored 2518 nodes (48210 simplex iterations) in 29.23 seconds (28.51 work units)\n",
      "Thread count was 32 (of 96 available processors)\n",
      "\n",
      "Solution count 10: 15.3864 15.3865 15.3865 ... 15.3865\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.538640382153e+01, best bound 1.524190878088e+01, gap 0.9391%\n",
      "\n",
      "User-callback calls 20170, time in user-callback 0.10 sec\n"
     ]
    }
   ],
   "source": [
    "# Read the problem\n",
    "number = \"0031\"\n",
    "grb_model = gp.read(f\"QPLIB_{number}.lp\")\n",
    "\n",
    "# Solution storage\n",
    "grb_model._feasible_solutions = []\n",
    "grb_model._relaxation_solutions = []\n",
    "grb_model.setParam(\"MIPGap\", 0.01)\n",
    "#model.setParam(\"NodeLimit\", 100)  # Explore a limited number of nodes\n",
    "\n",
    "# Optimize\n",
    "grb_model.optimize(my_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal solution: [0.0, 0.0, 0.5420392093302098, 0.0, 0.0, 0.09320745764617092, 0.0, 0.0, 0.0, 0.0, 0.1694989451487703, 0.13018713900818268, 0.0, 0.0, 0.06506724886666622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 1.0, 0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, 1.0, 1.0, -0.0, -0.0, 1.0, -0.0, -0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve optimal solution if available\n",
    "if grb_model.status == GRB.OPTIMAL:\n",
    "    optimal_solution = grb_model.getAttr('X', grb_model.getVars())\n",
    "    print(\"Optimal solution:\", optimal_solution)\n",
    "else:\n",
    "    print(f\"Model status: {grb_model.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a maximum finite bound for replacing infinities\n",
    "max_finite_bound = 1e5\n",
    "\n",
    "# Extract bounds and handle infinities\n",
    "variable_bounds = {}\n",
    "for var in grb_model.getVars():\n",
    "    lower_bound = var.LB\n",
    "    upper_bound = var.UB\n",
    "    \n",
    "    # Replace infinite bounds with finite values\n",
    "    if lower_bound == float('-inf'):\n",
    "        lower_bound = -max_finite_bound\n",
    "    if upper_bound == float('inf'):\n",
    "        upper_bound = max_finite_bound\n",
    "    \n",
    "    variable_bounds[var.VarName] = {'Lower': lower_bound, 'Upper': upper_bound}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting Q, A, b, d, etc\n",
    "\n",
    "from parse_QP import parse_qplib_file\n",
    "\n",
    "# Replace '0031' with the desired file number\n",
    "data = parse_qplib_file('0031')\n",
    "\n",
    "# Access the data\n",
    "A = data['A']\n",
    "b_vector = data['b_vector']\n",
    "E = data['E']\n",
    "d_vector = data['d']\n",
    "Q = data['Q']\n",
    "variables_info = data['variables_info']\n",
    "variables_info = [v[0] for v in variables_info]\n",
    "binary_indices = data['binary_indices']\n",
    "variable_indices = data['variable_indices']\n",
    "\n",
    "m, n = A.shape\n",
    "# Get indices of non-zero elements in A\n",
    "row_indices, col_indices = np.nonzero(A)\n",
    "edge_weights = A[row_indices, col_indices]\n",
    "\n",
    "# Map variable types to numerical values\n",
    "# Node types: 0 - continuous, 1 - binary\n",
    "variable_types = np.array([0 if v[0] == 'x' else 1 for v in variables_info])\n",
    "\n",
    "# Collect indices of continuous and binary variables\n",
    "continuous_indices = np.where(variable_types == 0)[0]\n",
    "binary_indices = np.where(variable_types == 1)[0]\n",
    "n_continuous = len(continuous_indices)\n",
    "n_binary = len(binary_indices)\n",
    "n_variables = n_continuous + n_binary\n",
    "\n",
    "variable_types_tensor = torch.tensor(variable_types)\n",
    "\n",
    "variable_lower_bounds = torch.tensor([variable_bounds[var_name]['Lower'] for var_name in variable_bounds], dtype=torch.float)\n",
    "variable_upper_bounds = torch.tensor([variable_bounds[var_name]['Upper'] for var_name in variable_bounds], dtype=torch.float)\n",
    "\n",
    "# For binary variables, we ensure LB=0, UB=1\n",
    "for i, vtype in enumerate(variable_types_tensor):\n",
    "    if vtype == 1.0:\n",
    "        variable_lower_bounds[i] = 0.0\n",
    "        variable_upper_bounds[i] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing feasible solutions from file.\n",
      "Loaded existing infeasible solutions from file.\n",
      "Loaded existing infeasible non-integral solutions from file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from generate_solutions import generate_feasible_solutions, generate_infeasible_solutions, generate_infeasible_nonintegral_solutions\n",
    "\n",
    "# Set generate_new to True or False as needed\n",
    "generate_new = False\n",
    "feasible_data_file = 'feasible_data.pkl'\n",
    "infeasible_data_file = 'infeasible_data.pkl'\n",
    "infeasible_nonintegral_data_file = 'infeasible_nonintegral_data.pkl'\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "# Load or generate feasible solutions\n",
    "if not generate_new and os.path.exists(feasible_data_file):\n",
    "    # Load feasible data\n",
    "    with open(feasible_data_file, 'rb') as f:\n",
    "        feasible_data = pickle.load(f)\n",
    "    feasible_solutions = feasible_data['solutions']\n",
    "    feasible_costs = feasible_data['costs']\n",
    "    print(\"Loaded existing feasible solutions from file.\")\n",
    "else:\n",
    "    # Generate feasible solutions\n",
    "    num_objectives = num_samples  # Adjust the number as needed\n",
    "    feasible_solutions, feasible_costs = generate_feasible_solutions(\n",
    "        A, E, Q, variables_info, b_vector, d_vector, num_objectives\n",
    "    )\n",
    "    # Save the generated data for future use\n",
    "    feasible_data = {'solutions': feasible_solutions, 'costs': feasible_costs}\n",
    "    with open(feasible_data_file, 'wb') as f:\n",
    "        pickle.dump(feasible_data, f)\n",
    "    print(\"Generated and saved feasible solutions.\")\n",
    "\n",
    "# Load or generate infeasible solutions\n",
    "if not generate_new and os.path.exists(infeasible_data_file):\n",
    "    # Load infeasible data\n",
    "    with open(infeasible_data_file, 'rb') as f:\n",
    "        infeasible_data = pickle.load(f)\n",
    "    infeasible_solutions = infeasible_data['solutions']\n",
    "    infeasible_costs = infeasible_data['costs']\n",
    "    print(\"Loaded existing infeasible solutions from file.\")\n",
    "else:\n",
    "    # Generate infeasible solutions\n",
    "    num_infeasible_samples = num_samples  # Adjust as needed\n",
    "    infeasible_solutions, infeasible_costs = generate_infeasible_solutions(\n",
    "        A, E, variables_info, b_vector, d_vector, Q, num_infeasible_samples, feasible_solutions\n",
    "    )\n",
    "    # Save the generated data for future use\n",
    "    infeasible_data = {'solutions': infeasible_solutions, 'costs': infeasible_costs}\n",
    "    with open(infeasible_data_file, 'wb') as f:\n",
    "        pickle.dump(infeasible_data, f)\n",
    "    print(\"Generated and saved infeasible solutions.\")\n",
    "\n",
    "# Load or generate infeasible non-integral solutions\n",
    "if not generate_new and os.path.exists(infeasible_nonintegral_data_file):\n",
    "    # Load infeasible non-integral data\n",
    "    with open(infeasible_nonintegral_data_file, 'rb') as f:\n",
    "        infeasible_nonintegral_data = pickle.load(f)\n",
    "    infeasible_nonintegral_solutions = infeasible_nonintegral_data['solutions']\n",
    "    infeasible_nonintegral_costs = infeasible_nonintegral_data['costs']\n",
    "    print(\"Loaded existing infeasible non-integral solutions from file.\")\n",
    "else:\n",
    "    # Generate infeasible non-integral solutions\n",
    "    num_infeasible_nonintegral_samples = num_samples  # Adjust as needed\n",
    "    infeasible_nonintegral_solutions, infeasible_nonintegral_costs = generate_infeasible_nonintegral_solutions(\n",
    "        A, E, variables_info, b_vector, d_vector, Q, num_infeasible_nonintegral_samples\n",
    "    )\n",
    "    # Save the generated data for future use\n",
    "    infeasible_nonintegral_data = {'solutions': infeasible_nonintegral_solutions, 'costs': infeasible_nonintegral_costs}\n",
    "    with open(infeasible_nonintegral_data_file, 'wb') as f:\n",
    "        pickle.dump(infeasible_nonintegral_data, f)\n",
    "    print(\"Generated and saved infeasible non-integral solutions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "540\n",
      "Before training, Test Loss: 3.4284190518789024 Recon Loss: 0.6521554467189743 Cost Loss: 1.0275315764438675 Constraint Loss: 1.0650954155558083 Integrality Loss: 0.6836366332678431\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "360\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "540\n",
      "Epoch 1, Train Loss: 0.9738, Recon: 0.0843, Cost: 0.1928, Const: 0.2506, Int: 0.4462 | Test Loss: 0.4039, Recon: 0.0014, Cost: 0.0575, Const: 0.0044, Int: 0.3405\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "360\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "540\n",
      "Epoch 2, Train Loss: 0.3225, Recon: 0.0011, Cost: 0.0481, Const: 0.0033, Int: 0.2701 | Test Loss: 0.2508, Recon: 0.0007, Cost: 0.0336, Const: 0.0041, Int: 0.2123\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "360\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "540\n",
      "Epoch 3, Train Loss: 0.1657, Recon: 0.0007, Cost: 0.0203, Const: 0.0028, Int: 0.1420 | Test Loss: 0.1228, Recon: 0.0005, Cost: 0.0160, Const: 0.0020, Int: 0.1044\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "360\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "540\n",
      "Epoch 4, Train Loss: 0.0983, Recon: 0.0008, Cost: 0.0122, Const: 0.0025, Int: 0.0827 | Test Loss: 0.0857, Recon: 0.0001, Cost: 0.0083, Const: 0.0018, Int: 0.0755\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "360\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "540\n",
      "Epoch 5, Train Loss: 0.0717, Recon: 0.0001, Cost: 0.0083, Const: 0.0014, Int: 0.0619 | Test Loss: 0.0695, Recon: 0.0002, Cost: 0.0070, Const: 0.0010, Int: 0.0613\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "360\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "540\n",
      "Epoch 6, Train Loss: 0.0613, Recon: 0.0003, Cost: 0.0078, Const: 0.0017, Int: 0.0515 | Test Loss: 0.0635, Recon: 0.0004, Cost: 0.0115, Const: 0.0017, Int: 0.0499\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n",
      "960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data, DataLoader, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import numpy as np\n",
    "\n",
    "from data_preparation_obj import create_data_list_obj, prepare_edge_index_and_attr, normalize_targets, split_data\n",
    "from data_preparation_constraints import prepare_constraint_edge_data, normalize_node_features, create_data_list_feas\n",
    "\n",
    "# Assume you have already defined or loaded:\n",
    "# A, E, Q, variables_info, b_vector, d_vector, variable_types_tensor, variable_lower_bounds, variable_upper_bounds, n_variables\n",
    "# feasible_solutions, feasible_costs\n",
    "# infeasible_solutions, infeasible_costs\n",
    "# infeasible_nonintegral_solutions, infeasible_nonintegral_costs\n",
    "\n",
    "# Prepare edge information from Q\n",
    "edge_index_obj, edge_attr_obj = prepare_edge_index_and_attr(Q)\n",
    "\n",
    "# Prepare edge information from A and E\n",
    "edge_index_feas, edge_attr_feas = prepare_constraint_edge_data(A, E, n_variables)\n",
    "\n",
    "# Create Data objects for feasible solutions\n",
    "data_list_obj_feas = create_data_list_obj(\n",
    "    feasible_solutions, feasible_costs, edge_index_obj, edge_attr_obj,\n",
    "    variable_types_tensor, variable_lower_bounds, variable_upper_bounds\n",
    ")\n",
    "\n",
    "data_list_feas_feas = create_data_list_feas(\n",
    "    feasible_solutions, feasible_costs, A, E, b_vector, d_vector, edge_index_feas, edge_attr_feas, n_variables,\n",
    "    variable_types_tensor, variable_lower_bounds, variable_upper_bounds\n",
    ")\n",
    "\n",
    "# Create Data objects for infeasible solutions\n",
    "data_list_obj_infeas = create_data_list_obj(\n",
    "    infeasible_solutions, infeasible_costs, edge_index_obj, edge_attr_obj,\n",
    "    variable_types_tensor, variable_lower_bounds, variable_upper_bounds\n",
    ")\n",
    "\n",
    "data_list_feas_infeas = create_data_list_feas(\n",
    "    infeasible_solutions, infeasible_costs, A, E, b_vector, d_vector, edge_index_feas, edge_attr_feas, n_variables,\n",
    "    variable_types_tensor, variable_lower_bounds, variable_upper_bounds\n",
    ")\n",
    "\n",
    "# Create Data objects for infeasible non-integral solutions (if available)\n",
    "data_list_obj_infeas_nonint = create_data_list_obj(\n",
    "    infeasible_nonintegral_solutions, infeasible_nonintegral_costs, edge_index_obj, edge_attr_obj,\n",
    "    variable_types_tensor, variable_lower_bounds, variable_upper_bounds\n",
    ")\n",
    "\n",
    "data_list_feas_infeas_nonint = create_data_list_feas(\n",
    "    infeasible_nonintegral_solutions, infeasible_nonintegral_costs, A, E, b_vector, d_vector, edge_index_feas, edge_attr_feas, n_variables,\n",
    "    variable_types_tensor, variable_lower_bounds, variable_upper_bounds\n",
    ")\n",
    "\n",
    "# Combine all data\n",
    "data_list_obj = data_list_obj_feas + data_list_obj_infeas + data_list_obj_infeas_nonint\n",
    "data_list_feas = data_list_feas_feas + data_list_feas_infeas + data_list_feas_infeas_nonint\n",
    "\n",
    "# If you only want feasible + infeasible (not non-integral), comment the above lines and use:\n",
    "# data_list_obj = data_list_obj_feas + data_list_obj_infeas\n",
    "# data_list_feas = data_list_feas_feas + data_list_feas_infeas\n",
    "\n",
    "# Normalize node features for data_list_obj\n",
    "data_list_obj, mean_obj, std_obj = normalize_node_features(data_list_obj)\n",
    "\n",
    "# Normalize node features for data_list_feas\n",
    "data_list_feas, mean_feas, std_feas = normalize_node_features(data_list_feas)\n",
    "\n",
    "# Normalize targets (x and cost) for data_list_obj\n",
    "data_list_obj, (mean_y_x, std_y_x), (mean_y_cost, std_y_cost), _ = normalize_targets(data_list_obj)\n",
    "\n",
    "# Normalize targets (x, cost, and constraints) for data_list_feas\n",
    "data_list_feas, _, _, (mean_y_constraints, std_y_constraints) = normalize_targets(data_list_feas)\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data_obj, test_data_obj = split_data(data_list_obj, test_size=0.2, random_state=42)\n",
    "train_data_feas, test_data_feas = split_data(data_list_feas, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "class GNNModelObj(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNNModelObj, self).__init__()\n",
    "        self.conv1 = GCNConv(4, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight=edge_weight))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_weight=edge_weight))\n",
    "        return x\n",
    "\n",
    "\n",
    "class GNNModelConstraints(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNNModelConstraints, self).__init__()\n",
    "        self.conv1 = GCNConv(4, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight=edge_weight))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_weight=edge_weight))\n",
    "        x_var = x[data.variable_mask]\n",
    "        x_constraints = x[~data.variable_mask]\n",
    "        return x_var, x_constraints\n",
    "\n",
    "\n",
    "class JointGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels_obj, hidden_channels_cons, decoder_hidden_channels):\n",
    "        super(JointGNN, self).__init__()\n",
    "        # Encoders\n",
    "        self.encoder_obj = GNNModelObj(hidden_channels_obj)\n",
    "        self.encoder_cons = GNNModelConstraints(hidden_channels_cons)\n",
    "\n",
    "        concat_dim = hidden_channels_obj + hidden_channels_cons\n",
    "\n",
    "        # Decoder for x reconstruction\n",
    "        self.decoder_x = nn.Sequential(\n",
    "            nn.Linear(concat_dim, decoder_hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(decoder_hidden_channels, 1)\n",
    "        )\n",
    "\n",
    "        # Decoder for cost prediction\n",
    "        self.decoder_cost = nn.Sequential(\n",
    "            nn.Linear(concat_dim, decoder_hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(decoder_hidden_channels, 1)\n",
    "        )\n",
    "\n",
    "        # Decoder for constraint violation prediction\n",
    "        self.decoder_constraints = nn.Sequential(\n",
    "            nn.Linear(hidden_channels_cons, decoder_hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(decoder_hidden_channels, 1)\n",
    "        )\n",
    "\n",
    "        # Decoder for integrality prediction\n",
    "        self.decoder_integrality = nn.Sequential(\n",
    "            nn.Linear(concat_dim, decoder_hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(decoder_hidden_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, data_obj, data_feas):\n",
    "        x_obj = self.encoder_obj(data_obj)\n",
    "        x_cons_var, x_cons_constraints = self.encoder_cons(data_feas)\n",
    "\n",
    "        x_obj_var = x_obj[data_obj.variable_mask]\n",
    "        x_var = torch.cat([x_obj_var, x_cons_var], dim=1)\n",
    "\n",
    "        x_hat = self.decoder_x(x_var).squeeze()\n",
    "\n",
    "        batch = data_obj.batch[data_obj.variable_mask]\n",
    "        x_var_pooled = global_mean_pool(x_var, batch)\n",
    "        predicted_cost = self.decoder_cost(x_var_pooled).squeeze()\n",
    "\n",
    "        predicted_constraints = self.decoder_constraints(x_cons_constraints).squeeze()\n",
    "\n",
    "        integrality_scores = self.decoder_integrality(x_var).squeeze()\n",
    "        binary_mask = data_obj.binary_mask[data_obj.variable_mask]\n",
    "        predicted_integrality = integrality_scores[binary_mask]\n",
    "        print(len(predicted_integrality))\n",
    "\n",
    "        return x_hat, predicted_cost, predicted_constraints, predicted_integrality\n",
    "\n",
    "\n",
    "class JointDataset(Dataset):\n",
    "    def __init__(self, data_list_obj, data_list_feas):\n",
    "        assert len(data_list_obj) == len(data_list_feas)\n",
    "        self.data_list_obj = data_list_obj\n",
    "        self.data_list_feas = data_list_feas\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list_obj)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list_obj[idx], self.data_list_feas[idx]\n",
    "\n",
    "\n",
    "def joint_collate_fn(batch):\n",
    "    data_obj_list, data_feas_list = zip(*batch)\n",
    "    batch_obj = Batch.from_data_list(data_obj_list)\n",
    "    batch_feas = Batch.from_data_list(data_feas_list)\n",
    "    return batch_obj, batch_feas\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = JointDataset(train_data_obj, train_data_feas)\n",
    "test_dataset = JointDataset(test_data_obj, test_data_feas)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=joint_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=joint_collate_fn)\n",
    "\n",
    "model = JointGNN(hidden_channels_obj=512, hidden_channels_cons=256, decoder_hidden_channels=128).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion_mse = nn.MSELoss()\n",
    "criterion_bce = nn.BCELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_cost_loss = 0\n",
    "    total_constraint_loss = 0\n",
    "    total_integrality_loss = 0\n",
    "\n",
    "    for data_obj_batch, data_feas_batch in train_loader:\n",
    "        data_obj_batch = data_obj_batch.to(device)\n",
    "        data_feas_batch = data_feas_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x_hat, predicted_cost, predicted_constraints, predicted_integrality = model(data_obj_batch, data_feas_batch)\n",
    "\n",
    "        y_x = data_obj_batch.y_x\n",
    "        y_cost = data_obj_batch.y_cost.squeeze()\n",
    "        y_constraints = data_feas_batch.y_constraints\n",
    "        y_integrality = data_obj_batch.y_integrality.to(device)\n",
    "\n",
    "        recon_loss = criterion_mse(x_hat, y_x)\n",
    "        cost_loss = criterion_mse(predicted_cost, y_cost)\n",
    "        constraint_loss = criterion_mse(predicted_constraints, y_constraints)\n",
    "        integrality_loss = criterion_bce(predicted_integrality, y_integrality)\n",
    "\n",
    "        loss = recon_loss + cost_loss + constraint_loss + integrality_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * data_obj_batch.num_graphs\n",
    "        total_recon_loss += recon_loss.item() * data_obj_batch.num_graphs\n",
    "        total_cost_loss += cost_loss.item() * data_obj_batch.num_graphs\n",
    "        total_constraint_loss += constraint_loss.item() * data_obj_batch.num_graphs\n",
    "        total_integrality_loss += integrality_loss.item() * data_obj_batch.num_graphs\n",
    "\n",
    "    n = len(train_loader.dataset)\n",
    "    return (total_loss/n, total_recon_loss/n, total_cost_loss/n, total_constraint_loss/n, total_integrality_loss/n)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_cost_loss = 0\n",
    "    total_constraint_loss = 0\n",
    "    total_integrality_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_obj_batch, data_feas_batch in loader:\n",
    "            data_obj_batch = data_obj_batch.to(device)\n",
    "            data_feas_batch = data_feas_batch.to(device)\n",
    "\n",
    "            x_hat, predicted_cost, predicted_constraints, predicted_integrality = model(data_obj_batch, data_feas_batch)\n",
    "\n",
    "            y_x = data_obj_batch.y_x\n",
    "            y_cost = data_obj_batch.y_cost.squeeze()\n",
    "            y_constraints = data_feas_batch.y_constraints\n",
    "            y_integrality = data_obj_batch.y_integrality.to(device)\n",
    "\n",
    "            recon_loss = criterion_mse(x_hat, y_x)\n",
    "            cost_loss = criterion_mse(predicted_cost, y_cost)\n",
    "            constraint_loss = criterion_mse(predicted_constraints, y_constraints)\n",
    "            integrality_loss = criterion_bce(predicted_integrality, y_integrality)\n",
    "\n",
    "            loss = recon_loss + cost_loss + constraint_loss + integrality_loss\n",
    "\n",
    "            total_loss += loss.item() * data_obj_batch.num_graphs\n",
    "            total_recon_loss += recon_loss.item() * data_obj_batch.num_graphs\n",
    "            total_cost_loss += cost_loss.item() * data_obj_batch.num_graphs\n",
    "            total_constraint_loss += constraint_loss.item() * data_obj_batch.num_graphs\n",
    "            total_integrality_loss += integrality_loss.item() * data_obj_batch.num_graphs\n",
    "\n",
    "    n = len(loader.dataset)\n",
    "    return (total_loss/n, total_recon_loss/n, total_cost_loss/n, total_constraint_loss/n, total_integrality_loss/n)\n",
    "\n",
    "num_epochs = 50\n",
    "test_results = test(test_loader)\n",
    "print(\"Before training, Test Loss:\", test_results[0],\n",
    "      \"Recon Loss:\", test_results[1],\n",
    "      \"Cost Loss:\", test_results[2],\n",
    "      \"Constraint Loss:\", test_results[3],\n",
    "      \"Integrality Loss:\", test_results[4])\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_results = train()\n",
    "    test_results = test(test_loader)\n",
    "    print(f\"Epoch {epoch}, \"\n",
    "          f\"Train Loss: {train_results[0]:.4f}, Recon: {train_results[1]:.4f}, Cost: {train_results[2]:.4f}, Const: {train_results[3]:.4f}, Int: {train_results[4]:.4f} \"\n",
    "          f\"| Test Loss: {test_results[0]:.4f}, Recon: {test_results[1]:.4f}, Cost: {test_results[2]:.4f}, Const: {test_results[3]:.4f}, Int: {test_results[4]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list_feas_feas = create_data_list_feas(feasible_solutions, feasible_costs, A, E, b_vector, d_vector, edge_index_feas, edge_attr_feas, n_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Reconstruction Error: 0.13619418442249298\n"
     ]
    }
   ],
   "source": [
    "# Use a batch of data\n",
    "data_obj_batch, data_feas_batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    data_obj_batch, data_feas_batch = data_obj_batch.to(device), data_feas_batch.to(device)\n",
    "    # Encode and decode\n",
    "    z_obj = model.encoder_obj(data_obj_batch)\n",
    "    z_cons_var, z_constraints = model.encoder_cons(data_feas_batch)\n",
    "    x_obj_var = z_obj[data_obj_batch.variable_mask]\n",
    "    x_var = torch.cat([x_obj_var, z_cons_var], dim=1)\n",
    "    x_hat = model.decoder_x(x_var).squeeze()\n",
    "    # Denormalize x_hat and y_x\n",
    "    x_hat_denorm = x_hat * std_y_x + mean_y_x\n",
    "    y_x_denorm = data_obj_batch.y_x * std_y_x + mean_y_x\n",
    "    # Compute reconstruction error\n",
    "    recon_error = torch.norm(x_hat_denorm - y_x_denorm)\n",
    "    print(f\"Decoder Reconstruction Error: {recon_error.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x745a3ab2b1d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_x_denorm.cpu().numpy(), x_hat_denorm.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feasible Solutions Integrality Predictions ---\n",
      "Solution index: 0\n",
      "Binary Variables (Indices): [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "Predicted Integrality: [3.5721666e-07 9.4408238e-01 9.4408238e-01 9.9937314e-01 9.4408238e-01\n",
      " 1.8875800e-08 9.4408238e-01 9.9937314e-01 9.4408238e-01 3.4109473e-01\n",
      " 9.4408238e-01 1.3061387e-05 9.9937314e-01 9.9937314e-01 1.7971946e-04\n",
      " 9.9937314e-01 1.5641532e-04 1.5215267e-04 1.3687973e-07 1.1173832e-03\n",
      " 1.5198921e-06 9.9937314e-01 1.9372342e-04 9.9937314e-01 1.7516238e-04\n",
      " 9.4408238e-01 2.5660008e-06 2.1339265e-06 2.3325764e-07 7.8876526e-04]\n",
      "True Integrality:      [0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "------\n",
      "\n",
      "Solution index: 1\n",
      "Binary Variables (Indices): [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "Predicted Integrality: [5.2159921e-05 4.7803415e-08 1.8515316e-04 2.2456820e-08 1.2589870e-04\n",
      " 4.9906180e-06 4.3566627e-04 2.4301398e-05 9.4408238e-01 1.1959086e-05\n",
      " 1.6899601e-06 9.9937314e-01 4.0807166e-08 9.9937314e-01 9.9937314e-01\n",
      " 1.9243100e-08 1.7058283e-04 9.4408238e-01 9.4408238e-01 9.4408238e-01\n",
      " 3.0532789e-05 9.9937314e-01 6.2605983e-07 2.0627667e-04 1.4704649e-03\n",
      " 7.6364579e-08 9.9937314e-01 9.9937314e-01 5.7121110e-07 9.9937314e-01]\n",
      "True Integrality:      [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 0. 1.]\n",
      "------\n",
      "\n",
      "Solution index: 2\n",
      "Binary Variables (Indices): [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "Predicted Integrality: [0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.9440824  0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.9440824  0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314]\n",
      "True Integrality:      [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "------\n",
      "\n",
      "--- Infeasible Non-Integral Solutions Integrality Predictions ---\n",
      "Solution index: 495\n",
      "Binary Variables (Indices): [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "Predicted Integrality: [0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.9440824  0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.9440824  0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314]\n",
      "True Integrality:      [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "------\n",
      "\n",
      "Solution index: 496\n",
      "Binary Variables (Indices): [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "Predicted Integrality: [9.8525716e-06 9.9937314e-01 1.4189613e-04 2.3796065e-05 1.4625647e-08\n",
      " 3.6290075e-08 9.9937314e-01 4.3562027e-06 9.9937314e-01 9.9937314e-01\n",
      " 4.5864992e-03 1.9000491e-04 3.3463871e-06 4.1003479e-03 6.4937225e-08\n",
      " 7.7861358e-07 8.3021430e-04 9.9937314e-01 9.9937314e-01 9.4408238e-01\n",
      " 9.4408238e-01 6.0475890e-05 5.6496356e-06 9.9937314e-01 3.7142875e-08\n",
      " 9.4408238e-01 9.9937314e-01 9.9937314e-01 9.4408238e-01 2.0851994e-04]\n",
      "True Integrality:      [0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1.\n",
      " 0. 1. 1. 1. 1. 0.]\n",
      "------\n",
      "\n",
      "Solution index: 497\n",
      "Binary Variables (Indices): [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "Predicted Integrality: [1.3187423e-06 5.2193372e-04 1.7438559e-08 5.7732741e-05 3.9841339e-05\n",
      " 9.9937314e-01 7.0643444e-05 4.2586220e-05 3.4656188e-07 2.2081105e-07\n",
      " 5.6142680e-06 5.8640498e-01 2.8770469e-06 6.7033970e-06 1.3493768e-04\n",
      " 8.5321879e-03 3.5182493e-05 1.9048419e-05 2.6038519e-04 3.2852967e-07\n",
      " 9.4408238e-01 7.0698436e-05 9.6142743e-05 2.8120306e-07 3.4420691e-06\n",
      " 4.4586291e-03 1.5798410e-04 1.4683031e-08 4.6234219e-03 1.9774179e-06]\n",
      "True Integrality:      [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "def print_integrality_predictions(data_obj_list, data_feas_list, indices, description):\n",
    "    print(f\"--- {description} Solutions Integrality Predictions ---\")\n",
    "    model.eval()\n",
    "    for i in indices:\n",
    "        # Wrap single Data objects into a batch of size 1\n",
    "        data_obj_batch = Batch.from_data_list([data_obj_list[i]]).to(device)\n",
    "        data_feas_batch = Batch.from_data_list([data_feas_list[i]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_hat, predicted_cost, predicted_constraints, predicted_integrality = model(data_obj_batch, data_feas_batch)\n",
    "\n",
    "        # Now data_obj_batch and data_feas_batch have the .batch attribute\n",
    "        # Extract ground truth integrality\n",
    "        y_integrality = data_obj_batch.y_integrality.to(device)\n",
    "        binary_mask = data_obj_batch.binary_mask[data_obj_batch.variable_mask].cpu().numpy()\n",
    "\n",
    "        predicted_integrality_cpu = predicted_integrality.cpu().numpy()\n",
    "        y_integrality_cpu = y_integrality.cpu().numpy()\n",
    "\n",
    "        print(f\"Solution index: {i}\")\n",
    "        print(\"Binary Variables (Indices):\", np.where(binary_mask)[0])\n",
    "        print(\"Predicted Integrality:\", predicted_integrality_cpu)\n",
    "        print(\"True Integrality:     \", y_integrality_cpu)\n",
    "        print(\"------\\n\")\n",
    "\n",
    "# Example usage:\n",
    "feasible_indices = [0, 1, 2]  # Indices for feasible solutions in the test set\n",
    "infeasible_nonintegral_indices = [len(test_data_obj)-3, len(test_data_obj)-2, len(test_data_obj)-1]\n",
    "\n",
    "print_integrality_predictions(test_data_obj, test_data_feas, feasible_indices, \"Feasible\")\n",
    "print_integrality_predictions(test_data_obj, test_data_feas, infeasible_nonintegral_indices, \"Infeasible Non-Integral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feasible Solutions Integrality Predictions ---\n",
      "Solution index: 11\n",
      "Binary Variables (Indices): [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "Predicted Integrality: [0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.9440824  0.99937314 0.99937314 0.99937314 0.99937314 0.9440824\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314]\n",
      "True Integrality:      [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "------\n",
      "\n",
      "Solution index: 15\n",
      "Binary Variables (Indices): [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "Predicted Integrality: [0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.9440824\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.9440824  0.99937314 0.99937314 0.99937314 0.99937314]\n",
      "True Integrality:      [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "------\n",
      "\n",
      "Solution index: 18\n",
      "Binary Variables (Indices): [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "Predicted Integrality: [0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.9440824  0.99937314 0.99937314 0.99937314 0.99937314\n",
      " 0.99937314 0.99937314 0.99937314 0.99937314 0.9440824  0.99937314]\n",
      "True Integrality:      [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "------\n",
      "\n",
      "--- Infeasible Non-Integral Solutions Integrality Predictions ---\n",
      "Solution index: 0\n",
      "Binary Variables (Indices): [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "Predicted Integrality: [3.5721666e-07 9.4408238e-01 9.4408238e-01 9.9937314e-01 9.4408238e-01\n",
      " 1.8875800e-08 9.4408238e-01 9.9937314e-01 9.4408238e-01 3.4109473e-01\n",
      " 9.4408238e-01 1.3061387e-05 9.9937314e-01 9.9937314e-01 1.7971946e-04\n",
      " 9.9937314e-01 1.5641532e-04 1.5215267e-04 1.3687973e-07 1.1173832e-03\n",
      " 1.5198921e-06 9.9937314e-01 1.9372342e-04 9.9937314e-01 1.7516238e-04\n",
      " 9.4408238e-01 2.5660008e-06 2.1339265e-06 2.3325764e-07 7.8876526e-04]\n",
      "True Integrality:      [0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0.]\n",
      "------\n",
      "\n",
      "Solution index: 1\n",
      "Binary Variables (Indices): [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "Predicted Integrality: [5.2159921e-05 4.7803415e-08 1.8515316e-04 2.2456820e-08 1.2589870e-04\n",
      " 4.9906180e-06 4.3566627e-04 2.4301398e-05 9.4408238e-01 1.1959086e-05\n",
      " 1.6899601e-06 9.9937314e-01 4.0807166e-08 9.9937314e-01 9.9937314e-01\n",
      " 1.9243100e-08 1.7058283e-04 9.4408238e-01 9.4408238e-01 9.4408238e-01\n",
      " 3.0532789e-05 9.9937314e-01 6.2605983e-07 2.0627667e-04 1.4704649e-03\n",
      " 7.6364579e-08 9.9937314e-01 9.9937314e-01 5.7121110e-07 9.9937314e-01]\n",
      "True Integrality:      [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 0. 1.]\n",
      "------\n",
      "\n",
      "Solution index: 3\n",
      "Binary Variables (Indices): [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "Predicted Integrality: [1.48453746e-05 1.26121944e-04 5.84786584e-08 2.53107935e-08\n",
      " 9.44082379e-01 1.52260502e-04 4.08320329e-06 1.37087191e-04\n",
      " 1.55775098e-07 9.59164254e-07 9.99373138e-01 3.37986023e-07\n",
      " 1.59850490e-04 3.70535780e-08 3.43208981e-08 1.09824607e-04\n",
      " 9.99373138e-01 1.45054093e-08 9.99373138e-01 9.99373138e-01\n",
      " 1.43526762e-04 7.27758834e-06 1.96640748e-08 1.49022535e-05\n",
      " 9.99373138e-01 9.99373138e-01 2.10901963e-08 9.99373138e-01\n",
      " 6.84709107e-07 1.01918660e-04]\n",
      "True Integrality:      [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0.]\n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "def is_infeasible_nonintegral(data_obj, data_feas, feasibility_tol=1e-4):\n",
    "    # Check feasibility\n",
    "    y_constraints = data_feas.y_constraints.cpu().numpy()\n",
    "    infeasible = np.any(y_constraints > feasibility_tol)\n",
    "\n",
    "    # Check integrality: if any binary var is non-integral => y_integrality=0 for that var\n",
    "    y_int = data_obj.y_integrality.cpu().numpy()\n",
    "\n",
    "    nonintegral = np.any(y_int == 0)  # If any binary variable is non-integral\n",
    "\n",
    "    return infeasible and nonintegral\n",
    "\n",
    "def is_feasible_integral(data_obj, data_feas, feasibility_tol=1e-4):\n",
    "    # Feasible if all constraints are within tolerance\n",
    "    y_constraints = data_feas.y_constraints.cpu().numpy()\n",
    "    feasible = np.all(y_constraints <= feasibility_tol + 1e-9)  # some tolerance\n",
    "\n",
    "    # Integral if all binary vars integral\n",
    "    y_int = data_obj.y_integrality.cpu().numpy()\n",
    "    integral = np.all(y_int == 1)\n",
    "\n",
    "    return feasible and integral\n",
    "\n",
    "def print_integrality_predictions(data_obj_list, data_feas_list, indices, description, model, device):\n",
    "    print(f\"--- {description} Solutions Integrality Predictions ---\")\n",
    "    model.eval()\n",
    "    for i in indices:\n",
    "        data_obj = data_obj_list[i]\n",
    "        data_feas = data_feas_list[i]\n",
    "\n",
    "        # Wrap single samples into a Batch\n",
    "        data_obj_batch = Batch.from_data_list([data_obj]).to(device)\n",
    "        data_feas_batch = Batch.from_data_list([data_feas]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_hat, predicted_cost, predicted_constraints, predicted_integrality = model(data_obj_batch, data_feas_batch)\n",
    "\n",
    "        # Ground truth integrality\n",
    "        y_integrality = data_obj_batch.y_integrality.to(device)\n",
    "        # Binary mask for variables\n",
    "        binary_mask = data_obj_batch.binary_mask[data_obj_batch.variable_mask].cpu().numpy()\n",
    "\n",
    "        predicted_integrality_cpu = predicted_integrality.cpu().numpy()\n",
    "        y_integrality_cpu = y_integrality.cpu().numpy()\n",
    "\n",
    "        print(f\"Solution index: {i}\")\n",
    "        print(\"Binary Variables (Indices):\", np.where(binary_mask)[0])\n",
    "        print(\"Predicted Integrality:\", predicted_integrality_cpu)\n",
    "        print(\"True Integrality:     \", y_integrality_cpu)\n",
    "        print(\"------\\n\")\n",
    "\n",
    "# Now let's pick some actual feasible and infeasible_nonintegral solutions from the test set\n",
    "feasible_candidates = []\n",
    "infeas_nonint_candidates = []\n",
    "\n",
    "# We'll scan through the test set to find a few examples\n",
    "for idx in range(len(test_dataset)):\n",
    "    data_obj, data_feas = test_dataset[idx]\n",
    "\n",
    "    if is_feasible_integral(data_obj, data_feas):\n",
    "        feasible_candidates.append(idx)\n",
    "    elif is_infeasible_nonintegral(data_obj, data_feas):\n",
    "        \n",
    "        infeas_nonint_candidates.append(idx)\n",
    "\n",
    "    # Stop if we have enough examples\n",
    "    if len(feasible_candidates) >= 3 and len(infeas_nonint_candidates) >= 3:\n",
    "        break\n",
    "\n",
    "# Print some feasible solution predictions\n",
    "if feasible_candidates:\n",
    "    print_integrality_predictions(test_data_obj, test_data_feas, feasible_candidates[:3], \"Feasible\", model, device)\n",
    "else:\n",
    "    print(\"No feasible integral examples found in test set.\")\n",
    "\n",
    "# Print some infeasible non-integral solution predictions\n",
    "if infeas_nonint_candidates:\n",
    "    print_integrality_predictions(test_data_obj, test_data_feas, infeas_nonint_candidates[:3], \"Infeasible Non-Integral\", model, device)\n",
    "else:\n",
    "    print(\"No infeasible non-integral examples found in test set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(model, data_list_obj, data_list_feas):\n",
    "    model.eval()\n",
    "    actual_costs = []\n",
    "    predicted_costs = []\n",
    "    actual_constraints = []\n",
    "    predicted_constraints_list = []\n",
    "\n",
    "    # For integrality evaluation\n",
    "    total_binary_vars = 0\n",
    "    correct_integrality_preds = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_obj, data_feas in zip(data_list_obj, data_list_feas):\n",
    "            data_obj, data_feas = data_obj.to(device), data_feas.to(device)\n",
    "\n",
    "            # Ground truth solution\n",
    "            y_x = data_obj.y_x * std_y_x + mean_y_x  # Denormalize x\n",
    "            y_x_np = y_x.detach().cpu().numpy()  # (n_variables,)\n",
    "\n",
    "            # Compute actual cost\n",
    "            actual_cost = 0.5 * y_x_np.T @ Q @ y_x_np  # Quadratic form\n",
    "            actual_costs.append(actual_cost)\n",
    "\n",
    "            # Compute actual constraint violations\n",
    "            inequality_violations = A @ y_x_np - b_vector\n",
    "            equality_violations = E @ y_x_np - d_vector\n",
    "            actual_constraint = np.concatenate((inequality_violations, equality_violations))\n",
    "            actual_constraints.extend(actual_constraint)\n",
    "\n",
    "            # Prepare batches\n",
    "            data_obj_batch = Batch.from_data_list([data_obj]).to(device)\n",
    "            data_feas_batch = Batch.from_data_list([data_feas]).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            x_hat, predicted_cost, predicted_constraints, predicted_integrality = model(data_obj_batch, data_feas_batch)\n",
    "\n",
    "            # Denormalize predicted cost and constraints\n",
    "            predicted_cost_denorm = (predicted_cost.item() * std_y_cost + mean_y_cost)\n",
    "            predicted_constraints_denorm = (predicted_constraints * std_y_constraints + mean_y_constraints).detach().cpu().numpy()\n",
    "\n",
    "            predicted_costs.append(predicted_cost_denorm)\n",
    "            predicted_constraints_list.extend(predicted_constraints_denorm)\n",
    "\n",
    "            # Evaluate integrality predictions\n",
    "            # Extract ground truth integrality\n",
    "            y_integrality = data_obj_batch.y_integrality.cpu().numpy()  # shape: [num_binary_vars_in_graph]\n",
    "            predicted_integrality_cpu = predicted_integrality.cpu().numpy()\n",
    "\n",
    "            # Binarize predicted integrality: 1 if p>0.5 else 0\n",
    "            predicted_integrality_bin = (predicted_integrality_cpu > 0.5).astype(float)\n",
    "\n",
    "            # Count correct integrality predictions\n",
    "            correct_integrality_preds += np.sum(predicted_integrality_bin == y_integrality)\n",
    "            total_binary_vars += len(y_integrality)\n",
    "\n",
    "    # Compute correlations for cost and constraints\n",
    "    cost_correlation = np.corrcoef(actual_costs, predicted_costs)[0, 1]\n",
    "    constraint_correlation = np.corrcoef(np.array(actual_constraints), np.array(predicted_constraints_list))[0, 1]\n",
    "\n",
    "    # Compute integrality accuracy\n",
    "    integrality_accuracy = correct_integrality_preds / total_binary_vars if total_binary_vars > 0 else 0.0\n",
    "\n",
    "    print(f\"Cost Prediction Correlation: {cost_correlation}\")\n",
    "    print(f\"Constraint Prediction Correlation: {constraint_correlation}\")\n",
    "    print(f\"Integrality Prediction Accuracy: {integrality_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Prediction Correlation: 0.9994264150981651\n",
      "Constraint Prediction Correlation: 0.8946393781570621\n",
      "Integrality Prediction Accuracy: 99.45%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have test_data_obj and test_data_feas\n",
    "evaluate_predictions(model, test_data_obj, test_data_feas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=joint_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "\n",
    "def compute_mean_embeddings(train_loader):\n",
    "    variable_sums = defaultdict(lambda: torch.zeros(model.encoder_obj.conv2.out_channels + model.encoder_cons.conv2.out_channels))\n",
    "    variable_counts = defaultdict(int)\n",
    "    constraint_sums = defaultdict(lambda: torch.zeros(model.encoder_cons.conv2.out_channels))\n",
    "    constraint_counts = defaultdict(int)\n",
    "\n",
    "    # Integrality accumulators\n",
    "    integrality_sums = defaultdict(float)\n",
    "    integrality_counts = defaultdict(int)\n",
    "\n",
    "    for data_obj_batch, data_feas_batch in train_loader:\n",
    "        with torch.no_grad():\n",
    "            data_obj_batch, data_feas_batch = data_obj_batch.to(device), data_feas_batch.to(device)\n",
    "            x_obj = model.encoder_obj(data_obj_batch)\n",
    "            x_cons_var, x_cons_constraints = model.encoder_cons(data_feas_batch)\n",
    "\n",
    "            x_obj_var = x_obj[data_obj_batch.variable_mask]\n",
    "            x_var = torch.cat([x_obj_var, x_cons_var], dim=1)\n",
    "\n",
    "            # Run full model to get integrality predictions\n",
    "            x_hat, predicted_cost, predicted_constraints, predicted_integrality = model(data_obj_batch, data_feas_batch)\n",
    "\n",
    "            # Move to CPU\n",
    "            x_var_cpu = x_var.cpu()\n",
    "            x_cons_constraints_cpu = x_cons_constraints.cpu()\n",
    "\n",
    "            # Aggregate variable embeddings as PyTorch tensors (no .numpy() call)\n",
    "            for idx in range(x_var_cpu.size(0)):\n",
    "                variable_sums[idx] += x_var_cpu[idx]\n",
    "                variable_counts[idx] += 1\n",
    "\n",
    "            # Aggregate constraint embeddings\n",
    "            for idx in range(x_cons_constraints_cpu.size(0)):\n",
    "                constraint_sums[idx] += x_cons_constraints_cpu[idx]\n",
    "                constraint_counts[idx] += 1\n",
    "\n",
    "            # Aggregate integrality predictions for binary variables\n",
    "            binary_mask = data_obj_batch.binary_mask[data_obj_batch.variable_mask].cpu().numpy()\n",
    "            predicted_integrality_cpu = predicted_integrality.cpu().numpy()\n",
    "\n",
    "            binary_var_indices = np.where(binary_mask)[0]\n",
    "            for b_idx, var_idx in enumerate(binary_var_indices):\n",
    "                integrality_sums[var_idx] += predicted_integrality_cpu[b_idx]\n",
    "                integrality_counts[var_idx] += 1\n",
    "\n",
    "    # Compute mean embeddings\n",
    "    mean_x_var_list = [variable_sums[idx] / variable_counts[idx] for idx in sorted(variable_sums.keys())]\n",
    "    mean_x_cons_constraints_list = [constraint_sums[idx] / constraint_counts[idx] for idx in sorted(constraint_sums.keys())]\n",
    "\n",
    "    # Stack them into tensors\n",
    "    mean_x_var_tensor = torch.stack(mean_x_var_list)\n",
    "    mean_x_cons_constraints_tensor = torch.stack(mean_x_cons_constraints_list)\n",
    "\n",
    "    # Compute mean integrality predictions\n",
    "    mean_integrality = {}\n",
    "    for var_idx in sorted(integrality_sums.keys()):\n",
    "        mean_integrality[var_idx] = integrality_sums[var_idx] / integrality_counts[var_idx]\n",
    "\n",
    "    return mean_x_var_tensor, mean_x_cons_constraints_tensor, mean_integrality\n",
    "\n",
    "# Now call the function\n",
    "mean_x_var_tensor, mean_x_cons_constraints_tensor, mean_integrality = compute_mean_embeddings(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/1000, Total Loss: 289313.0625, Cost Loss: 3.6701, Constraint Loss: 12.7554, Integrality Loss: 1.6176, Positivity Loss: 0.0000\n",
      "Iteration 100/1000, Total Loss: 47422.7070, Cost Loss: 0.3002, Constraint Loss: 0.0100, Integrality Loss: 0.4731, Positivity Loss: 0.0000\n",
      "Iteration 200/1000, Total Loss: -322.0095, Cost Loss: 0.3021, Constraint Loss: 0.0337, Integrality Loss: -0.0141, Positivity Loss: 0.0000\n",
      "Iteration 300/1000, Total Loss: -400.8761, Cost Loss: 0.3022, Constraint Loss: 0.0338, Integrality Loss: -0.0149, Positivity Loss: 0.0000\n",
      "Iteration 400/1000, Total Loss: -400.9158, Cost Loss: 0.3022, Constraint Loss: 0.0338, Integrality Loss: -0.0149, Positivity Loss: 0.0000\n",
      "Iteration 500/1000, Total Loss: 116349.6797, Cost Loss: 0.3469, Constraint Loss: 0.0099, Integrality Loss: 1.0204, Positivity Loss: 0.0001\n",
      "Iteration 600/1000, Total Loss: 203134.9219, Cost Loss: 0.2983, Constraint Loss: 0.0071, Integrality Loss: 1.7598, Positivity Loss: 0.0003\n",
      "Iteration 700/1000, Total Loss: 243136.0781, Cost Loss: 0.2820, Constraint Loss: 0.0142, Integrality Loss: 1.9649, Positivity Loss: 0.0005\n",
      "Iteration 800/1000, Total Loss: 291056.3438, Cost Loss: 0.3310, Constraint Loss: 0.0116, Integrality Loss: 2.6374, Positivity Loss: 0.0003\n",
      "Iteration 900/1000, Total Loss: 339803.4375, Cost Loss: 0.3900, Constraint Loss: 0.0120, Integrality Loss: 3.0272, Positivity Loss: 0.0004\n",
      "Iteration 1000/1000, Total Loss: 350018.7500, Cost Loss: 0.3996, Constraint Loss: 0.1153, Integrality Loss: 3.3767, Positivity Loss: 0.0001\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1/25\n",
      "Iteration 1/3000, Total Loss: 231.7262, Cost Loss: 4.4309, Constraint Loss: 17.3043, Integrality Loss: 0.0032, Positivity Loss: 0.0000, Avg Binary Var: 0.0684\n",
      "Iteration 100/3000, Total Loss: 10.9972, Cost Loss: 0.0065, Constraint Loss: 0.0250, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 200/3000, Total Loss: 6.6444, Cost Loss: -0.0371, Constraint Loss: 0.0039, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1665\n",
      "Iteration 300/3000, Total Loss: 7.0069, Cost Loss: -0.0366, Constraint Loss: 0.0042, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 400/3000, Total Loss: 6.5662, Cost Loss: -0.0456, Constraint Loss: 0.0010, Integrality Loss: 0.0030, Positivity Loss: 0.0002, Avg Binary Var: 0.1314\n",
      "Iteration 500/3000, Total Loss: 6.2590, Cost Loss: -0.0142, Constraint Loss: 0.0195, Integrality Loss: 0.0613, Positivity Loss: 0.0000, Avg Binary Var: 0.0817\n",
      "Iteration 600/3000, Total Loss: 3.5323, Cost Loss: -0.0378, Constraint Loss: 0.0027, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 700/3000, Total Loss: 3.8355, Cost Loss: -0.0414, Constraint Loss: 0.0021, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1666\n",
      "Iteration 800/3000, Total Loss: 4.3776, Cost Loss: -0.0481, Constraint Loss: 0.0008, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 900/3000, Total Loss: 5.9590, Cost Loss: -0.0374, Constraint Loss: 0.0011, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 1000/3000, Total Loss: 8.3247, Cost Loss: -0.0446, Constraint Loss: 0.0023, Integrality Loss: 0.0001, Positivity Loss: 0.0002, Avg Binary Var: 0.1329\n",
      "Iteration 1100/3000, Total Loss: 6.2609, Cost Loss: -0.0145, Constraint Loss: 0.0108, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 1200/3000, Total Loss: 4.4053, Cost Loss: -0.0211, Constraint Loss: 0.0131, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 1300/3000, Total Loss: 10.0477, Cost Loss: -0.0468, Constraint Loss: 0.0007, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 1400/3000, Total Loss: 3.7466, Cost Loss: -0.0474, Constraint Loss: 0.0007, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1664\n",
      "Iteration 1500/3000, Total Loss: 3.3984, Cost Loss: -0.0361, Constraint Loss: 0.0073, Integrality Loss: 0.0004, Positivity Loss: 0.0001, Avg Binary Var: 0.1007\n",
      "Iteration 1600/3000, Total Loss: 8.2891, Cost Loss: -0.0548, Constraint Loss: 0.0100, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1666\n",
      "Iteration 1700/3000, Total Loss: 10.6769, Cost Loss: -0.0692, Constraint Loss: 0.0135, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1333\n",
      "Iteration 1800/3000, Total Loss: 7.8634, Cost Loss: -0.0347, Constraint Loss: 0.0015, Integrality Loss: 0.0002, Positivity Loss: 0.0001, Avg Binary Var: 0.1662\n",
      "Iteration 1900/3000, Total Loss: 6.7479, Cost Loss: -0.0624, Constraint Loss: 0.0218, Integrality Loss: 0.0094, Positivity Loss: 0.0004, Avg Binary Var: 0.1703\n",
      "Iteration 2000/3000, Total Loss: 5.2166, Cost Loss: -0.0563, Constraint Loss: 0.0017, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1333\n",
      "Iteration 2100/3000, Total Loss: 5.7799, Cost Loss: -0.0800, Constraint Loss: 0.0100, Integrality Loss: 0.0000, Positivity Loss: 0.0007, Avg Binary Var: 0.1333\n",
      "Iteration 2200/3000, Total Loss: 8.2376, Cost Loss: -0.0218, Constraint Loss: 0.0008, Integrality Loss: 0.0292, Positivity Loss: 0.0001, Avg Binary Var: 0.1594\n",
      "Iteration 2300/3000, Total Loss: 4.1210, Cost Loss: -0.0679, Constraint Loss: 0.0075, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1333\n",
      "Iteration 2400/3000, Total Loss: 2.9709, Cost Loss: -0.0345, Constraint Loss: 0.0030, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1666\n",
      "Iteration 2500/3000, Total Loss: 3.4778, Cost Loss: -0.1241, Constraint Loss: 0.0694, Integrality Loss: 0.0000, Positivity Loss: 0.0019, Avg Binary Var: 0.1000\n",
      "Iteration 2600/3000, Total Loss: 4.0581, Cost Loss: -0.0642, Constraint Loss: 0.0076, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1333\n",
      "Iteration 2700/3000, Total Loss: 2.7947, Cost Loss: -0.0881, Constraint Loss: 0.0668, Integrality Loss: 0.0000, Positivity Loss: 0.0010, Avg Binary Var: 0.1335\n",
      "Iteration 2800/3000, Total Loss: 7.4969, Cost Loss: -0.0139, Constraint Loss: 0.0074, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2900/3000, Total Loss: 6.9987, Cost Loss: 0.0018, Constraint Loss: 0.0244, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 3000/3000, Total Loss: 10.6771, Cost Loss: 0.0612, Constraint Loss: 0.0921, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "\n",
      "Continuous Variables (first 30): [ 0.003  0.435  0.003  0.003  0.003  0.003  0.003  0.003  0.003  0.003\n",
      "  0.003  0.375  0.003  0.003  0.003  0.003  0.037 -0.011 -0.016  0.001\n",
      " -0.011 -0.009 -0.011 -0.011 -0.01  -0.003 -0.011 -0.011 -0.011 -0.011]\n",
      "Binary/Integer Variables (remaining): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Optimized Cost: -0.0939132274633173\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-1.00000000e+00  3.00000003e-03 -5.64999998e-01  3.00000003e-03\n",
      "  3.00000003e-03  3.00000003e-03  3.00000003e-03  3.00000003e-03\n",
      "  3.00000003e-03  3.00000003e-03  3.00000003e-03  3.00000003e-03\n",
      " -6.25000000e-01  3.00000003e-03  3.00000003e-03  3.00000003e-03\n",
      "  3.00000003e-03  3.70000005e-02 -1.09999999e-02 -1.01600000e+00\n",
      "  1.00000005e-03 -1.09999999e-02 -1.00900000e+00 -1.09999999e-02\n",
      " -1.09999999e-02 -9.99999978e-03 -3.00000003e-03 -1.09999999e-02\n",
      " -1.09999999e-02 -1.09999999e-02 -1.09999999e-02]\n",
      "Equality Violations (should be close to 0): [-0.236]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.489  0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.429  0.     0.     0.     0.     0.     0.     0.038  0.\n",
      "  0.     0.045  0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.     1.    -0.\n",
      " -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.014129639\n",
      "Starting run 2/25\n",
      "Iteration 1/3000, Total Loss: 223.1202, Cost Loss: 4.3191, Constraint Loss: 16.4018, Integrality Loss: 0.0835, Positivity Loss: 0.0000, Avg Binary Var: 0.0897\n",
      "Iteration 100/3000, Total Loss: 10.0993, Cost Loss: -0.0109, Constraint Loss: 0.0349, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0667\n",
      "Iteration 200/3000, Total Loss: 6.6650, Cost Loss: -0.0146, Constraint Loss: 0.0123, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 300/3000, Total Loss: 13.5141, Cost Loss: -0.0400, Constraint Loss: 0.9975, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1999\n",
      "Iteration 400/3000, Total Loss: 6.5619, Cost Loss: -0.0276, Constraint Loss: 0.0126, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1002\n",
      "Iteration 500/3000, Total Loss: 8.7227, Cost Loss: -0.0431, Constraint Loss: 0.0025, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 600/3000, Total Loss: 12.1996, Cost Loss: 0.0022, Constraint Loss: 0.0513, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0999\n",
      "Iteration 700/3000, Total Loss: 10.3239, Cost Loss: -0.0374, Constraint Loss: 0.0345, Integrality Loss: 0.0220, Positivity Loss: 0.0001, Avg Binary Var: 0.1060\n",
      "Iteration 800/3000, Total Loss: 5.8482, Cost Loss: -0.0423, Constraint Loss: 0.0019, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 900/3000, Total Loss: 6.4919, Cost Loss: -0.0323, Constraint Loss: 0.0013, Integrality Loss: 0.0338, Positivity Loss: 0.0001, Avg Binary Var: 0.1585\n",
      "Iteration 1000/3000, Total Loss: 8.4612, Cost Loss: -0.0353, Constraint Loss: 0.0119, Integrality Loss: 0.0000, Positivity Loss: 0.0016, Avg Binary Var: 0.1333\n",
      "Iteration 1100/3000, Total Loss: 5.0316, Cost Loss: -0.0377, Constraint Loss: 0.0030, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 1200/3000, Total Loss: 6.9507, Cost Loss: -0.0348, Constraint Loss: 0.0026, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 1300/3000, Total Loss: 7.7889, Cost Loss: -0.0416, Constraint Loss: 0.0027, Integrality Loss: 0.0619, Positivity Loss: 0.0002, Avg Binary Var: 0.1156\n",
      "Iteration 1400/3000, Total Loss: 7.5124, Cost Loss: -0.0390, Constraint Loss: 0.0017, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1500/3000, Total Loss: 10.8968, Cost Loss: 0.0802, Constraint Loss: 0.1185, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1600/3000, Total Loss: 12.3504, Cost Loss: 0.0083, Constraint Loss: 0.0404, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 1700/3000, Total Loss: 9.3410, Cost Loss: -0.0026, Constraint Loss: 0.0252, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1800/3000, Total Loss: 7.0912, Cost Loss: -0.0492, Constraint Loss: 0.0016, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1900/3000, Total Loss: 7.8730, Cost Loss: -0.0633, Constraint Loss: 0.0045, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1000\n",
      "Iteration 2000/3000, Total Loss: 5.0104, Cost Loss: 0.0863, Constraint Loss: 0.0420, Integrality Loss: 0.0008, Positivity Loss: 0.0000, Avg Binary Var: 0.1657\n",
      "Iteration 2100/3000, Total Loss: 16.3518, Cost Loss: -0.1311, Constraint Loss: 1.0209, Integrality Loss: 0.0003, Positivity Loss: 0.0020, Avg Binary Var: 0.1994\n",
      "Iteration 2200/3000, Total Loss: 4.3368, Cost Loss: -0.0337, Constraint Loss: 0.0812, Integrality Loss: 0.0148, Positivity Loss: 0.0001, Avg Binary Var: 0.1380\n",
      "Iteration 2300/3000, Total Loss: 2.9048, Cost Loss: -0.0626, Constraint Loss: 0.0027, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1000\n",
      "Iteration 2400/3000, Total Loss: 4.7516, Cost Loss: 0.0074, Constraint Loss: 0.0214, Integrality Loss: 0.0609, Positivity Loss: 0.0000, Avg Binary Var: 0.1185\n",
      "Iteration 2500/3000, Total Loss: 3.8229, Cost Loss: -0.0736, Constraint Loss: 0.0177, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1333\n",
      "Iteration 2600/3000, Total Loss: 4.7235, Cost Loss: -0.0711, Constraint Loss: 0.0691, Integrality Loss: 0.0000, Positivity Loss: 0.0007, Avg Binary Var: 0.1000\n",
      "Iteration 2700/3000, Total Loss: 1.8872, Cost Loss: -0.0224, Constraint Loss: 0.0137, Integrality Loss: 0.0202, Positivity Loss: 0.0001, Avg Binary Var: 0.0943\n",
      "Iteration 2800/3000, Total Loss: 2.3723, Cost Loss: 0.0244, Constraint Loss: 0.0029, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2900/3000, Total Loss: 12.3260, Cost Loss: -0.0112, Constraint Loss: 0.0147, Integrality Loss: 0.0051, Positivity Loss: 0.0000, Avg Binary Var: 0.1359\n",
      "Iteration 3000/3000, Total Loss: 17.9476, Cost Loss: -0.0758, Constraint Loss: 0.0090, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1333\n",
      "\n",
      "Continuous Variables (first 30): [ 0.008  0.273  0.008  0.008  0.01   0.008  0.008  0.008  0.008  0.008\n",
      "  0.008  0.253  0.008  0.434  0.008  0.008  0.008 -0.004  0.     0.001\n",
      " -0.004 -0.004 -0.004 -0.004 -0.003 -0.002 -0.004 -0.004 -0.004 -0.004]\n",
      "Binary/Integer Variables (remaining): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Optimized Cost: -0.03843571477384291\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-1.00000000e+00  8.00000038e-03 -7.26999998e-01  8.00000038e-03\n",
      "  8.00000038e-03  9.99999978e-03  8.00000038e-03  8.00000038e-03\n",
      "  8.00000038e-03  8.00000038e-03  8.00000038e-03  8.00000038e-03\n",
      " -7.47000009e-01  8.00000038e-03 -5.66000015e-01  8.00000038e-03\n",
      "  8.00000038e-03  8.00000038e-03 -4.00000019e-03  0.00000000e+00\n",
      "  1.00000005e-03 -1.00400000e+00 -4.00000019e-03 -4.00000019e-03\n",
      " -4.00000019e-03 -3.00000003e-03 -2.00000009e-03 -4.00000019e-03\n",
      " -4.00000019e-03 -4.00000019e-03 -4.00000019e-03]\n",
      "Equality Violations (should be close to 0): [0.03399998]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.284  0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.264  0.     0.445  0.     0.     0.     0.     0.     0.\n",
      "  0.007  0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.     1.    -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      "  1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.001557827\n",
      "Starting run 3/25\n",
      "Iteration 1/3000, Total Loss: 243.2934, Cost Loss: 4.7649, Constraint Loss: 18.2866, Integrality Loss: 0.0868, Positivity Loss: 0.0031, Avg Binary Var: 0.0429\n",
      "Iteration 100/3000, Total Loss: 11.6151, Cost Loss: 0.0315, Constraint Loss: 0.0363, Integrality Loss: 0.0001, Positivity Loss: 0.0000, Avg Binary Var: 0.0996\n",
      "Iteration 200/3000, Total Loss: 5.0209, Cost Loss: -0.0254, Constraint Loss: 0.0101, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.0667\n",
      "Iteration 300/3000, Total Loss: 7.9933, Cost Loss: -0.0141, Constraint Loss: 0.0106, Integrality Loss: 0.0540, Positivity Loss: 0.0000, Avg Binary Var: 0.1539\n",
      "Iteration 400/3000, Total Loss: 3.9735, Cost Loss: -0.0368, Constraint Loss: 0.0027, Integrality Loss: 0.0080, Positivity Loss: 0.0001, Avg Binary Var: 0.1300\n",
      "Iteration 500/3000, Total Loss: 11.2380, Cost Loss: -0.0132, Constraint Loss: 0.0125, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1002\n",
      "Iteration 600/3000, Total Loss: 10.3874, Cost Loss: -0.0448, Constraint Loss: 0.0042, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 700/3000, Total Loss: 6.2539, Cost Loss: -0.0423, Constraint Loss: 0.0014, Integrality Loss: 0.0467, Positivity Loss: 0.0002, Avg Binary Var: 0.0895\n",
      "Iteration 800/3000, Total Loss: 5.8272, Cost Loss: -0.0465, Constraint Loss: 0.0008, Integrality Loss: 0.0549, Positivity Loss: 0.0002, Avg Binary Var: 0.1458\n",
      "Iteration 900/3000, Total Loss: 7.4242, Cost Loss: -0.0308, Constraint Loss: 0.0086, Integrality Loss: 0.0019, Positivity Loss: 0.0001, Avg Binary Var: 0.1015\n",
      "Iteration 1000/3000, Total Loss: 4.8723, Cost Loss: -0.0427, Constraint Loss: 0.0015, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 1100/3000, Total Loss: 6.7351, Cost Loss: -0.0510, Constraint Loss: 0.0008, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 1200/3000, Total Loss: 4.4163, Cost Loss: -0.0504, Constraint Loss: 0.0010, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 1300/3000, Total Loss: 16.6207, Cost Loss: -0.0434, Constraint Loss: 0.0050, Integrality Loss: 0.0347, Positivity Loss: 0.0002, Avg Binary Var: 0.1088\n",
      "Iteration 1400/3000, Total Loss: 11.8572, Cost Loss: -0.0486, Constraint Loss: 0.0004, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1666\n",
      "Iteration 1500/3000, Total Loss: 9.2375, Cost Loss: -0.0256, Constraint Loss: 0.1350, Integrality Loss: 0.0007, Positivity Loss: 0.0001, Avg Binary Var: 0.0676\n",
      "Iteration 1600/3000, Total Loss: 9.2761, Cost Loss: 0.0737, Constraint Loss: 0.0485, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1700/3000, Total Loss: 10.5788, Cost Loss: -0.0603, Constraint Loss: 0.0002, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1667\n",
      "Iteration 1800/3000, Total Loss: 18.2409, Cost Loss: -0.0030, Constraint Loss: 0.0277, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1900/3000, Total Loss: 12.4706, Cost Loss: -0.0671, Constraint Loss: 0.0040, Integrality Loss: 0.0189, Positivity Loss: 0.0005, Avg Binary Var: 0.1388\n",
      "Iteration 2000/3000, Total Loss: 15.0723, Cost Loss: -0.0196, Constraint Loss: 0.0042, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 2100/3000, Total Loss: 15.1857, Cost Loss: -0.0703, Constraint Loss: 0.0242, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1333\n",
      "Iteration 2200/3000, Total Loss: 11.4222, Cost Loss: 0.0512, Constraint Loss: 0.0600, Integrality Loss: 0.1257, Positivity Loss: 0.0000, Avg Binary Var: 0.1328\n",
      "Iteration 2300/3000, Total Loss: 6.6361, Cost Loss: -0.0051, Constraint Loss: 0.0089, Integrality Loss: 0.0081, Positivity Loss: 0.0000, Avg Binary Var: 0.1033\n",
      "Iteration 2400/3000, Total Loss: 4.9984, Cost Loss: -0.0384, Constraint Loss: 0.0024, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 2500/3000, Total Loss: 3.8063, Cost Loss: -0.0656, Constraint Loss: 0.0012, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1667\n",
      "Iteration 2600/3000, Total Loss: 9.9291, Cost Loss: 0.0001, Constraint Loss: 0.0611, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2700/3000, Total Loss: 12.3437, Cost Loss: -0.0224, Constraint Loss: 0.0143, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0998\n",
      "Iteration 2800/3000, Total Loss: 8.1872, Cost Loss: -0.0032, Constraint Loss: 0.0252, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 2900/3000, Total Loss: 4.4924, Cost Loss: -0.0439, Constraint Loss: 0.0013, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 3000/3000, Total Loss: 4.9663, Cost Loss: 0.0299, Constraint Loss: 0.0220, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "\n",
      "Continuous Variables (first 30): [ 0.008  0.008  0.008  0.008  0.312  0.008  0.008  0.008  0.008  0.148\n",
      "  0.008  0.376  0.009  0.008  0.008  0.008  0.008 -0.008 -0.003 -0.002\n",
      " -0.008 -0.008 -0.008 -0.008 -0.008 -0.007 -0.008 -0.008 -0.008 -0.008]\n",
      "Binary/Integer Variables (remaining): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Optimized Cost: -0.0762230067279124\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-3.00000000e+00  8.00000038e-03  8.00000038e-03  8.00000038e-03\n",
      "  8.00000038e-03 -6.87999994e-01  8.00000038e-03  8.00000038e-03\n",
      "  8.00000038e-03  8.00000038e-03  1.48000002e-01  8.00000038e-03\n",
      " -6.24000013e-01  8.99999961e-03  8.00000038e-03  8.00000038e-03\n",
      "  8.00000038e-03  8.00000038e-03 -8.00000038e-03 -3.00000003e-03\n",
      " -2.00000009e-03 -8.00000038e-03 -8.00000038e-03 -8.00000038e-03\n",
      " -8.00000038e-03 -8.00000038e-03 -7.00000022e-03 -8.00000038e-03\n",
      " -8.00000038e-03 -8.00000038e-03 -8.00000038e-03]\n",
      "Equality Violations (should be close to 0): [-0.143]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.     0.     0.468  0.     0.     0.     0.     0.\n",
      "  0.     0.532  0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.    -0.    -0.    -0.     1.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.07219076\n",
      "Starting run 4/25\n",
      "Iteration 1/3000, Total Loss: 171.5994, Cost Loss: 3.4393, Constraint Loss: 11.4136, Integrality Loss: 0.0016, Positivity Loss: 0.0019, Avg Binary Var: 0.0019\n",
      "Iteration 100/3000, Total Loss: 10.8224, Cost Loss: 0.0539, Constraint Loss: 0.0238, Integrality Loss: 0.0541, Positivity Loss: 0.0000, Avg Binary Var: 0.1123\n",
      "Iteration 200/3000, Total Loss: 6.4383, Cost Loss: -0.0364, Constraint Loss: 0.0038, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 300/3000, Total Loss: 5.9820, Cost Loss: -0.0360, Constraint Loss: 0.0021, Integrality Loss: 0.0519, Positivity Loss: 0.0001, Avg Binary Var: 0.1119\n",
      "Iteration 400/3000, Total Loss: 3.5013, Cost Loss: -0.0469, Constraint Loss: 0.0040, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 500/3000, Total Loss: 2.7072, Cost Loss: -0.0381, Constraint Loss: 0.0031, Integrality Loss: 0.0024, Positivity Loss: 0.0001, Avg Binary Var: 0.1017\n",
      "Iteration 600/3000, Total Loss: 4.5786, Cost Loss: -0.0412, Constraint Loss: 0.0027, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 700/3000, Total Loss: 6.4284, Cost Loss: -0.0218, Constraint Loss: 0.0039, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 800/3000, Total Loss: 9.6334, Cost Loss: -0.0269, Constraint Loss: 0.0047, Integrality Loss: 0.0026, Positivity Loss: 0.0001, Avg Binary Var: 0.1649\n",
      "Iteration 900/3000, Total Loss: 6.9800, Cost Loss: -0.0460, Constraint Loss: 0.0016, Integrality Loss: 0.0149, Positivity Loss: 0.0002, Avg Binary Var: 0.1384\n",
      "Iteration 1000/3000, Total Loss: 9.3967, Cost Loss: -0.0423, Constraint Loss: 0.0009, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1100/3000, Total Loss: 7.9612, Cost Loss: -0.0215, Constraint Loss: 0.0026, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 1200/3000, Total Loss: 8.0584, Cost Loss: -0.0306, Constraint Loss: 0.0041, Integrality Loss: 0.0609, Positivity Loss: 0.0001, Avg Binary Var: 0.1519\n",
      "Iteration 1300/3000, Total Loss: 8.4637, Cost Loss: -0.1353, Constraint Loss: 0.0525, Integrality Loss: 0.0000, Positivity Loss: 0.0021, Avg Binary Var: 0.1667\n",
      "Iteration 1400/3000, Total Loss: 10.7246, Cost Loss: -0.0645, Constraint Loss: 0.0066, Integrality Loss: 0.0611, Positivity Loss: 0.0004, Avg Binary Var: 0.1483\n",
      "Iteration 1500/3000, Total Loss: 5.7260, Cost Loss: 0.0055, Constraint Loss: 0.0106, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 1600/3000, Total Loss: 6.3539, Cost Loss: -0.0834, Constraint Loss: 0.0156, Integrality Loss: 0.0000, Positivity Loss: 0.0007, Avg Binary Var: 0.1666\n",
      "Iteration 1700/3000, Total Loss: 10.5535, Cost Loss: -0.0151, Constraint Loss: 0.0401, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1665\n",
      "Iteration 1800/3000, Total Loss: 10.6371, Cost Loss: 0.0556, Constraint Loss: 0.0346, Integrality Loss: 0.0038, Positivity Loss: 0.0000, Avg Binary Var: 0.1645\n",
      "Iteration 1900/3000, Total Loss: 11.3427, Cost Loss: -0.0208, Constraint Loss: 0.0047, Integrality Loss: 0.0003, Positivity Loss: 0.0001, Avg Binary Var: 0.1661\n",
      "Iteration 2000/3000, Total Loss: 12.6201, Cost Loss: -0.0196, Constraint Loss: 0.0104, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2100/3000, Total Loss: 6.4292, Cost Loss: -0.0463, Constraint Loss: 0.0014, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 2200/3000, Total Loss: 9.0272, Cost Loss: -0.0413, Constraint Loss: 0.0083, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1334\n",
      "Iteration 2300/3000, Total Loss: 7.9455, Cost Loss: -0.0254, Constraint Loss: 0.0180, Integrality Loss: 0.0007, Positivity Loss: 0.0001, Avg Binary Var: 0.1334\n",
      "Iteration 2400/3000, Total Loss: 4.4280, Cost Loss: 0.0384, Constraint Loss: 0.0579, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2500/3000, Total Loss: 9.3125, Cost Loss: 0.0272, Constraint Loss: 0.0634, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2600/3000, Total Loss: 10.0919, Cost Loss: -0.0684, Constraint Loss: 0.0101, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1667\n",
      "Iteration 2700/3000, Total Loss: 10.1269, Cost Loss: 0.1115, Constraint Loss: 0.1393, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 2800/3000, Total Loss: 5.2748, Cost Loss: -0.0621, Constraint Loss: 0.0045, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1667\n",
      "Iteration 2900/3000, Total Loss: 5.0767, Cost Loss: 0.0882, Constraint Loss: 0.0524, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 3000/3000, Total Loss: 8.2074, Cost Loss: -0.0597, Constraint Loss: 0.0146, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1667\n",
      "\n",
      "Continuous Variables (first 30): [ 0.015  0.015  0.015  0.015  0.015  0.015  0.015  0.302  0.212  0.015\n",
      "  0.015  0.35   0.015  0.015  0.015  0.015  0.015 -0.001  0.001  0.002\n",
      " -0.001 -0.001 -0.001 -0.001 -0.001  0.    -0.001 -0.001 -0.001 -0.001]\n",
      "Binary/Integer Variables (remaining): [0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Optimized Cost: -0.005819717005745222\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [ 0.00000000e+00  1.49999997e-02  1.49999997e-02  1.49999997e-02\n",
      "  1.49999997e-02  1.49999997e-02  1.49999997e-02  1.49999997e-02\n",
      " -6.98000014e-01 -7.88000003e-01  1.49999997e-02  1.49999997e-02\n",
      " -6.50000006e-01  1.49999997e-02  1.49999997e-02  1.49999997e-02\n",
      "  1.49999997e-02  1.49999997e-02 -1.00000005e-03  1.00000005e-03\n",
      " -9.98000000e-01 -1.00000005e-03 -1.00000005e-03 -1.00100000e+00\n",
      " -1.00000005e-03 -1.00000005e-03  0.00000000e+00 -1.00000005e-03\n",
      " -1.00000005e-03 -1.00000005e-03 -1.00000005e-03]\n",
      "Equality Violations (should be close to 0): [0.06699997]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.     0.     0.     0.     0.     0.329  0.239  0.\n",
      "  0.     0.377  0.     0.     0.     0.     0.     0.     0.     0.029\n",
      "  0.     0.     0.026  0.     0.     0.     0.     0.     0.     0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.     1.     1.    -0.\n",
      " -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.     1.\n",
      " -0.    -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.006804943\n",
      "Starting run 5/25\n",
      "Iteration 1/3000, Total Loss: 146.2578, Cost Loss: 2.8225, Constraint Loss: 8.7733, Integrality Loss: 0.0616, Positivity Loss: 0.0009, Avg Binary Var: 0.0848\n",
      "Iteration 100/3000, Total Loss: 10.6310, Cost Loss: -0.0257, Constraint Loss: 0.0067, Integrality Loss: 0.0001, Positivity Loss: 0.0001, Avg Binary Var: 0.1664\n",
      "Iteration 200/3000, Total Loss: 8.2391, Cost Loss: -0.0417, Constraint Loss: 0.1441, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 300/3000, Total Loss: 6.0500, Cost Loss: -0.0466, Constraint Loss: 0.0028, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 400/3000, Total Loss: 5.0409, Cost Loss: -0.0319, Constraint Loss: 0.0037, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 500/3000, Total Loss: 5.2596, Cost Loss: -0.0321, Constraint Loss: 0.0038, Integrality Loss: 0.0027, Positivity Loss: 0.0001, Avg Binary Var: 0.1352\n",
      "Iteration 600/3000, Total Loss: 4.2103, Cost Loss: -0.0287, Constraint Loss: 0.0138, Integrality Loss: 0.0014, Positivity Loss: 0.0001, Avg Binary Var: 0.0987\n",
      "Iteration 700/3000, Total Loss: 3.5190, Cost Loss: -0.0461, Constraint Loss: 0.0068, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 800/3000, Total Loss: 5.9146, Cost Loss: -0.0412, Constraint Loss: 0.0025, Integrality Loss: 0.0532, Positivity Loss: 0.0002, Avg Binary Var: 0.1454\n",
      "Iteration 900/3000, Total Loss: 2.8701, Cost Loss: -0.0410, Constraint Loss: 0.0033, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 1000/3000, Total Loss: 2.8474, Cost Loss: -0.0431, Constraint Loss: 0.0010, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1100/3000, Total Loss: 1.7640, Cost Loss: -0.0383, Constraint Loss: 0.0026, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1200/3000, Total Loss: 4.1962, Cost Loss: -0.0950, Constraint Loss: 0.0460, Integrality Loss: 0.0000, Positivity Loss: 0.0011, Avg Binary Var: 0.1667\n",
      "Iteration 1300/3000, Total Loss: 6.1520, Cost Loss: -0.0428, Constraint Loss: 0.0148, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1400/3000, Total Loss: 7.4354, Cost Loss: -0.0417, Constraint Loss: 0.0019, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1500/3000, Total Loss: 15.1405, Cost Loss: -0.0426, Constraint Loss: 0.0063, Integrality Loss: 0.0451, Positivity Loss: 0.0002, Avg Binary Var: 0.1102\n",
      "Iteration 1600/3000, Total Loss: 17.7129, Cost Loss: -0.0555, Constraint Loss: 0.0642, Integrality Loss: 0.0552, Positivity Loss: 0.0003, Avg Binary Var: 0.1208\n",
      "Iteration 1700/3000, Total Loss: 11.2980, Cost Loss: -0.0433, Constraint Loss: 0.0011, Integrality Loss: 0.0013, Positivity Loss: 0.0002, Avg Binary Var: 0.1653\n",
      "Iteration 1800/3000, Total Loss: 7.8392, Cost Loss: -0.0140, Constraint Loss: 0.0075, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1900/3000, Total Loss: 7.5535, Cost Loss: -0.0028, Constraint Loss: 0.0335, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2000/3000, Total Loss: 5.7033, Cost Loss: -0.0671, Constraint Loss: 0.0153, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1000\n",
      "Iteration 2100/3000, Total Loss: 10.0485, Cost Loss: 0.0882, Constraint Loss: 0.2917, Integrality Loss: 0.0087, Positivity Loss: 0.0000, Avg Binary Var: 0.0632\n",
      "Iteration 2200/3000, Total Loss: 10.5013, Cost Loss: 0.0081, Constraint Loss: 0.0244, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 2300/3000, Total Loss: 6.4774, Cost Loss: -0.0321, Constraint Loss: 0.0055, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 2400/3000, Total Loss: 4.9725, Cost Loss: -0.0850, Constraint Loss: 0.0651, Integrality Loss: 0.0000, Positivity Loss: 0.0009, Avg Binary Var: 0.1333\n",
      "Iteration 2500/3000, Total Loss: 4.5199, Cost Loss: -0.0457, Constraint Loss: 0.0015, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 2600/3000, Total Loss: 4.4222, Cost Loss: -0.0310, Constraint Loss: 0.0035, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.0667\n",
      "Iteration 2700/3000, Total Loss: 3.0482, Cost Loss: -0.1125, Constraint Loss: 0.0678, Integrality Loss: 0.0001, Positivity Loss: 0.0015, Avg Binary Var: 0.0330\n",
      "Iteration 2800/3000, Total Loss: 3.5038, Cost Loss: -0.0406, Constraint Loss: 0.0430, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 2900/3000, Total Loss: 5.4363, Cost Loss: -0.0224, Constraint Loss: 0.0121, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 3000/3000, Total Loss: 8.2312, Cost Loss: -0.0477, Constraint Loss: 0.0008, Integrality Loss: 0.0003, Positivity Loss: 0.0002, Avg Binary Var: 0.1328\n",
      "\n",
      "Continuous Variables (first 30): [ 0.007  0.006  0.007  0.299  0.008  0.007  0.007  0.354  0.007  0.007\n",
      "  0.008  0.007  0.297  0.008  0.008  0.007  0.007 -0.005 -0.003 -0.003\n",
      " -0.005 -0.004 -0.005 -0.005 -0.004 -0.004 -0.005 -0.004 -0.004 -0.004]\n",
      "Binary/Integer Variables (remaining): [0.    0.    0.    1.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      " 1.    0.    0.    0.    0.    0.    0.    0.    0.    0.001 0.    0.\n",
      " 0.    0.    0.    0.    0.    0.   ]\n",
      "Optimized Cost: -0.04947927421701866\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-1.999       0.007       0.006       0.007      -0.70100001  0.008\n",
      "  0.007       0.007      -0.646       0.007       0.007       0.008\n",
      "  0.007      -0.70300001  0.008       0.008       0.007       0.007\n",
      " -0.005      -0.003      -0.003      -0.005      -0.005      -0.005\n",
      " -0.005      -0.004      -0.004      -0.005      -0.004      -0.004\n",
      " -0.004     ]\n",
      "Equality Violations (should be close to 0): [-0.00400001]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.     0.316  0.     0.     0.     0.371  0.     0.\n",
      "  0.     0.     0.314  0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.    -0.    -0.     1.    -0.    -0.    -0.     1.    -0.    -0.\n",
      " -0.    -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.0018062592\n",
      "Starting run 6/25\n",
      "Iteration 1/3000, Total Loss: 168.9315, Cost Loss: 3.0542, Constraint Loss: 11.0829, Integrality Loss: 0.0037, Positivity Loss: 0.0000, Avg Binary Var: 0.1303\n",
      "Iteration 100/3000, Total Loss: 10.2790, Cost Loss: -0.0256, Constraint Loss: 0.0112, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 200/3000, Total Loss: 5.4123, Cost Loss: -0.0260, Constraint Loss: 0.0100, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 300/3000, Total Loss: 7.7702, Cost Loss: -0.0424, Constraint Loss: 0.1928, Integrality Loss: 0.0005, Positivity Loss: 0.0002, Avg Binary Var: 0.1008\n",
      "Iteration 400/3000, Total Loss: 6.3030, Cost Loss: -0.0433, Constraint Loss: 0.0022, Integrality Loss: 0.0075, Positivity Loss: 0.0002, Avg Binary Var: 0.1032\n",
      "Iteration 500/3000, Total Loss: 4.2272, Cost Loss: -0.0465, Constraint Loss: 0.0009, Integrality Loss: 0.0053, Positivity Loss: 0.0002, Avg Binary Var: 0.1639\n",
      "Iteration 600/3000, Total Loss: 6.8747, Cost Loss: -0.0373, Constraint Loss: 0.0065, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 700/3000, Total Loss: 4.0238, Cost Loss: -0.0434, Constraint Loss: 0.0016, Integrality Loss: 0.0007, Positivity Loss: 0.0002, Avg Binary Var: 0.1009\n",
      "Iteration 800/3000, Total Loss: 4.9088, Cost Loss: -0.0295, Constraint Loss: 0.0038, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.0667\n",
      "Iteration 900/3000, Total Loss: 8.1853, Cost Loss: -0.0377, Constraint Loss: 0.0023, Integrality Loss: 0.0520, Positivity Loss: 0.0001, Avg Binary Var: 0.1549\n",
      "Iteration 1000/3000, Total Loss: 11.7505, Cost Loss: -0.0302, Constraint Loss: 0.0494, Integrality Loss: 0.0001, Positivity Loss: 0.0001, Avg Binary Var: 0.1337\n",
      "Iteration 1100/3000, Total Loss: 10.6025, Cost Loss: -0.0233, Constraint Loss: 0.0020, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 1200/3000, Total Loss: 8.3944, Cost Loss: -0.0050, Constraint Loss: 0.0064, Integrality Loss: 0.0009, Positivity Loss: 0.0000, Avg Binary Var: 0.1010\n",
      "Iteration 1300/3000, Total Loss: 9.5903, Cost Loss: 0.0497, Constraint Loss: 0.0017, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1665\n",
      "Iteration 1400/3000, Total Loss: 7.1677, Cost Loss: 0.0675, Constraint Loss: 0.0670, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1500/3000, Total Loss: 7.4871, Cost Loss: -0.0312, Constraint Loss: 0.1789, Integrality Loss: 0.0001, Positivity Loss: 0.0001, Avg Binary Var: 0.1004\n",
      "Iteration 1600/3000, Total Loss: 4.2863, Cost Loss: 0.0217, Constraint Loss: 0.0011, Integrality Loss: 0.0151, Positivity Loss: 0.0000, Avg Binary Var: 0.1381\n",
      "Iteration 1700/3000, Total Loss: 3.2175, Cost Loss: -0.0328, Constraint Loss: 0.0395, Integrality Loss: 0.0034, Positivity Loss: 0.0001, Avg Binary Var: 0.0358\n",
      "Iteration 1800/3000, Total Loss: 8.1733, Cost Loss: -0.0599, Constraint Loss: 0.0217, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1331\n",
      "Iteration 1900/3000, Total Loss: 13.7195, Cost Loss: -0.0583, Constraint Loss: 0.0022, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1667\n",
      "Iteration 2000/3000, Total Loss: 15.5265, Cost Loss: -0.0670, Constraint Loss: 0.0171, Integrality Loss: 0.0364, Positivity Loss: 0.0005, Avg Binary Var: 0.1581\n",
      "Iteration 2100/3000, Total Loss: 10.8245, Cost Loss: 0.0591, Constraint Loss: 0.0882, Integrality Loss: 0.0001, Positivity Loss: 0.0000, Avg Binary Var: 0.1331\n",
      "Iteration 2200/3000, Total Loss: 7.2857, Cost Loss: -0.0361, Constraint Loss: 0.0039, Integrality Loss: 0.0606, Positivity Loss: 0.0001, Avg Binary Var: 0.1479\n",
      "Iteration 2300/3000, Total Loss: 8.1565, Cost Loss: -0.0268, Constraint Loss: 0.0091, Integrality Loss: 0.0183, Positivity Loss: 0.0001, Avg Binary Var: 0.1054\n",
      "Iteration 2400/3000, Total Loss: 5.7629, Cost Loss: 0.0620, Constraint Loss: 0.0818, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 2500/3000, Total Loss: 3.9291, Cost Loss: -0.0268, Constraint Loss: 0.0145, Integrality Loss: 0.0015, Positivity Loss: 0.0001, Avg Binary Var: 0.1320\n",
      "Iteration 2600/3000, Total Loss: 7.8228, Cost Loss: -0.0717, Constraint Loss: 0.0262, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1665\n",
      "Iteration 2700/3000, Total Loss: 4.7541, Cost Loss: -0.0518, Constraint Loss: 0.0030, Integrality Loss: 0.0331, Positivity Loss: 0.0003, Avg Binary Var: 0.1413\n",
      "Iteration 2800/3000, Total Loss: 15.3617, Cost Loss: 0.0137, Constraint Loss: 0.0267, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1666\n",
      "Iteration 2900/3000, Total Loss: 17.0229, Cost Loss: -0.0398, Constraint Loss: 0.0129, Integrality Loss: 0.0004, Positivity Loss: 0.0001, Avg Binary Var: 0.1340\n",
      "Iteration 3000/3000, Total Loss: 15.0032, Cost Loss: -0.0737, Constraint Loss: 0.0096, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1333\n",
      "\n",
      "Continuous Variables (first 30): [ 0.008  0.305  0.008  0.009  0.008  0.008  0.008  0.245  0.008  0.284\n",
      "  0.008  0.008  0.008  0.008  0.008  0.008  0.155 -0.002 -0.     0.\n",
      " -0.002 -0.002 -0.002 -0.002 -0.002 -0.001 -0.002 -0.002 -0.002 -0.002]\n",
      "Binary/Integer Variables (remaining): [0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Optimized Cost: -0.019548461775721445\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-1.          0.008      -0.69499999  0.008       0.009       0.008\n",
      "  0.008       0.008      -0.755       0.008      -0.71599999  0.008\n",
      "  0.008       0.008       0.008       0.008       0.008      -0.845\n",
      " -0.002       0.          0.         -0.002      -0.002      -0.002\n",
      " -0.002      -0.002      -0.001      -0.002      -0.002      -0.002\n",
      " -0.002     ]\n",
      "Equality Violations (should be close to 0): [0.07300003]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.308  0.     0.     0.     0.     0.     0.248  0.     0.287\n",
      "  0.     0.     0.     0.     0.     0.     0.158  0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.     1.    -0.    -0.    -0.    -0.    -0.     1.    -0.     1.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.     1.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.0009202957\n",
      "Starting run 7/25\n",
      "Iteration 1/3000, Total Loss: 153.8296, Cost Loss: 3.5666, Constraint Loss: 9.5236, Integrality Loss: 0.0268, Positivity Loss: 0.0030, Avg Binary Var: 0.0599\n",
      "Iteration 100/3000, Total Loss: 10.3911, Cost Loss: 0.0916, Constraint Loss: 0.0355, Integrality Loss: 0.0600, Positivity Loss: 0.0000, Avg Binary Var: 0.0524\n",
      "Iteration 200/3000, Total Loss: 4.9604, Cost Loss: -0.0007, Constraint Loss: 0.0157, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 300/3000, Total Loss: 10.5277, Cost Loss: -0.0080, Constraint Loss: 0.0193, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 400/3000, Total Loss: 8.1984, Cost Loss: -0.0335, Constraint Loss: 0.0055, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 500/3000, Total Loss: 5.0468, Cost Loss: -0.0459, Constraint Loss: 0.0011, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 600/3000, Total Loss: 5.4214, Cost Loss: -0.0431, Constraint Loss: 0.0021, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1001\n",
      "Iteration 700/3000, Total Loss: 5.3643, Cost Loss: -0.0439, Constraint Loss: 0.0021, Integrality Loss: 0.0001, Positivity Loss: 0.0002, Avg Binary Var: 0.1330\n",
      "Iteration 800/3000, Total Loss: 2.8511, Cost Loss: -0.0490, Constraint Loss: 0.0003, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 900/3000, Total Loss: 2.8037, Cost Loss: -0.0353, Constraint Loss: 0.0031, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 1000/3000, Total Loss: 4.5556, Cost Loss: -0.0472, Constraint Loss: 0.0005, Integrality Loss: 0.0003, Positivity Loss: 0.0002, Avg Binary Var: 0.1660\n",
      "Iteration 1100/3000, Total Loss: 4.8273, Cost Loss: -0.0466, Constraint Loss: 0.0016, Integrality Loss: 0.0002, Positivity Loss: 0.0002, Avg Binary Var: 0.1329\n",
      "Iteration 1200/3000, Total Loss: 5.1959, Cost Loss: -0.0812, Constraint Loss: 0.0314, Integrality Loss: 0.0000, Positivity Loss: 0.0007, Avg Binary Var: 0.1333\n",
      "Iteration 1300/3000, Total Loss: 3.6963, Cost Loss: -0.0406, Constraint Loss: 0.0064, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1400/3000, Total Loss: 5.1526, Cost Loss: 0.0045, Constraint Loss: 0.0291, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 1500/3000, Total Loss: 13.7335, Cost Loss: -0.0137, Constraint Loss: 0.0310, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 1600/3000, Total Loss: 6.7069, Cost Loss: -0.0761, Constraint Loss: 0.0247, Integrality Loss: 0.0000, Positivity Loss: 0.0007, Avg Binary Var: 0.0667\n",
      "Iteration 1700/3000, Total Loss: 8.9237, Cost Loss: 0.0074, Constraint Loss: 0.0135, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 1800/3000, Total Loss: 7.2654, Cost Loss: 0.0109, Constraint Loss: 0.0075, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1900/3000, Total Loss: 14.2761, Cost Loss: -0.0057, Constraint Loss: 0.0453, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 2000/3000, Total Loss: 9.0591, Cost Loss: -0.0618, Constraint Loss: 0.0012, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1333\n",
      "Iteration 2100/3000, Total Loss: 6.2632, Cost Loss: -0.0255, Constraint Loss: 0.0062, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 2200/3000, Total Loss: 4.6449, Cost Loss: -0.0572, Constraint Loss: 0.0066, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1666\n",
      "Iteration 2300/3000, Total Loss: 8.6202, Cost Loss: -0.0983, Constraint Loss: 0.0832, Integrality Loss: 0.0284, Positivity Loss: 0.0013, Avg Binary Var: 0.1405\n",
      "Iteration 2400/3000, Total Loss: 11.7480, Cost Loss: 0.0044, Constraint Loss: 0.0345, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2500/3000, Total Loss: 8.7961, Cost Loss: -0.0292, Constraint Loss: 0.0058, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 2600/3000, Total Loss: 10.3806, Cost Loss: -0.0300, Constraint Loss: 0.0020, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 2700/3000, Total Loss: 33.6662, Cost Loss: -0.0291, Constraint Loss: 0.0024, Integrality Loss: 0.1444, Positivity Loss: 0.0001, Avg Binary Var: 0.1221\n",
      "Iteration 2800/3000, Total Loss: 23.2843, Cost Loss: -0.0510, Constraint Loss: 0.0007, Integrality Loss: 0.0024, Positivity Loss: 0.0003, Avg Binary Var: 0.1344\n",
      "Iteration 2900/3000, Total Loss: 13.9736, Cost Loss: -0.0256, Constraint Loss: 0.0075, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 3000/3000, Total Loss: 11.9937, Cost Loss: -0.0591, Constraint Loss: 0.0325, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1333\n",
      "\n",
      "Continuous Variables (first 30): [0.274 0.019 0.038 0.02  0.019 0.019 0.019 0.019 0.019 0.019 0.019 0.019\n",
      " 0.019 0.019 0.02  0.501 0.019 0.002 0.005 0.005 0.002 0.002 0.002 0.002\n",
      " 0.002 0.003 0.002 0.002 0.002 0.002]\n",
      "Binary/Integer Variables (remaining): [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0.]\n",
      "Optimized Cost: 0.033592248897701786\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-1.         -0.72600001  0.019       0.038       0.02        0.019\n",
      "  0.019       0.019       0.019       0.019       0.019       0.019\n",
      "  0.019       0.019       0.019       0.02       -0.49900001  0.019\n",
      "  0.002       0.005       0.005       0.002       0.002       0.002\n",
      " -0.998       0.002       0.003       0.002      -0.998       0.002\n",
      "  0.002     ]\n",
      "Equality Violations (should be close to 0): [0.11399997]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.329  0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.556  0.     0.     0.     0.\n",
      "  0.     0.     0.     0.057  0.     0.     0.     0.057  0.     0.\n",
      "  1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.     1.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.     1.    -0.    -0.    -0.     1.    -0.    -0.   ]\n",
      "Projection Objective value: 0.018877506\n",
      "Starting run 8/25\n",
      "Iteration 1/3000, Total Loss: 147.7039, Cost Loss: 2.9177, Constraint Loss: 8.8619, Integrality Loss: 0.0905, Positivity Loss: 0.0101, Avg Binary Var: 0.0940\n",
      "Iteration 100/3000, Total Loss: 9.8276, Cost Loss: 0.0849, Constraint Loss: 0.0228, Integrality Loss: 0.0002, Positivity Loss: 0.0000, Avg Binary Var: 0.1327\n",
      "Iteration 200/3000, Total Loss: 5.1728, Cost Loss: -0.0174, Constraint Loss: 0.0170, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 300/3000, Total Loss: 5.8576, Cost Loss: -0.0395, Constraint Loss: 0.0022, Integrality Loss: 0.0509, Positivity Loss: 0.0002, Avg Binary Var: 0.1448\n",
      "Iteration 400/3000, Total Loss: 17.3396, Cost Loss: -0.0392, Constraint Loss: 1.0160, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.2002\n",
      "Iteration 500/3000, Total Loss: 17.2014, Cost Loss: -0.0484, Constraint Loss: 0.9993, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.2000\n",
      "Iteration 600/3000, Total Loss: 6.3334, Cost Loss: -0.0493, Constraint Loss: 0.0065, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1335\n",
      "Iteration 700/3000, Total Loss: 11.0162, Cost Loss: -0.0481, Constraint Loss: 0.0035, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 800/3000, Total Loss: 10.1738, Cost Loss: -0.0444, Constraint Loss: 0.0300, Integrality Loss: 0.0130, Positivity Loss: 0.0002, Avg Binary Var: 0.1044\n",
      "Iteration 900/3000, Total Loss: 7.5683, Cost Loss: -0.0460, Constraint Loss: 0.0035, Integrality Loss: 0.0032, Positivity Loss: 0.0002, Avg Binary Var: 0.1647\n",
      "Iteration 1000/3000, Total Loss: 9.0166, Cost Loss: -0.0135, Constraint Loss: 0.0100, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1100/3000, Total Loss: 8.7637, Cost Loss: -0.0428, Constraint Loss: 0.0017, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1666\n",
      "Iteration 1200/3000, Total Loss: 6.0254, Cost Loss: -0.0653, Constraint Loss: 0.0305, Integrality Loss: 0.0156, Positivity Loss: 0.0004, Avg Binary Var: 0.1715\n",
      "Iteration 1300/3000, Total Loss: 10.1730, Cost Loss: 0.0032, Constraint Loss: 0.0041, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1400/3000, Total Loss: 6.9471, Cost Loss: 0.0602, Constraint Loss: 0.0745, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1666\n",
      "Iteration 1500/3000, Total Loss: 4.8819, Cost Loss: -0.0002, Constraint Loss: 0.0234, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1332\n",
      "Iteration 1600/3000, Total Loss: 5.7535, Cost Loss: -0.0571, Constraint Loss: 0.0012, Integrality Loss: 0.0008, Positivity Loss: 0.0003, Avg Binary Var: 0.1343\n",
      "Iteration 1700/3000, Total Loss: 8.3050, Cost Loss: -0.0672, Constraint Loss: 0.0164, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1667\n",
      "Iteration 1800/3000, Total Loss: 14.2881, Cost Loss: -0.0827, Constraint Loss: 0.0254, Integrality Loss: 0.0000, Positivity Loss: 0.0007, Avg Binary Var: 0.1333\n",
      "Iteration 1900/3000, Total Loss: 13.0754, Cost Loss: 0.1115, Constraint Loss: 0.1052, Integrality Loss: 0.0034, Positivity Loss: 0.0000, Avg Binary Var: 0.0979\n",
      "Iteration 2000/3000, Total Loss: 6.4148, Cost Loss: -0.0681, Constraint Loss: 0.0103, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1000\n",
      "Iteration 2100/3000, Total Loss: 4.3210, Cost Loss: -0.0213, Constraint Loss: 0.0076, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2200/3000, Total Loss: 5.6429, Cost Loss: -0.0438, Constraint Loss: 0.0015, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 2300/3000, Total Loss: 3.0142, Cost Loss: -0.0402, Constraint Loss: 0.0391, Integrality Loss: 0.0001, Positivity Loss: 0.0002, Avg Binary Var: 0.1336\n",
      "Iteration 2400/3000, Total Loss: 2.0808, Cost Loss: -0.0550, Constraint Loss: 0.0225, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.0667\n",
      "Iteration 2500/3000, Total Loss: 4.1009, Cost Loss: -0.0537, Constraint Loss: 0.0008, Integrality Loss: 0.0006, Positivity Loss: 0.0003, Avg Binary Var: 0.1658\n",
      "Iteration 2600/3000, Total Loss: 5.9528, Cost Loss: -0.0224, Constraint Loss: 0.0096, Integrality Loss: 0.0016, Positivity Loss: 0.0001, Avg Binary Var: 0.1653\n",
      "Iteration 2700/3000, Total Loss: 9.4896, Cost Loss: 0.0249, Constraint Loss: 0.0395, Integrality Loss: 0.0001, Positivity Loss: 0.0000, Avg Binary Var: 0.1330\n",
      "Iteration 2800/3000, Total Loss: 4.1608, Cost Loss: -0.0688, Constraint Loss: 0.0075, Integrality Loss: 0.0021, Positivity Loss: 0.0005, Avg Binary Var: 0.1349\n",
      "Iteration 2900/3000, Total Loss: 3.1754, Cost Loss: -0.1210, Constraint Loss: 0.0490, Integrality Loss: 0.0000, Positivity Loss: 0.0017, Avg Binary Var: 0.1667\n",
      "Iteration 3000/3000, Total Loss: 15.0961, Cost Loss: -0.0756, Constraint Loss: 0.0084, Integrality Loss: 0.0001, Positivity Loss: 0.0006, Avg Binary Var: 0.1336\n",
      "\n",
      "Continuous Variables (first 30): [ 0.006  0.006  0.006  0.257  0.313  0.123  0.258  0.006  0.009  0.006\n",
      "  0.006  0.006  0.054  0.007  0.006  0.006  0.006 -0.003 -0.001 -0.001\n",
      " -0.003 -0.003 -0.003 -0.003 -0.002 -0.002 -0.003 -0.003 -0.003 -0.003]\n",
      "Binary/Integer Variables (remaining): [0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Optimized Cost: -0.030501221625180305\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [ 0.          0.006       0.006       0.006      -0.743      -0.68700001\n",
      " -0.877      -0.74200001  0.006       0.009       0.006       0.006\n",
      "  0.006      -0.946       0.007       0.006       0.006       0.006\n",
      " -0.003      -0.001      -0.001      -0.003      -0.003      -0.003\n",
      " -0.003      -0.002      -0.002      -0.003      -0.003      -0.003\n",
      " -0.003     ]\n",
      "Equality Violations (should be close to 0): [0.04799998]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.     0.256  0.312  0.122  0.257  0.     0.     0.\n",
      "  0.     0.     0.053  0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.    -0.    -0.     1.     1.     1.     1.    -0.    -0.    -0.\n",
      " -0.    -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.00058555603\n",
      "Starting run 9/25\n",
      "Iteration 1/3000, Total Loss: 212.8679, Cost Loss: 4.3548, Constraint Loss: 15.3440, Integrality Loss: 0.0602, Positivity Loss: 0.0000, Avg Binary Var: 0.0728\n",
      "Iteration 100/3000, Total Loss: 11.4932, Cost Loss: 0.0271, Constraint Loss: 0.0319, Integrality Loss: 0.0001, Positivity Loss: 0.0000, Avg Binary Var: 0.0670\n",
      "Iteration 200/3000, Total Loss: 6.4681, Cost Loss: -0.0346, Constraint Loss: 0.0034, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1666\n",
      "Iteration 300/3000, Total Loss: 6.0014, Cost Loss: -0.0349, Constraint Loss: 0.0036, Integrality Loss: 0.0002, Positivity Loss: 0.0001, Avg Binary Var: 0.0672\n",
      "Iteration 400/3000, Total Loss: 5.7712, Cost Loss: -0.0356, Constraint Loss: 0.0009, Integrality Loss: 0.0520, Positivity Loss: 0.0001, Avg Binary Var: 0.1450\n",
      "Iteration 500/3000, Total Loss: 4.1638, Cost Loss: -0.0449, Constraint Loss: 0.0011, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1332\n",
      "Iteration 600/3000, Total Loss: 7.8152, Cost Loss: -0.0431, Constraint Loss: 0.0022, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 700/3000, Total Loss: 8.2771, Cost Loss: -0.0244, Constraint Loss: 0.0084, Integrality Loss: 0.0001, Positivity Loss: 0.0001, Avg Binary Var: 0.1330\n",
      "Iteration 800/3000, Total Loss: 5.0221, Cost Loss: -0.0446, Constraint Loss: 0.0012, Integrality Loss: 0.0144, Positivity Loss: 0.0002, Avg Binary Var: 0.1287\n",
      "Iteration 900/3000, Total Loss: 7.3147, Cost Loss: -0.0497, Constraint Loss: 0.0069, Integrality Loss: 0.0618, Positivity Loss: 0.0015, Avg Binary Var: 0.1488\n",
      "Iteration 1000/3000, Total Loss: 4.8803, Cost Loss: -0.0430, Constraint Loss: 0.0021, Integrality Loss: 0.0361, Positivity Loss: 0.0002, Avg Binary Var: 0.0582\n",
      "Iteration 1100/3000, Total Loss: 6.4217, Cost Loss: -0.0460, Constraint Loss: 0.0008, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1666\n",
      "Iteration 1200/3000, Total Loss: 8.5572, Cost Loss: -0.0303, Constraint Loss: 0.0013, Integrality Loss: 0.0313, Positivity Loss: 0.0001, Avg Binary Var: 0.1590\n",
      "Iteration 1300/3000, Total Loss: 11.1203, Cost Loss: -0.0544, Constraint Loss: 0.0197, Integrality Loss: 0.0007, Positivity Loss: 0.0003, Avg Binary Var: 0.1342\n",
      "Iteration 1400/3000, Total Loss: 9.5011, Cost Loss: -0.0500, Constraint Loss: 0.0008, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1500/3000, Total Loss: 5.1719, Cost Loss: -0.0987, Constraint Loss: 0.0358, Integrality Loss: 0.0000, Positivity Loss: 0.0011, Avg Binary Var: 0.1667\n",
      "Iteration 1600/3000, Total Loss: 10.7202, Cost Loss: -0.0182, Constraint Loss: 0.0115, Integrality Loss: 0.0002, Positivity Loss: 0.0000, Avg Binary Var: 0.1004\n",
      "Iteration 1700/3000, Total Loss: 12.0888, Cost Loss: -0.0317, Constraint Loss: 0.0077, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 1800/3000, Total Loss: 14.1177, Cost Loss: 0.0440, Constraint Loss: 0.0267, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 1900/3000, Total Loss: 7.8998, Cost Loss: 0.1895, Constraint Loss: 0.0376, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0667\n",
      "Iteration 2000/3000, Total Loss: 6.1831, Cost Loss: 0.3614, Constraint Loss: 0.0811, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0333\n",
      "Iteration 2100/3000, Total Loss: 6.3501, Cost Loss: -0.0621, Constraint Loss: 0.0735, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1333\n",
      "Iteration 2200/3000, Total Loss: 3.5973, Cost Loss: 0.0370, Constraint Loss: 0.0461, Integrality Loss: 0.0238, Positivity Loss: 0.0000, Avg Binary Var: 0.0936\n",
      "Iteration 2300/3000, Total Loss: 5.4617, Cost Loss: -0.0540, Constraint Loss: 0.0020, Integrality Loss: 0.0006, Positivity Loss: 0.0003, Avg Binary Var: 0.1324\n",
      "Iteration 2400/3000, Total Loss: 4.5884, Cost Loss: 0.0053, Constraint Loss: 0.0573, Integrality Loss: 0.0007, Positivity Loss: 0.0000, Avg Binary Var: 0.1324\n",
      "Iteration 2500/3000, Total Loss: 9.2871, Cost Loss: -0.0510, Constraint Loss: 0.0053, Integrality Loss: 0.0104, Positivity Loss: 0.0003, Avg Binary Var: 0.1628\n",
      "Iteration 2600/3000, Total Loss: 9.5836, Cost Loss: -0.0133, Constraint Loss: 0.0033, Integrality Loss: 0.0003, Positivity Loss: 0.0000, Avg Binary Var: 0.1327\n",
      "Iteration 2700/3000, Total Loss: 4.8645, Cost Loss: -0.0545, Constraint Loss: 0.0028, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1000\n",
      "Iteration 2800/3000, Total Loss: 8.6394, Cost Loss: -0.0462, Constraint Loss: 0.0351, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1667\n",
      "Iteration 2900/3000, Total Loss: 6.2308, Cost Loss: -0.0241, Constraint Loss: 0.0073, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 3000/3000, Total Loss: 7.1203, Cost Loss: -0.0825, Constraint Loss: 0.0581, Integrality Loss: 0.0000, Positivity Loss: 0.0008, Avg Binary Var: 0.1667\n",
      "\n",
      "Continuous Variables (first 30): [0.011 0.011 0.054 0.011 0.011 0.011 0.198 0.012 0.311 0.011 0.01  0.284\n",
      " 0.011 0.011 0.011 0.011 0.132 0.002 0.005 0.005 0.002 0.002 0.002 0.002\n",
      " 0.002 0.004 0.002 0.002 0.002 0.002]\n",
      "Binary/Integer Variables (remaining): [0.    0.    1.    0.    0.    0.    0.996 0.    1.    0.    0.    1.\n",
      " 0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.   ]\n",
      "Optimized Cost: 0.035269974028513215\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-0.00400001  0.011       0.011      -0.946       0.011       0.011\n",
      "  0.011      -0.79799999  0.012      -0.68900001  0.011       0.01\n",
      " -0.71599999  0.011       0.011       0.011       0.011      -0.868\n",
      "  0.002       0.005       0.005       0.002       0.002       0.002\n",
      "  0.002       0.002       0.004       0.002       0.002       0.002\n",
      "  0.002     ]\n",
      "Equality Violations (should be close to 0): [0.145]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.058  0.     0.     0.     0.202  0.     0.315  0.\n",
      "  0.     0.288  0.     0.     0.     0.     0.136  0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.    -0.     1.    -0.    -0.    -0.     1.    -0.     1.    -0.\n",
      " -0.     1.    -0.    -0.    -0.    -0.     1.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.0016646385\n",
      "Starting run 10/25\n",
      "Iteration 1/3000, Total Loss: 211.3377, Cost Loss: 4.0113, Constraint Loss: 15.2662, Integrality Loss: 0.0108, Positivity Loss: 0.0003, Avg Binary Var: 0.1282\n",
      "Iteration 100/3000, Total Loss: 11.6951, Cost Loss: 0.0185, Constraint Loss: 0.0592, Integrality Loss: 0.0271, Positivity Loss: 0.0000, Avg Binary Var: 0.0614\n",
      "Iteration 200/3000, Total Loss: 6.4181, Cost Loss: -0.0063, Constraint Loss: 0.0252, Integrality Loss: 0.0348, Positivity Loss: 0.0000, Avg Binary Var: 0.0917\n",
      "Iteration 300/3000, Total Loss: 16.9751, Cost Loss: -0.0340, Constraint Loss: 0.9997, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1999\n",
      "Iteration 400/3000, Total Loss: 6.3577, Cost Loss: -0.0394, Constraint Loss: 0.0028, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 500/3000, Total Loss: 8.0939, Cost Loss: -0.0221, Constraint Loss: 0.0108, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1001\n",
      "Iteration 600/3000, Total Loss: 5.8717, Cost Loss: -0.0255, Constraint Loss: 0.0076, Integrality Loss: 0.0001, Positivity Loss: 0.0001, Avg Binary Var: 0.0670\n",
      "Iteration 700/3000, Total Loss: 7.1628, Cost Loss: -0.0451, Constraint Loss: 0.0010, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 800/3000, Total Loss: 5.0944, Cost Loss: -0.0354, Constraint Loss: 0.0025, Integrality Loss: 0.0049, Positivity Loss: 0.0001, Avg Binary Var: 0.1025\n",
      "Iteration 900/3000, Total Loss: 4.4429, Cost Loss: -0.0456, Constraint Loss: 0.0032, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1000/3000, Total Loss: 4.4634, Cost Loss: -0.0462, Constraint Loss: 0.0009, Integrality Loss: 0.0001, Positivity Loss: 0.0002, Avg Binary Var: 0.0996\n",
      "Iteration 1100/3000, Total Loss: 2.3589, Cost Loss: -0.0443, Constraint Loss: 0.0020, Integrality Loss: 0.0067, Positivity Loss: 0.0002, Avg Binary Var: 0.0970\n",
      "Iteration 1200/3000, Total Loss: 4.2031, Cost Loss: -0.0449, Constraint Loss: 0.0018, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1300/3000, Total Loss: 9.9821, Cost Loss: -0.0431, Constraint Loss: 0.0053, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1400/3000, Total Loss: 18.9908, Cost Loss: -0.0496, Constraint Loss: 0.9892, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1998\n",
      "Iteration 1500/3000, Total Loss: 11.3686, Cost Loss: -0.0539, Constraint Loss: 0.0010, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1333\n",
      "Iteration 1600/3000, Total Loss: 9.2041, Cost Loss: 0.0249, Constraint Loss: 0.0185, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1700/3000, Total Loss: 6.9571, Cost Loss: 0.0056, Constraint Loss: 0.0234, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1666\n",
      "Iteration 1800/3000, Total Loss: 10.6062, Cost Loss: -0.0539, Constraint Loss: 0.0015, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1667\n",
      "Iteration 1900/3000, Total Loss: 16.3976, Cost Loss: -0.0748, Constraint Loss: 0.0464, Integrality Loss: 0.0000, Positivity Loss: 0.0007, Avg Binary Var: 0.1333\n",
      "Iteration 2000/3000, Total Loss: 11.5239, Cost Loss: 0.0775, Constraint Loss: 0.0579, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2100/3000, Total Loss: 7.2974, Cost Loss: -0.0552, Constraint Loss: 0.0441, Integrality Loss: 0.0055, Positivity Loss: 0.0004, Avg Binary Var: 0.0640\n",
      "Iteration 2200/3000, Total Loss: 14.2810, Cost Loss: -0.0496, Constraint Loss: 0.0016, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 2300/3000, Total Loss: 11.1208, Cost Loss: -0.0180, Constraint Loss: 0.0254, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 2400/3000, Total Loss: 18.7747, Cost Loss: 0.0438, Constraint Loss: 0.0296, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2500/3000, Total Loss: 13.1476, Cost Loss: -0.1193, Constraint Loss: 0.1406, Integrality Loss: 0.0065, Positivity Loss: 0.0018, Avg Binary Var: 0.1030\n",
      "Iteration 2600/3000, Total Loss: 11.3954, Cost Loss: -0.1067, Constraint Loss: 0.0264, Integrality Loss: 0.0000, Positivity Loss: 0.0012, Avg Binary Var: 0.1333\n",
      "Iteration 2700/3000, Total Loss: 17.0131, Cost Loss: 0.0047, Constraint Loss: 0.0149, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1666\n",
      "Iteration 2800/3000, Total Loss: 14.6918, Cost Loss: -0.0670, Constraint Loss: 0.0361, Integrality Loss: 0.0012, Positivity Loss: 0.0005, Avg Binary Var: 0.1655\n",
      "Iteration 2900/3000, Total Loss: 9.5995, Cost Loss: -0.0085, Constraint Loss: 0.0315, Integrality Loss: 0.0476, Positivity Loss: 0.0000, Avg Binary Var: 0.0774\n",
      "Iteration 3000/3000, Total Loss: 8.2543, Cost Loss: -0.0706, Constraint Loss: 0.0546, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1667\n",
      "\n",
      "Continuous Variables (first 30): [0.021 0.021 0.021 0.021 0.033 0.021 0.021 0.462 0.021 0.021 0.021 0.021\n",
      " 0.021 0.021 0.021 0.021 0.297 0.003 0.006 0.007 0.003 0.003 0.003 0.003\n",
      " 0.004 0.005 0.003 0.003 0.003 0.004]\n",
      "Binary/Integer Variables (remaining): [0.    0.    0.    0.    1.    0.    0.    1.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    1.    0.    0.    0.985 0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    1.   ]\n",
      "Optimized Cost: 0.05078885555679373\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-0.01499999  0.021       0.021       0.021       0.021      -0.967\n",
      "  0.021       0.021      -0.53799999  0.021       0.021       0.021\n",
      "  0.021       0.021       0.021       0.021       0.021      -0.70300001\n",
      "  0.003       0.006      -0.97800001  0.003       0.003       0.003\n",
      "  0.003       0.004       0.005       0.003       0.003       0.003\n",
      " -0.996     ]\n",
      "Equality Violations (should be close to 0): [0.136]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.     0.     0.072  0.     0.     0.501  0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.336  0.     0.     0.046\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.043\n",
      " -0.    -0.    -0.    -0.     1.    -0.    -0.     1.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.     1.    -0.    -0.     1.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.     1.   ]\n",
      "Projection Objective value: 0.014309883\n",
      "Starting run 11/25\n",
      "Iteration 1/3000, Total Loss: 176.9135, Cost Loss: 2.9310, Constraint Loss: 11.9652, Integrality Loss: 0.0086, Positivity Loss: 0.0005, Avg Binary Var: 0.1349\n",
      "Iteration 100/3000, Total Loss: 9.9170, Cost Loss: 0.1634, Constraint Loss: 0.0285, Integrality Loss: 0.0067, Positivity Loss: 0.0000, Avg Binary Var: 0.1303\n",
      "Iteration 200/3000, Total Loss: 5.3133, Cost Loss: -0.0140, Constraint Loss: 0.0171, Integrality Loss: 0.0018, Positivity Loss: 0.0000, Avg Binary Var: 0.1318\n",
      "Iteration 300/3000, Total Loss: 7.5052, Cost Loss: -0.0351, Constraint Loss: 0.0050, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 400/3000, Total Loss: 3.6900, Cost Loss: -0.0369, Constraint Loss: 0.0028, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 500/3000, Total Loss: 7.3482, Cost Loss: -0.0474, Constraint Loss: 0.0007, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1666\n",
      "Iteration 600/3000, Total Loss: 6.2524, Cost Loss: -0.0415, Constraint Loss: 0.0013, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 700/3000, Total Loss: 7.4793, Cost Loss: -0.0479, Constraint Loss: 0.0007, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1001\n",
      "Iteration 800/3000, Total Loss: 6.6076, Cost Loss: -0.0423, Constraint Loss: 0.0016, Integrality Loss: 0.0084, Positivity Loss: 0.0002, Avg Binary Var: 0.1367\n",
      "Iteration 900/3000, Total Loss: 9.6211, Cost Loss: -0.0445, Constraint Loss: 0.0059, Integrality Loss: 0.0032, Positivity Loss: 0.0002, Avg Binary Var: 0.1352\n",
      "Iteration 1000/3000, Total Loss: 7.5388, Cost Loss: -0.0373, Constraint Loss: 0.0037, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 1100/3000, Total Loss: 4.2556, Cost Loss: -0.0417, Constraint Loss: 0.0014, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1200/3000, Total Loss: 4.9419, Cost Loss: -0.0457, Constraint Loss: 0.0017, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1300/3000, Total Loss: 4.4959, Cost Loss: -0.0024, Constraint Loss: 0.0173, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1001\n",
      "Iteration 1400/3000, Total Loss: 14.8003, Cost Loss: -0.0047, Constraint Loss: 0.0213, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 1500/3000, Total Loss: 10.2013, Cost Loss: -0.0218, Constraint Loss: 0.0056, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 1600/3000, Total Loss: 6.6576, Cost Loss: -0.0557, Constraint Loss: 0.0081, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1000\n",
      "Iteration 1700/3000, Total Loss: 7.4355, Cost Loss: -0.0211, Constraint Loss: 0.0016, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1800/3000, Total Loss: 6.2982, Cost Loss: -0.0553, Constraint Loss: 0.0012, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1333\n",
      "Iteration 1900/3000, Total Loss: 6.2683, Cost Loss: -0.0779, Constraint Loss: 0.0128, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1667\n",
      "Iteration 2000/3000, Total Loss: 18.3482, Cost Loss: -0.0622, Constraint Loss: 0.0069, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1665\n",
      "Iteration 2100/3000, Total Loss: 14.8159, Cost Loss: -0.0889, Constraint Loss: 0.0487, Integrality Loss: 0.0000, Positivity Loss: 0.0009, Avg Binary Var: 0.1667\n",
      "Iteration 2200/3000, Total Loss: 17.3427, Cost Loss: -0.0485, Constraint Loss: 0.0028, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 2300/3000, Total Loss: 9.4126, Cost Loss: 0.0087, Constraint Loss: 0.0202, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0667\n",
      "Iteration 2400/3000, Total Loss: 7.1430, Cost Loss: -0.0552, Constraint Loss: 0.0020, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1000\n",
      "Iteration 2500/3000, Total Loss: 7.4404, Cost Loss: 0.0092, Constraint Loss: 0.0310, Integrality Loss: 0.0003, Positivity Loss: 0.0000, Avg Binary Var: 0.0995\n",
      "Iteration 2600/3000, Total Loss: 4.9834, Cost Loss: -0.0352, Constraint Loss: 0.0022, Integrality Loss: 0.0055, Positivity Loss: 0.0001, Avg Binary Var: 0.1027\n",
      "Iteration 2700/3000, Total Loss: 6.1213, Cost Loss: -0.0239, Constraint Loss: 0.0046, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 2800/3000, Total Loss: 13.7557, Cost Loss: -0.0435, Constraint Loss: 0.0032, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1664\n",
      "Iteration 2900/3000, Total Loss: 5.5059, Cost Loss: -0.0369, Constraint Loss: 0.0106, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 3000/3000, Total Loss: 6.5259, Cost Loss: -0.0680, Constraint Loss: 0.0044, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1667\n",
      "\n",
      "Continuous Variables (first 30): [ 0.008  0.008  0.596  0.124  0.008  0.242  0.008  0.008  0.008  0.008\n",
      "  0.008  0.008  0.009  0.008  0.008  0.008  0.008 -0.003 -0.003 -0.003\n",
      " -0.003 -0.003 -0.003 -0.003 -0.003 -0.003 -0.003 -0.003 -0.003 -0.003]\n",
      "Binary/Integer Variables (remaining): [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0.]\n",
      "Optimized Cost: -0.035010650561828845\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [ 0.          0.008       0.008      -0.40399998 -0.876       0.008\n",
      " -0.758       0.008       0.008       0.008       0.008       0.008\n",
      "  0.008       0.009       0.008       0.008       0.008       0.008\n",
      " -0.003      -0.003      -0.003      -1.003      -0.003      -0.003\n",
      " -0.003      -0.003      -0.003      -0.003      -0.003      -1.003\n",
      " -0.003     ]\n",
      "Equality Violations (should be close to 0): [0.03600002]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.605  0.133  0.     0.251  0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.006  0.     0.     0.     0.     0.     0.     0.     0.006  0.\n",
      " -0.    -0.     1.     1.    -0.     1.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      "  1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.     1.    -0.   ]\n",
      "Projection Objective value: 0.0013995171\n",
      "Starting run 12/25\n",
      "Iteration 1/3000, Total Loss: 167.9876, Cost Loss: 2.9220, Constraint Loss: 10.9927, Integrality Loss: 0.0607, Positivity Loss: 0.0022, Avg Binary Var: 0.0188\n",
      "Iteration 100/3000, Total Loss: 10.7735, Cost Loss: 0.0802, Constraint Loss: 0.0343, Integrality Loss: 0.0934, Positivity Loss: 0.0000, Avg Binary Var: 0.0551\n",
      "Iteration 200/3000, Total Loss: 5.6849, Cost Loss: -0.0088, Constraint Loss: 0.0109, Integrality Loss: 0.0189, Positivity Loss: 0.0001, Avg Binary Var: 0.1388\n",
      "Iteration 300/3000, Total Loss: 4.2164, Cost Loss: -0.0388, Constraint Loss: 0.0027, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1334\n",
      "Iteration 400/3000, Total Loss: 6.7068, Cost Loss: -0.0364, Constraint Loss: 0.1809, Integrality Loss: 0.0002, Positivity Loss: 0.0001, Avg Binary Var: 0.1005\n",
      "Iteration 500/3000, Total Loss: 5.9867, Cost Loss: -0.0403, Constraint Loss: 0.0014, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 600/3000, Total Loss: 3.7021, Cost Loss: -0.0474, Constraint Loss: 0.0008, Integrality Loss: 0.0008, Positivity Loss: 0.0002, Avg Binary Var: 0.1343\n",
      "Iteration 700/3000, Total Loss: 2.7792, Cost Loss: -0.0289, Constraint Loss: 0.0038, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 800/3000, Total Loss: 3.6375, Cost Loss: -0.0276, Constraint Loss: 0.0124, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 900/3000, Total Loss: 17.3062, Cost Loss: -0.0321, Constraint Loss: 0.0049, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 1000/3000, Total Loss: 15.5632, Cost Loss: -0.0368, Constraint Loss: 0.0078, Integrality Loss: 0.0097, Positivity Loss: 0.0001, Avg Binary Var: 0.1370\n",
      "Iteration 1100/3000, Total Loss: 12.5744, Cost Loss: -0.0472, Constraint Loss: 0.0007, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 1200/3000, Total Loss: 11.5157, Cost Loss: -0.0527, Constraint Loss: 0.1360, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1000\n",
      "Iteration 1300/3000, Total Loss: 7.9077, Cost Loss: 0.0482, Constraint Loss: 0.0314, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1400/3000, Total Loss: 6.0698, Cost Loss: 0.0408, Constraint Loss: 0.0246, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1500/3000, Total Loss: 6.8952, Cost Loss: 0.0207, Constraint Loss: 0.0439, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 1600/3000, Total Loss: 4.9494, Cost Loss: 0.0125, Constraint Loss: 0.0249, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 1700/3000, Total Loss: 13.1533, Cost Loss: -0.0741, Constraint Loss: 0.0092, Integrality Loss: 0.0003, Positivity Loss: 0.0006, Avg Binary Var: 0.1339\n",
      "Iteration 1800/3000, Total Loss: 7.9727, Cost Loss: -0.0249, Constraint Loss: 0.0045, Integrality Loss: 0.0433, Positivity Loss: 0.0001, Avg Binary Var: 0.1289\n",
      "Iteration 1900/3000, Total Loss: 6.7772, Cost Loss: -0.0502, Constraint Loss: 0.0531, Integrality Loss: 0.0001, Positivity Loss: 0.0002, Avg Binary Var: 0.1003\n",
      "Iteration 2000/3000, Total Loss: 4.4145, Cost Loss: -0.0187, Constraint Loss: 0.0106, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 2100/3000, Total Loss: 3.0667, Cost Loss: -0.0220, Constraint Loss: 0.0136, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1332\n",
      "Iteration 2200/3000, Total Loss: 2.4921, Cost Loss: -0.0431, Constraint Loss: 0.0031, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 2300/3000, Total Loss: 11.0924, Cost Loss: -0.0469, Constraint Loss: 0.0033, Integrality Loss: 0.0058, Positivity Loss: 0.0002, Avg Binary Var: 0.1639\n",
      "Iteration 2400/3000, Total Loss: 5.7882, Cost Loss: -0.0004, Constraint Loss: 0.0277, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2500/3000, Total Loss: 5.8907, Cost Loss: -0.0285, Constraint Loss: 0.0011, Integrality Loss: 0.0002, Positivity Loss: 0.0001, Avg Binary Var: 0.1339\n",
      "Iteration 2600/3000, Total Loss: 4.1211, Cost Loss: 0.0446, Constraint Loss: 0.0628, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2700/3000, Total Loss: 7.1036, Cost Loss: -0.0338, Constraint Loss: 0.0835, Integrality Loss: 0.0413, Positivity Loss: 0.0001, Avg Binary Var: 0.1239\n",
      "Iteration 2800/3000, Total Loss: 11.3344, Cost Loss: 0.0909, Constraint Loss: 0.0420, Integrality Loss: 0.0004, Positivity Loss: 0.0000, Avg Binary Var: 0.1340\n",
      "Iteration 2900/3000, Total Loss: 7.4206, Cost Loss: 0.0030, Constraint Loss: 0.0267, Integrality Loss: 0.0026, Positivity Loss: 0.0000, Avg Binary Var: 0.1313\n",
      "Iteration 3000/3000, Total Loss: 4.9051, Cost Loss: 0.0043, Constraint Loss: 0.0231, Integrality Loss: 0.0536, Positivity Loss: 0.0000, Avg Binary Var: 0.1454\n",
      "\n",
      "Continuous Variables (first 30): [ 0.014  0.015  0.015  0.015  0.015  0.015  0.015  0.015  0.015  0.741\n",
      "  0.015  0.015  0.015  0.015  0.014  0.015  0.015 -0.006 -0.005 -0.006\n",
      " -0.006 -0.006 -0.006 -0.006 -0.006 -0.005 -0.006 -0.006 -0.006 -0.006]\n",
      "Binary/Integer Variables (remaining): [0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.002 0.    0.    0.    0.    0.004 0.\n",
      " 0.    0.    0.    0.996 0.992 0.   ]\n",
      "Optimized Cost: -0.06289315895543304\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-2.00600002  0.014       0.015       0.015       0.015       0.015\n",
      "  0.015       0.015       0.015       0.015      -0.259       0.015\n",
      "  0.015       0.015       0.015       0.014       0.015       0.015\n",
      " -0.008      -0.005      -0.006      -0.006      -0.006      -0.01\n",
      " -0.006      -0.006      -0.005      -0.006      -1.00199999 -0.99799998\n",
      " -0.006     ]\n",
      "Equality Violations (should be close to 0): [-0.09700001]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.831\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.084  0.084  0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.     1.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.     1.     1.    -0.   ]\n",
      "Projection Objective value: 0.028496504\n",
      "Starting run 13/25\n",
      "Iteration 1/3000, Total Loss: 266.3225, Cost Loss: 5.0734, Constraint Loss: 20.6826, Integrality Loss: 0.0278, Positivity Loss: 0.0001, Avg Binary Var: 0.0596\n",
      "Iteration 100/3000, Total Loss: 10.9726, Cost Loss: 0.0032, Constraint Loss: 0.0256, Integrality Loss: 0.0004, Positivity Loss: 0.0000, Avg Binary Var: 0.1007\n",
      "Iteration 200/3000, Total Loss: 15.9785, Cost Loss: -0.0447, Constraint Loss: 0.8916, Integrality Loss: 0.0028, Positivity Loss: 0.0002, Avg Binary Var: 0.1981\n",
      "Iteration 300/3000, Total Loss: 6.3016, Cost Loss: -0.0428, Constraint Loss: 0.0033, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 400/3000, Total Loss: 3.3913, Cost Loss: -0.0304, Constraint Loss: 0.0051, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 500/3000, Total Loss: 4.0878, Cost Loss: -0.0398, Constraint Loss: 0.0022, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 600/3000, Total Loss: 6.5305, Cost Loss: -0.0391, Constraint Loss: 0.1022, Integrality Loss: 0.0191, Positivity Loss: 0.0002, Avg Binary Var: 0.0722\n",
      "Iteration 700/3000, Total Loss: 6.8322, Cost Loss: -0.0439, Constraint Loss: 0.0019, Integrality Loss: 0.0095, Positivity Loss: 0.0002, Avg Binary Var: 0.0964\n",
      "Iteration 800/3000, Total Loss: 4.2319, Cost Loss: -0.0425, Constraint Loss: 0.0026, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 900/3000, Total Loss: 4.4663, Cost Loss: -0.0481, Constraint Loss: 0.0005, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 1000/3000, Total Loss: 11.5058, Cost Loss: -0.0507, Constraint Loss: 0.0009, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1332\n",
      "Iteration 1100/3000, Total Loss: 6.4918, Cost Loss: -0.0535, Constraint Loss: 0.0017, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1667\n",
      "Iteration 1200/3000, Total Loss: 18.1327, Cost Loss: -0.0412, Constraint Loss: 0.0029, Integrality Loss: 0.0002, Positivity Loss: 0.0002, Avg Binary Var: 0.1339\n",
      "Iteration 1300/3000, Total Loss: 14.9745, Cost Loss: -0.0498, Constraint Loss: 0.0006, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1400/3000, Total Loss: 13.5942, Cost Loss: -0.0429, Constraint Loss: 0.0018, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1500/3000, Total Loss: 10.8487, Cost Loss: -0.0440, Constraint Loss: 0.0016, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1600/3000, Total Loss: 6.7941, Cost Loss: -0.0451, Constraint Loss: 0.0013, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.0998\n",
      "Iteration 1700/3000, Total Loss: 5.7732, Cost Loss: -0.0883, Constraint Loss: 0.0672, Integrality Loss: 0.0144, Positivity Loss: 0.0009, Avg Binary Var: 0.0713\n",
      "Iteration 1800/3000, Total Loss: 7.6328, Cost Loss: 0.0038, Constraint Loss: 0.0155, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1332\n",
      "Iteration 1900/3000, Total Loss: 5.7159, Cost Loss: 0.0237, Constraint Loss: 0.0405, Integrality Loss: 0.0023, Positivity Loss: 0.0000, Avg Binary Var: 0.1316\n",
      "Iteration 2000/3000, Total Loss: 4.2585, Cost Loss: -0.0640, Constraint Loss: 0.0272, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1000\n",
      "Iteration 2100/3000, Total Loss: 2.6901, Cost Loss: -0.0387, Constraint Loss: 0.0062, Integrality Loss: 0.0353, Positivity Loss: 0.0002, Avg Binary Var: 0.0583\n",
      "Iteration 2200/3000, Total Loss: 5.3306, Cost Loss: -0.0870, Constraint Loss: 0.0240, Integrality Loss: 0.0001, Positivity Loss: 0.0008, Avg Binary Var: 0.1330\n",
      "Iteration 2300/3000, Total Loss: 3.4008, Cost Loss: -0.0091, Constraint Loss: 0.0347, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 2400/3000, Total Loss: 9.1104, Cost Loss: -0.0297, Constraint Loss: 0.0050, Integrality Loss: 0.0357, Positivity Loss: 0.0001, Avg Binary Var: 0.1251\n",
      "Iteration 2500/3000, Total Loss: 2.3848, Cost Loss: -0.0376, Constraint Loss: 0.0125, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 2600/3000, Total Loss: 8.6793, Cost Loss: 0.0132, Constraint Loss: 0.0500, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2700/3000, Total Loss: 6.1140, Cost Loss: -0.0403, Constraint Loss: 0.0048, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 2800/3000, Total Loss: 6.9925, Cost Loss: -0.0647, Constraint Loss: 0.0149, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1002\n",
      "Iteration 2900/3000, Total Loss: 6.3351, Cost Loss: -0.0894, Constraint Loss: 0.0381, Integrality Loss: 0.0035, Positivity Loss: 0.0009, Avg Binary Var: 0.1646\n",
      "Iteration 3000/3000, Total Loss: 6.8612, Cost Loss: -0.0230, Constraint Loss: 0.0150, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "\n",
      "Continuous Variables (first 30): [ 0.004  0.185  0.004  0.405  0.004  0.004  0.004  0.231  0.004  0.003\n",
      "  0.004  0.129  0.003  0.003  0.004  0.004  0.004 -0.008 -0.006 -0.006\n",
      " -0.008 -0.008 -0.008 -0.008 -0.008 -0.007 -0.008 -0.008 -0.008 -0.008]\n",
      "Binary/Integer Variables (remaining): [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Optimized Cost: -0.08384889528738332\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-1.          0.004      -0.815       0.004      -0.595       0.004\n",
      "  0.004       0.004      -0.76899999  0.004       0.003       0.004\n",
      " -0.87100001  0.003       0.003       0.004       0.004       0.004\n",
      " -0.008      -0.006      -0.006      -0.008      -0.008      -0.008\n",
      " -0.008      -0.008      -0.007      -0.008      -0.008      -0.008\n",
      " -0.008     ]\n",
      "Equality Violations (should be close to 0): [-0.1]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.198  0.     0.418  0.     0.     0.     0.244  0.     0.\n",
      "  0.     0.141  0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.     1.    -0.     1.    -0.    -0.    -0.     1.    -0.    -0.\n",
      " -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.0015730858\n",
      "Starting run 14/25\n",
      "Iteration 1/3000, Total Loss: 281.5516, Cost Loss: 5.1206, Constraint Loss: 22.1735, Integrality Loss: 0.0064, Positivity Loss: 0.0028, Avg Binary Var: 0.0658\n",
      "Iteration 100/3000, Total Loss: 11.4837, Cost Loss: 0.1165, Constraint Loss: 0.0303, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0667\n",
      "Iteration 200/3000, Total Loss: 8.1164, Cost Loss: -0.0180, Constraint Loss: 0.0172, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 300/3000, Total Loss: 8.2349, Cost Loss: -0.0233, Constraint Loss: 0.0113, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.0333\n",
      "Iteration 400/3000, Total Loss: 7.0338, Cost Loss: -0.0442, Constraint Loss: 0.0017, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 500/3000, Total Loss: 8.5394, Cost Loss: -0.0355, Constraint Loss: 0.0047, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1331\n",
      "Iteration 600/3000, Total Loss: 9.3043, Cost Loss: -0.0209, Constraint Loss: 0.0124, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 700/3000, Total Loss: 5.6091, Cost Loss: -0.0403, Constraint Loss: 0.0024, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.0667\n",
      "Iteration 800/3000, Total Loss: 4.2282, Cost Loss: -0.0415, Constraint Loss: 0.0024, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 900/3000, Total Loss: 5.0708, Cost Loss: -0.0445, Constraint Loss: 0.0044, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.0667\n",
      "Iteration 1000/3000, Total Loss: 6.2255, Cost Loss: -0.0425, Constraint Loss: 0.0019, Integrality Loss: 0.0002, Positivity Loss: 0.0002, Avg Binary Var: 0.1005\n",
      "Iteration 1100/3000, Total Loss: 3.5198, Cost Loss: -0.0439, Constraint Loss: 0.0008, Integrality Loss: 0.0002, Positivity Loss: 0.0002, Avg Binary Var: 0.1660\n",
      "Iteration 1200/3000, Total Loss: 6.2427, Cost Loss: -0.0377, Constraint Loss: 0.0060, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.0666\n",
      "Iteration 1300/3000, Total Loss: 12.0856, Cost Loss: -0.0406, Constraint Loss: 0.0020, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1400/3000, Total Loss: 13.3047, Cost Loss: -0.0343, Constraint Loss: 0.0024, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 1500/3000, Total Loss: 10.8015, Cost Loss: -0.0407, Constraint Loss: 0.0029, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1600/3000, Total Loss: 7.5788, Cost Loss: -0.0479, Constraint Loss: 0.0008, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1700/3000, Total Loss: 11.2377, Cost Loss: -0.0551, Constraint Loss: 0.0088, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1333\n",
      "Iteration 1800/3000, Total Loss: 12.7612, Cost Loss: -0.0270, Constraint Loss: 0.0067, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 1900/3000, Total Loss: 9.6896, Cost Loss: -0.1228, Constraint Loss: 0.0442, Integrality Loss: 0.0000, Positivity Loss: 0.0017, Avg Binary Var: 0.1000\n",
      "Iteration 2000/3000, Total Loss: 5.8019, Cost Loss: -0.0692, Constraint Loss: 0.0173, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1000\n",
      "Iteration 2100/3000, Total Loss: 9.4390, Cost Loss: -0.0849, Constraint Loss: 0.0346, Integrality Loss: 0.0000, Positivity Loss: 0.0008, Avg Binary Var: 0.1666\n",
      "Iteration 2200/3000, Total Loss: 8.4840, Cost Loss: -0.0330, Constraint Loss: 0.0095, Integrality Loss: 0.0003, Positivity Loss: 0.0001, Avg Binary Var: 0.0994\n",
      "Iteration 2300/3000, Total Loss: 7.9321, Cost Loss: -0.0439, Constraint Loss: 0.0036, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 2400/3000, Total Loss: 5.2441, Cost Loss: -0.0791, Constraint Loss: 0.0355, Integrality Loss: 0.0180, Positivity Loss: 0.0007, Avg Binary Var: 0.1053\n",
      "Iteration 2500/3000, Total Loss: 4.5849, Cost Loss: 0.0293, Constraint Loss: 0.0585, Integrality Loss: 0.0001, Positivity Loss: 0.0000, Avg Binary Var: 0.0669\n",
      "Iteration 2600/3000, Total Loss: 6.0422, Cost Loss: 0.0879, Constraint Loss: 0.0242, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 2700/3000, Total Loss: 11.9181, Cost Loss: -0.0188, Constraint Loss: 0.0111, Integrality Loss: 0.0357, Positivity Loss: 0.0000, Avg Binary Var: 0.1250\n",
      "Iteration 2800/3000, Total Loss: 8.6045, Cost Loss: -0.0321, Constraint Loss: 0.0047, Integrality Loss: 0.0772, Positivity Loss: 0.0001, Avg Binary Var: 0.1189\n",
      "Iteration 2900/3000, Total Loss: 8.9694, Cost Loss: 0.0670, Constraint Loss: 0.0663, Integrality Loss: 0.0529, Positivity Loss: 0.0000, Avg Binary Var: 0.1455\n",
      "Iteration 3000/3000, Total Loss: 15.1137, Cost Loss: -0.0807, Constraint Loss: 0.0365, Integrality Loss: 0.0000, Positivity Loss: 0.0009, Avg Binary Var: 0.1332\n",
      "\n",
      "Continuous Variables (first 30): [0.359 0.013 0.013 0.013 0.013 0.207 0.013 0.007 0.014 0.013 0.013 0.373\n",
      " 0.013 0.013 0.013 0.013 0.013 0.    0.004 0.004 0.    0.001 0.    0.\n",
      " 0.001 0.002 0.    0.001 0.001 0.001]\n",
      "Binary/Integer Variables (remaining): [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Optimized Cost: 0.01523739636021791\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-1.    -0.641  0.013  0.013  0.013  0.013 -0.793  0.013  0.007  0.014\n",
      "  0.013  0.013 -0.627  0.013  0.013  0.013  0.013  0.013  0.     0.004\n",
      "  0.004  0.    -0.999  0.     0.     0.001  0.002  0.     0.001  0.001\n",
      "  0.001]\n",
      "Equality Violations (should be close to 0): [0.131]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.374  0.     0.     0.     0.     0.222  0.     0.     0.     0.\n",
      "  0.     0.388  0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.016  0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  1.    -0.    -0.    -0.    -0.     1.    -0.    -0.    -0.    -0.\n",
      " -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.0032134056\n",
      "Starting run 15/25\n",
      "Iteration 1/3000, Total Loss: 225.6455, Cost Loss: 3.8352, Constraint Loss: 16.7983, Integrality Loss: 0.0046, Positivity Loss: 0.0000, Avg Binary Var: 0.0374\n",
      "Iteration 100/3000, Total Loss: 11.1173, Cost Loss: 0.1176, Constraint Loss: 0.0352, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1664\n",
      "Iteration 200/3000, Total Loss: 5.8551, Cost Loss: -0.0066, Constraint Loss: 0.0214, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1666\n",
      "Iteration 300/3000, Total Loss: 3.5928, Cost Loss: -0.0340, Constraint Loss: 0.0051, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 400/3000, Total Loss: 6.0030, Cost Loss: -0.0487, Constraint Loss: 0.0005, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 500/3000, Total Loss: 4.1070, Cost Loss: -0.0470, Constraint Loss: 0.0007, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 600/3000, Total Loss: 4.1923, Cost Loss: -0.0405, Constraint Loss: 0.0024, Integrality Loss: 0.0131, Positivity Loss: 0.0002, Avg Binary Var: 0.1383\n",
      "Iteration 700/3000, Total Loss: 5.8333, Cost Loss: -0.0463, Constraint Loss: 0.0008, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 800/3000, Total Loss: 8.7549, Cost Loss: -0.0463, Constraint Loss: 0.0006, Integrality Loss: 0.0017, Positivity Loss: 0.0002, Avg Binary Var: 0.1319\n",
      "Iteration 900/3000, Total Loss: 5.0567, Cost Loss: -0.0497, Constraint Loss: 0.0004, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1000/3000, Total Loss: 9.8772, Cost Loss: -0.0448, Constraint Loss: 0.0016, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 1100/3000, Total Loss: 6.5551, Cost Loss: -0.0507, Constraint Loss: 0.0015, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1200/3000, Total Loss: 7.9706, Cost Loss: -0.0482, Constraint Loss: 0.0007, Integrality Loss: 0.0170, Positivity Loss: 0.0002, Avg Binary Var: 0.1345\n",
      "Iteration 1300/3000, Total Loss: 7.2574, Cost Loss: -0.0541, Constraint Loss: 0.0027, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1333\n",
      "Iteration 1400/3000, Total Loss: 4.7822, Cost Loss: -0.0507, Constraint Loss: 0.0011, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1333\n",
      "Iteration 1500/3000, Total Loss: 6.6227, Cost Loss: -0.0663, Constraint Loss: 0.0065, Integrality Loss: 0.0005, Positivity Loss: 0.0004, Avg Binary Var: 0.1326\n",
      "Iteration 1600/3000, Total Loss: 12.7071, Cost Loss: 0.0294, Constraint Loss: 0.0477, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 1700/3000, Total Loss: 15.8970, Cost Loss: -0.0743, Constraint Loss: 0.0093, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1667\n",
      "Iteration 1800/3000, Total Loss: 11.5845, Cost Loss: -0.0264, Constraint Loss: 0.0043, Integrality Loss: 0.0360, Positivity Loss: 0.0001, Avg Binary Var: 0.1404\n",
      "Iteration 1900/3000, Total Loss: 6.3068, Cost Loss: -0.0569, Constraint Loss: 0.0115, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1333\n",
      "Iteration 2000/3000, Total Loss: 4.5682, Cost Loss: 0.0352, Constraint Loss: 0.0366, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2100/3000, Total Loss: 7.0507, Cost Loss: 0.0659, Constraint Loss: 0.0466, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0667\n",
      "Iteration 2200/3000, Total Loss: 4.5350, Cost Loss: -0.0559, Constraint Loss: 0.0116, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.0998\n",
      "Iteration 2300/3000, Total Loss: 6.1073, Cost Loss: -0.0734, Constraint Loss: 0.0104, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1333\n",
      "Iteration 2400/3000, Total Loss: 11.3600, Cost Loss: -0.0456, Constraint Loss: 0.0011, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 2500/3000, Total Loss: 11.7846, Cost Loss: -0.0038, Constraint Loss: 0.0264, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2600/3000, Total Loss: 10.1837, Cost Loss: -0.0729, Constraint Loss: 0.0803, Integrality Loss: 0.0000, Positivity Loss: 0.0007, Avg Binary Var: 0.1333\n",
      "Iteration 2700/3000, Total Loss: 6.0156, Cost Loss: -0.0929, Constraint Loss: 0.0399, Integrality Loss: 0.0000, Positivity Loss: 0.0010, Avg Binary Var: 0.1667\n",
      "Iteration 2800/3000, Total Loss: 6.8045, Cost Loss: -0.0498, Constraint Loss: 0.0008, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 2900/3000, Total Loss: 16.8392, Cost Loss: -0.0289, Constraint Loss: 0.9664, Integrality Loss: 0.0004, Positivity Loss: 0.0001, Avg Binary Var: 0.1994\n",
      "Iteration 3000/3000, Total Loss: 5.6951, Cost Loss: -0.0581, Constraint Loss: 0.0018, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1333\n",
      "\n",
      "Continuous Variables (first 30): [ 0.007  0.007  0.007  0.361  0.235  0.007  0.007  0.007  0.009  0.007\n",
      "  0.008  0.007  0.365  0.007  0.007  0.007  0.007 -0.005 -0.004 -0.004\n",
      " -0.005 -0.005 -0.005 -0.005 -0.005 -0.005 -0.005 -0.005 -0.005 -0.005]\n",
      "Binary/Integer Variables (remaining): [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Optimized Cost: -0.05691822262736615\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-1.          0.007       0.007       0.007      -0.639      -0.765\n",
      "  0.007       0.007       0.007       0.009       0.007       0.008\n",
      "  0.007      -0.63499999  0.007       0.007       0.007       0.007\n",
      " -1.005      -0.004      -0.004      -0.005      -0.005      -0.005\n",
      " -0.005      -0.005      -0.005      -0.005      -0.005      -0.005\n",
      " -0.005     ]\n",
      "Equality Violations (should be close to 0): [-0.00099999]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.     0.372  0.246  0.     0.     0.     0.     0.\n",
      "  0.     0.     0.376  0.     0.     0.     0.     0.006  0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.    -0.    -0.     1.     1.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.     1.    -0.    -0.    -0.    -0.     1.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.0014986992\n",
      "Starting run 16/25\n",
      "Iteration 1/3000, Total Loss: 221.6024, Cost Loss: 4.3626, Constraint Loss: 16.2570, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1002\n",
      "Iteration 100/3000, Total Loss: 11.1943, Cost Loss: 0.0395, Constraint Loss: 0.0256, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1666\n",
      "Iteration 200/3000, Total Loss: 8.2685, Cost Loss: -0.0117, Constraint Loss: 0.0156, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 300/3000, Total Loss: 6.0600, Cost Loss: -0.0366, Constraint Loss: 0.0044, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 400/3000, Total Loss: 6.1577, Cost Loss: -0.0255, Constraint Loss: 0.0121, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 500/3000, Total Loss: 5.2461, Cost Loss: -0.0436, Constraint Loss: 0.0012, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 600/3000, Total Loss: 6.0728, Cost Loss: -0.0320, Constraint Loss: 0.0061, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 700/3000, Total Loss: 4.0504, Cost Loss: -0.0487, Constraint Loss: 0.0004, Integrality Loss: 0.0003, Positivity Loss: 0.0002, Avg Binary Var: 0.1339\n",
      "Iteration 800/3000, Total Loss: 7.7985, Cost Loss: -0.0433, Constraint Loss: 0.0027, Integrality Loss: 0.0003, Positivity Loss: 0.0002, Avg Binary Var: 0.1327\n",
      "Iteration 900/3000, Total Loss: 5.2574, Cost Loss: -0.0498, Constraint Loss: 0.0003, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1000/3000, Total Loss: 16.6723, Cost Loss: -0.0222, Constraint Loss: 1.0051, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.2000\n",
      "Iteration 1100/3000, Total Loss: 13.3087, Cost Loss: -0.0294, Constraint Loss: 0.0071, Integrality Loss: 0.0001, Positivity Loss: 0.0001, Avg Binary Var: 0.1664\n",
      "Iteration 1200/3000, Total Loss: 11.4615, Cost Loss: -0.0483, Constraint Loss: 0.0016, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 1300/3000, Total Loss: 25.5812, Cost Loss: -0.0439, Constraint Loss: 0.0008, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1400/3000, Total Loss: 18.3700, Cost Loss: -0.0293, Constraint Loss: 0.0035, Integrality Loss: 0.0044, Positivity Loss: 0.0001, Avg Binary Var: 0.1309\n",
      "Iteration 1500/3000, Total Loss: 13.4271, Cost Loss: -0.0855, Constraint Loss: 0.0238, Integrality Loss: 0.0000, Positivity Loss: 0.0008, Avg Binary Var: 0.1333\n",
      "Iteration 1600/3000, Total Loss: 10.4587, Cost Loss: 0.0058, Constraint Loss: 0.0151, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 1700/3000, Total Loss: 7.2889, Cost Loss: -0.0589, Constraint Loss: 0.0041, Integrality Loss: 0.0001, Positivity Loss: 0.0003, Avg Binary Var: 0.1329\n",
      "Iteration 1800/3000, Total Loss: 6.1433, Cost Loss: -0.0377, Constraint Loss: 0.0044, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 1900/3000, Total Loss: 6.0933, Cost Loss: -0.0273, Constraint Loss: 0.0077, Integrality Loss: 0.0495, Positivity Loss: 0.0001, Avg Binary Var: 0.1223\n",
      "Iteration 2000/3000, Total Loss: 4.7779, Cost Loss: -0.0425, Constraint Loss: 0.0018, Integrality Loss: 0.0002, Positivity Loss: 0.0002, Avg Binary Var: 0.1672\n",
      "Iteration 2100/3000, Total Loss: 11.4115, Cost Loss: -0.0635, Constraint Loss: 0.0148, Integrality Loss: 0.0002, Positivity Loss: 0.0004, Avg Binary Var: 0.1328\n",
      "Iteration 2200/3000, Total Loss: 13.4668, Cost Loss: -0.0619, Constraint Loss: 0.0076, Integrality Loss: 0.0155, Positivity Loss: 0.0004, Avg Binary Var: 0.1278\n",
      "Iteration 2300/3000, Total Loss: 8.6545, Cost Loss: 0.0565, Constraint Loss: 0.1061, Integrality Loss: 0.0002, Positivity Loss: 0.0000, Avg Binary Var: 0.1671\n",
      "Iteration 2400/3000, Total Loss: 5.5321, Cost Loss: -0.0018, Constraint Loss: 0.0562, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1665\n",
      "Iteration 2500/3000, Total Loss: 19.5499, Cost Loss: -0.0697, Constraint Loss: 0.0323, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.0667\n",
      "Iteration 2600/3000, Total Loss: 8.0959, Cost Loss: -0.0692, Constraint Loss: 0.0255, Integrality Loss: 0.0089, Positivity Loss: 0.0005, Avg Binary Var: 0.0632\n",
      "Iteration 2700/3000, Total Loss: 6.0565, Cost Loss: -0.0691, Constraint Loss: 0.0309, Integrality Loss: 0.0581, Positivity Loss: 0.0006, Avg Binary Var: 0.0468\n",
      "Iteration 2800/3000, Total Loss: 3.7418, Cost Loss: -0.0548, Constraint Loss: 0.0295, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1000\n",
      "Iteration 2900/3000, Total Loss: 2.7447, Cost Loss: -0.0194, Constraint Loss: 0.0281, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0667\n",
      "Iteration 3000/3000, Total Loss: 2.9182, Cost Loss: 0.0445, Constraint Loss: 0.0646, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0667\n",
      "\n",
      "Continuous Variables (first 30): [ 0.439  0.003  0.003  0.003  0.003  0.003  0.441  0.003  0.003  0.003\n",
      "  0.003  0.003  0.003  0.003  0.003  0.003  0.003 -0.009 -0.005 -0.005\n",
      " -0.009 -0.009 -0.009 -0.009 -0.009 -0.007 -0.009 -0.009 -0.009 -0.009]\n",
      "Binary/Integer Variables (remaining): [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Optimized Cost: -0.08416611048285416\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-3.         -0.56099999  0.003       0.003       0.003       0.003\n",
      "  0.003      -0.55899999  0.003       0.003       0.003       0.003\n",
      "  0.003       0.003       0.003       0.003       0.003       0.003\n",
      " -0.009      -0.005      -0.005      -0.009      -0.009      -0.009\n",
      " -0.009      -0.009      -0.007      -0.009      -0.009      -0.009\n",
      " -0.009     ]\n",
      "Equality Violations (should be close to 0): [-0.18199997]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.499  0.     0.     0.     0.     0.     0.501  0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  1.    -0.    -0.    -0.    -0.    -0.     1.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.008244038\n",
      "Starting run 17/25\n",
      "Iteration 1/3000, Total Loss: 162.0135, Cost Loss: 3.1571, Constraint Loss: 10.3979, Integrality Loss: 0.0217, Positivity Loss: 0.0000, Avg Binary Var: 0.0421\n",
      "Iteration 100/3000, Total Loss: 10.4304, Cost Loss: 0.0218, Constraint Loss: 0.0359, Integrality Loss: 0.0111, Positivity Loss: 0.0000, Avg Binary Var: 0.1373\n",
      "Iteration 200/3000, Total Loss: 5.7447, Cost Loss: -0.0265, Constraint Loss: 0.0499, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1335\n",
      "Iteration 300/3000, Total Loss: 6.3463, Cost Loss: -0.0389, Constraint Loss: 0.0043, Integrality Loss: 0.0046, Positivity Loss: 0.0001, Avg Binary Var: 0.1358\n",
      "Iteration 400/3000, Total Loss: 10.4882, Cost Loss: -0.0288, Constraint Loss: 0.0103, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 500/3000, Total Loss: 7.3611, Cost Loss: -0.0487, Constraint Loss: 0.0005, Integrality Loss: 0.0604, Positivity Loss: 0.0002, Avg Binary Var: 0.1145\n",
      "Iteration 600/3000, Total Loss: 15.6734, Cost Loss: -0.0502, Constraint Loss: 0.0026, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 700/3000, Total Loss: 12.3157, Cost Loss: -0.0475, Constraint Loss: 0.0009, Integrality Loss: 0.0891, Positivity Loss: 0.0002, Avg Binary Var: 0.1223\n",
      "Iteration 800/3000, Total Loss: 12.3698, Cost Loss: -0.0420, Constraint Loss: 0.0016, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 900/3000, Total Loss: 13.9035, Cost Loss: -0.0296, Constraint Loss: 0.0067, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 1000/3000, Total Loss: 14.1440, Cost Loss: -0.0388, Constraint Loss: 0.0043, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1100/3000, Total Loss: 10.9392, Cost Loss: -0.0420, Constraint Loss: 0.0141, Integrality Loss: 0.0717, Positivity Loss: 0.0002, Avg Binary Var: 0.1385\n",
      "Iteration 1200/3000, Total Loss: 15.5525, Cost Loss: -0.0491, Constraint Loss: 0.0073, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1668\n",
      "Iteration 1300/3000, Total Loss: 13.2612, Cost Loss: -0.0778, Constraint Loss: 0.0075, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1667\n",
      "Iteration 1400/3000, Total Loss: 10.1628, Cost Loss: -0.0470, Constraint Loss: 0.0007, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1500/3000, Total Loss: 7.3244, Cost Loss: -0.0261, Constraint Loss: 0.0049, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 1600/3000, Total Loss: 10.5334, Cost Loss: -0.0052, Constraint Loss: 0.0095, Integrality Loss: 0.0247, Positivity Loss: 0.0000, Avg Binary Var: 0.1268\n",
      "Iteration 1700/3000, Total Loss: 8.3875, Cost Loss: 0.0067, Constraint Loss: 0.0525, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 1800/3000, Total Loss: 6.5909, Cost Loss: -0.0841, Constraint Loss: 0.0150, Integrality Loss: 0.0000, Positivity Loss: 0.0007, Avg Binary Var: 0.1333\n",
      "Iteration 1900/3000, Total Loss: 7.8121, Cost Loss: 0.0116, Constraint Loss: 0.0078, Integrality Loss: 0.0348, Positivity Loss: 0.0000, Avg Binary Var: 0.1251\n",
      "Iteration 2000/3000, Total Loss: 13.5329, Cost Loss: -0.0362, Constraint Loss: 0.0060, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 2100/3000, Total Loss: 8.9512, Cost Loss: -0.0286, Constraint Loss: 0.0061, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 2200/3000, Total Loss: 6.2621, Cost Loss: 0.0025, Constraint Loss: 0.0270, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 2300/3000, Total Loss: 9.1884, Cost Loss: -0.0516, Constraint Loss: 0.0048, Integrality Loss: 0.0001, Positivity Loss: 0.0003, Avg Binary Var: 0.1331\n",
      "Iteration 2400/3000, Total Loss: 12.5714, Cost Loss: -0.0206, Constraint Loss: 0.0102, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 2500/3000, Total Loss: 11.1366, Cost Loss: -0.0813, Constraint Loss: 0.0617, Integrality Loss: 0.0000, Positivity Loss: 0.0008, Avg Binary Var: 0.1667\n",
      "Iteration 2600/3000, Total Loss: 11.4068, Cost Loss: -0.0144, Constraint Loss: 0.0150, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 2700/3000, Total Loss: 8.2888, Cost Loss: 0.0822, Constraint Loss: 0.0679, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 2800/3000, Total Loss: 10.8278, Cost Loss: -0.0634, Constraint Loss: 0.0075, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1667\n",
      "Iteration 2900/3000, Total Loss: 6.0872, Cost Loss: -0.0293, Constraint Loss: 0.0074, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 3000/3000, Total Loss: 5.0788, Cost Loss: -0.0267, Constraint Loss: 0.0078, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "\n",
      "Continuous Variables (first 30): [ 0.017  0.017  0.017  0.017  0.017  0.017  0.251  0.017  0.017  0.017\n",
      "  0.017  0.017  0.151  0.017  0.381  0.017  0.017 -0.006 -0.004 -0.004\n",
      " -0.006 -0.005 -0.006 -0.006 -0.005 -0.005 -0.005 -0.005 -0.005 -0.005]\n",
      "Binary/Integer Variables (remaining): [0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      " 0.999 0.    1.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      " 0.    0.    0.    1.    0.    0.   ]\n",
      "Optimized Cost: -0.05827386924739696\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-9.99987125e-04  1.70000009e-02  1.70000009e-02  1.70000009e-02\n",
      "  1.70000009e-02  1.70000009e-02  1.70000009e-02 -7.49000013e-01\n",
      "  1.70000009e-02  1.70000009e-02  1.70000009e-02  1.70000009e-02\n",
      "  1.70000009e-02 -8.48000020e-01  1.70000009e-02 -6.18999988e-01\n",
      "  1.70000009e-02  1.70000009e-02 -6.00000005e-03 -4.00000019e-03\n",
      " -1.00400000e+00 -6.00000005e-03 -4.99999989e-03 -6.00000005e-03\n",
      " -6.00000005e-03 -4.99999989e-03 -4.99999989e-03 -4.99999989e-03\n",
      " -1.00500000e+00 -4.99999989e-03 -4.99999989e-03]\n",
      "Equality Violations (should be close to 0): [-0.04599999]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.     0.     0.     0.     0.296  0.     0.     0.\n",
      "  0.     0.     0.196  0.     0.426  0.     0.     0.     0.     0.041\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.04   0.     0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.     1.    -0.    -0.    -0.\n",
      " -0.    -0.     1.    -0.     1.    -0.    -0.    -0.    -0.     1.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.     1.    -0.    -0.   ]\n",
      "Projection Objective value: 0.01457262\n",
      "Starting run 18/25\n",
      "Iteration 1/3000, Total Loss: 153.2795, Cost Loss: 3.0316, Constraint Loss: 9.6266, Integrality Loss: 0.0007, Positivity Loss: 0.0001, Avg Binary Var: 0.1343\n",
      "Iteration 100/3000, Total Loss: 9.2990, Cost Loss: 0.0133, Constraint Loss: 0.0224, Integrality Loss: 0.0015, Positivity Loss: 0.0000, Avg Binary Var: 0.0992\n",
      "Iteration 200/3000, Total Loss: 7.4993, Cost Loss: 0.0011, Constraint Loss: 0.0272, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 300/3000, Total Loss: 8.3997, Cost Loss: -0.0398, Constraint Loss: 0.0018, Integrality Loss: 0.0023, Positivity Loss: 0.0002, Avg Binary Var: 0.1650\n",
      "Iteration 400/3000, Total Loss: 9.8918, Cost Loss: -0.0270, Constraint Loss: 0.0056, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 500/3000, Total Loss: 9.3070, Cost Loss: -0.0390, Constraint Loss: 0.0017, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 600/3000, Total Loss: 8.7960, Cost Loss: -0.0369, Constraint Loss: 0.0054, Integrality Loss: 0.0081, Positivity Loss: 0.0001, Avg Binary Var: 0.1630\n",
      "Iteration 700/3000, Total Loss: 8.0789, Cost Loss: -0.0266, Constraint Loss: 0.0079, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.0667\n",
      "Iteration 800/3000, Total Loss: 4.3608, Cost Loss: -0.0427, Constraint Loss: 0.0016, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 900/3000, Total Loss: 3.3473, Cost Loss: -0.0426, Constraint Loss: 0.0014, Integrality Loss: 0.0004, Positivity Loss: 0.0002, Avg Binary Var: 0.1006\n",
      "Iteration 1000/3000, Total Loss: 3.6325, Cost Loss: -0.0491, Constraint Loss: 0.0006, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1100/3000, Total Loss: 7.7587, Cost Loss: -0.0468, Constraint Loss: 0.0007, Integrality Loss: 0.0003, Positivity Loss: 0.0002, Avg Binary Var: 0.1006\n",
      "Iteration 1200/3000, Total Loss: 3.9538, Cost Loss: -0.0434, Constraint Loss: 0.0045, Integrality Loss: 0.0025, Positivity Loss: 0.0002, Avg Binary Var: 0.1316\n",
      "Iteration 1300/3000, Total Loss: 2.9934, Cost Loss: -0.0180, Constraint Loss: 0.0067, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 1400/3000, Total Loss: 2.2936, Cost Loss: -0.0435, Constraint Loss: 0.0051, Integrality Loss: 0.0032, Positivity Loss: 0.0002, Avg Binary Var: 0.1020\n",
      "Iteration 1500/3000, Total Loss: 2.9652, Cost Loss: -0.0633, Constraint Loss: 0.0024, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1333\n",
      "Iteration 1600/3000, Total Loss: 3.0389, Cost Loss: 0.0367, Constraint Loss: 0.0562, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 1700/3000, Total Loss: 4.6255, Cost Loss: -0.0977, Constraint Loss: 0.0570, Integrality Loss: 0.0000, Positivity Loss: 0.0012, Avg Binary Var: 0.1667\n",
      "Iteration 1800/3000, Total Loss: 4.2523, Cost Loss: -0.0722, Constraint Loss: 0.0729, Integrality Loss: 0.0000, Positivity Loss: 0.0007, Avg Binary Var: 0.1332\n",
      "Iteration 1900/3000, Total Loss: 1.5227, Cost Loss: -0.0821, Constraint Loss: 0.0225, Integrality Loss: 0.0000, Positivity Loss: 0.0007, Avg Binary Var: 0.1667\n",
      "Iteration 2000/3000, Total Loss: 2.8802, Cost Loss: -0.0095, Constraint Loss: 0.0229, Integrality Loss: 0.0516, Positivity Loss: 0.0002, Avg Binary Var: 0.1204\n",
      "Iteration 2100/3000, Total Loss: 5.9215, Cost Loss: 0.1524, Constraint Loss: 0.1737, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 2200/3000, Total Loss: 3.8816, Cost Loss: 0.0166, Constraint Loss: 0.0470, Integrality Loss: 0.0568, Positivity Loss: 0.0000, Avg Binary Var: 0.1536\n",
      "Iteration 2300/3000, Total Loss: 9.7010, Cost Loss: -0.0387, Constraint Loss: 0.0301, Integrality Loss: 0.0443, Positivity Loss: 0.0001, Avg Binary Var: 0.1121\n",
      "Iteration 2400/3000, Total Loss: 3.5778, Cost Loss: -0.0683, Constraint Loss: 0.0199, Integrality Loss: 0.0003, Positivity Loss: 0.0005, Avg Binary Var: 0.0672\n",
      "Iteration 2500/3000, Total Loss: 7.8877, Cost Loss: -0.0667, Constraint Loss: 0.0024, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1000\n",
      "Iteration 2600/3000, Total Loss: 9.3596, Cost Loss: -0.0223, Constraint Loss: 0.0103, Integrality Loss: 0.0005, Positivity Loss: 0.0001, Avg Binary Var: 0.1326\n",
      "Iteration 2700/3000, Total Loss: 7.4132, Cost Loss: -0.0186, Constraint Loss: 0.0328, Integrality Loss: 0.0005, Positivity Loss: 0.0000, Avg Binary Var: 0.1341\n",
      "Iteration 2800/3000, Total Loss: 5.7556, Cost Loss: -0.0614, Constraint Loss: 0.0184, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1334\n",
      "Iteration 2900/3000, Total Loss: 3.3272, Cost Loss: -0.0585, Constraint Loss: 0.0018, Integrality Loss: 0.0007, Positivity Loss: 0.0003, Avg Binary Var: 0.1325\n",
      "Iteration 3000/3000, Total Loss: 2.0038, Cost Loss: -0.0604, Constraint Loss: 0.0124, Integrality Loss: 0.0233, Positivity Loss: 0.0004, Avg Binary Var: 0.1271\n",
      "\n",
      "Continuous Variables (first 30): [ 0.163  0.368  0.012  0.013  0.012  0.012  0.012  0.012  0.377  0.012\n",
      "  0.012  0.012  0.013  0.012  0.012  0.012  0.012 -0.001  0.002  0.002\n",
      " -0.001 -0.001 -0.001 -0.001 -0.001 -0.    -0.001 -0.001 -0.001 -0.001]\n",
      "Binary/Integer Variables (remaining): [1.    0.999 0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 1.    0.    0.    0.    0.    0.   ]\n",
      "Optimized Cost: -0.005275352879932289\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-1.00099999e+00 -8.36999997e-01 -6.31000012e-01  1.20000001e-02\n",
      "  1.30000003e-02  1.20000001e-02  1.20000001e-02  1.20000001e-02\n",
      "  1.20000001e-02 -6.22999996e-01  1.20000001e-02  1.20000001e-02\n",
      "  1.20000001e-02  1.30000003e-02  1.20000001e-02  1.20000001e-02\n",
      "  1.20000001e-02  1.20000001e-02 -1.00000005e-03  2.00000009e-03\n",
      "  2.00000009e-03 -1.00000005e-03 -1.00000005e-03 -1.00000005e-03\n",
      " -1.00000005e-03 -1.00100000e+00  0.00000000e+00 -1.00000005e-03\n",
      " -1.00000005e-03 -1.00000005e-03 -1.00000005e-03]\n",
      "Equality Violations (should be close to 0): [0.07200001]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.186  0.391  0.     0.     0.     0.     0.     0.     0.4    0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.022  0.     0.     0.     0.     0.\n",
      "  1.     1.    -0.    -0.    -0.    -0.    -0.    -0.     1.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.     1.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.0042467117\n",
      "Starting run 19/25\n",
      "Iteration 1/3000, Total Loss: 151.2991, Cost Loss: 3.4579, Constraint Loss: 9.2937, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.0000\n",
      "Iteration 100/3000, Total Loss: 10.1486, Cost Loss: 0.0197, Constraint Loss: 0.0300, Integrality Loss: 0.0013, Positivity Loss: 0.0000, Avg Binary Var: 0.0679\n",
      "Iteration 200/3000, Total Loss: 6.6661, Cost Loss: -0.0448, Constraint Loss: 0.0013, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 300/3000, Total Loss: 6.4593, Cost Loss: -0.0344, Constraint Loss: 0.0300, Integrality Loss: 0.0031, Positivity Loss: 0.0001, Avg Binary Var: 0.1020\n",
      "Iteration 400/3000, Total Loss: 7.2007, Cost Loss: -0.0463, Constraint Loss: 0.0009, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 500/3000, Total Loss: 8.3921, Cost Loss: -0.0450, Constraint Loss: 0.0018, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1666\n",
      "Iteration 600/3000, Total Loss: 8.9606, Cost Loss: -0.0478, Constraint Loss: 0.0007, Integrality Loss: 0.0305, Positivity Loss: 0.0002, Avg Binary Var: 0.1265\n",
      "Iteration 700/3000, Total Loss: 5.6334, Cost Loss: -0.0472, Constraint Loss: 0.0007, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1334\n",
      "Iteration 800/3000, Total Loss: 7.0335, Cost Loss: -0.0471, Constraint Loss: 0.0011, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1334\n",
      "Iteration 900/3000, Total Loss: 8.1187, Cost Loss: -0.0496, Constraint Loss: 0.0004, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1000/3000, Total Loss: 15.9207, Cost Loss: -0.0527, Constraint Loss: 0.7282, Integrality Loss: 0.0152, Positivity Loss: 0.0003, Avg Binary Var: 0.1951\n",
      "Iteration 1100/3000, Total Loss: 6.7182, Cost Loss: -0.0267, Constraint Loss: 0.0046, Integrality Loss: 0.0008, Positivity Loss: 0.0001, Avg Binary Var: 0.1009\n",
      "Iteration 1200/3000, Total Loss: 5.0844, Cost Loss: -0.0870, Constraint Loss: 0.0601, Integrality Loss: 0.0000, Positivity Loss: 0.0009, Avg Binary Var: 0.1667\n",
      "Iteration 1300/3000, Total Loss: 11.5092, Cost Loss: 0.0086, Constraint Loss: 0.0310, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 1400/3000, Total Loss: 6.0168, Cost Loss: -0.0652, Constraint Loss: 0.0084, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1000\n",
      "Iteration 1500/3000, Total Loss: 3.9317, Cost Loss: -0.0094, Constraint Loss: 0.0065, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 1600/3000, Total Loss: 2.8817, Cost Loss: -0.0300, Constraint Loss: 0.0076, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.0998\n",
      "Iteration 1700/3000, Total Loss: 8.7581, Cost Loss: 0.0085, Constraint Loss: 0.0713, Integrality Loss: 0.0007, Positivity Loss: 0.0000, Avg Binary Var: 0.1658\n",
      "Iteration 1800/3000, Total Loss: 11.8898, Cost Loss: 0.0510, Constraint Loss: 0.0239, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 1900/3000, Total Loss: 11.5795, Cost Loss: -0.1103, Constraint Loss: 0.0561, Integrality Loss: 0.0000, Positivity Loss: 0.0014, Avg Binary Var: 0.1333\n",
      "Iteration 2000/3000, Total Loss: 13.2144, Cost Loss: -0.0312, Constraint Loss: 0.0061, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 2100/3000, Total Loss: 7.0016, Cost Loss: -0.0345, Constraint Loss: 0.0029, Integrality Loss: 0.0625, Positivity Loss: 0.0001, Avg Binary Var: 0.1164\n",
      "Iteration 2200/3000, Total Loss: 6.6483, Cost Loss: 0.0760, Constraint Loss: 0.0338, Integrality Loss: 0.0625, Positivity Loss: 0.0000, Avg Binary Var: 0.1497\n",
      "Iteration 2300/3000, Total Loss: 3.1589, Cost Loss: -0.0369, Constraint Loss: 0.0036, Integrality Loss: 0.0055, Positivity Loss: 0.0001, Avg Binary Var: 0.1306\n",
      "Iteration 2400/3000, Total Loss: 7.6634, Cost Loss: -0.0530, Constraint Loss: 0.0214, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1333\n",
      "Iteration 2500/3000, Total Loss: 3.3303, Cost Loss: -0.0363, Constraint Loss: 0.0110, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 2600/3000, Total Loss: 8.0796, Cost Loss: -0.1038, Constraint Loss: 0.0181, Integrality Loss: 0.0000, Positivity Loss: 0.0011, Avg Binary Var: 0.1667\n",
      "Iteration 2700/3000, Total Loss: 12.1325, Cost Loss: 0.0009, Constraint Loss: 0.0245, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2800/3000, Total Loss: 7.2418, Cost Loss: -0.0450, Constraint Loss: 0.0028, Integrality Loss: 0.0231, Positivity Loss: 0.0002, Avg Binary Var: 0.1271\n",
      "Iteration 2900/3000, Total Loss: 5.7474, Cost Loss: -0.0724, Constraint Loss: 0.0197, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1334\n",
      "Iteration 3000/3000, Total Loss: 4.0326, Cost Loss: -0.0152, Constraint Loss: 0.0035, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "\n",
      "Continuous Variables (first 30): [ 0.017  0.48   0.017  0.017  0.017  0.017  0.017  0.017  0.017  0.017\n",
      "  0.017  0.017  0.3    0.017  0.017  0.017  0.016 -0.001  0.001  0.002\n",
      " -0.001 -0.001 -0.001 -0.001 -0.001 -0.    -0.001 -0.001 -0.001 -0.001]\n",
      "Binary/Integer Variables (remaining): [0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 1.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.084]\n",
      "Optimized Cost: -0.0059367881505483465\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-1.91600000e+00  1.70000009e-02 -5.20000011e-01  1.70000009e-02\n",
      "  1.70000009e-02  1.70000009e-02  1.70000009e-02  1.70000009e-02\n",
      "  1.70000009e-02  1.70000009e-02  1.70000009e-02  1.70000009e-02\n",
      "  1.70000009e-02 -6.99999988e-01  1.70000009e-02  1.70000009e-02\n",
      "  1.70000009e-02  1.60000008e-02 -1.00000005e-03 -9.99000000e-01\n",
      "  2.00000009e-03 -1.00000005e-03 -1.00000005e-03 -1.00000005e-03\n",
      " -1.00000005e-03 -1.00000005e-03  0.00000000e+00 -1.00000005e-03\n",
      " -1.00000005e-03 -1.00000005e-03 -8.49999989e-02]\n",
      "Equality Violations (should be close to 0): [0.02700001]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.553  0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.373  0.     0.     0.     0.     0.     0.074  0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.     1.    -0.    -0.    -0.    -0.    -0.     1.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.027359009\n",
      "Starting run 20/25\n",
      "Iteration 1/3000, Total Loss: 211.2491, Cost Loss: 3.6535, Constraint Loss: 15.3152, Integrality Loss: 0.0616, Positivity Loss: 0.0000, Avg Binary Var: 0.1188\n",
      "Iteration 100/3000, Total Loss: 10.2649, Cost Loss: 0.0022, Constraint Loss: 0.0204, Integrality Loss: 0.0001, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 200/3000, Total Loss: 7.9441, Cost Loss: -0.0403, Constraint Loss: 0.0072, Integrality Loss: 0.0020, Positivity Loss: 0.0006, Avg Binary Var: 0.1644\n",
      "Iteration 300/3000, Total Loss: 8.1352, Cost Loss: -0.0516, Constraint Loss: 0.0043, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1333\n",
      "Iteration 400/3000, Total Loss: 5.2218, Cost Loss: -0.0310, Constraint Loss: 0.0039, Integrality Loss: 0.0018, Positivity Loss: 0.0001, Avg Binary Var: 0.1318\n",
      "Iteration 500/3000, Total Loss: 6.7001, Cost Loss: -0.0448, Constraint Loss: 0.0013, Integrality Loss: 0.1223, Positivity Loss: 0.0002, Avg Binary Var: 0.0992\n",
      "Iteration 600/3000, Total Loss: 9.2949, Cost Loss: -0.0238, Constraint Loss: 0.0074, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 700/3000, Total Loss: 6.7563, Cost Loss: -0.0392, Constraint Loss: 0.0023, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 800/3000, Total Loss: 5.2407, Cost Loss: -0.0336, Constraint Loss: 0.0039, Integrality Loss: 0.0001, Positivity Loss: 0.0001, Avg Binary Var: 0.1329\n",
      "Iteration 900/3000, Total Loss: 6.9858, Cost Loss: -0.0139, Constraint Loss: 0.0056, Integrality Loss: 0.0542, Positivity Loss: 0.0000, Avg Binary Var: 0.1123\n",
      "Iteration 1000/3000, Total Loss: 3.3043, Cost Loss: -0.0339, Constraint Loss: 0.0082, Integrality Loss: 0.0001, Positivity Loss: 0.0001, Avg Binary Var: 0.0670\n",
      "Iteration 1100/3000, Total Loss: 3.6121, Cost Loss: -0.0473, Constraint Loss: 0.0008, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 1200/3000, Total Loss: 3.3703, Cost Loss: -0.0346, Constraint Loss: 0.0039, Integrality Loss: 0.0001, Positivity Loss: 0.0001, Avg Binary Var: 0.1330\n",
      "Iteration 1300/3000, Total Loss: 7.4509, Cost Loss: -0.0200, Constraint Loss: 0.0098, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 1400/3000, Total Loss: 13.9756, Cost Loss: -0.0235, Constraint Loss: 0.0206, Integrality Loss: 0.0275, Positivity Loss: 0.0001, Avg Binary Var: 0.1071\n",
      "Iteration 1500/3000, Total Loss: 12.6292, Cost Loss: -0.0318, Constraint Loss: 0.0094, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 1600/3000, Total Loss: 10.9771, Cost Loss: -0.0770, Constraint Loss: 0.0430, Integrality Loss: 0.0595, Positivity Loss: 0.0007, Avg Binary Var: 0.1474\n",
      "Iteration 1700/3000, Total Loss: 9.8875, Cost Loss: -0.0303, Constraint Loss: 0.0181, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 1800/3000, Total Loss: 9.7474, Cost Loss: -0.0588, Constraint Loss: 0.0175, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1333\n",
      "Iteration 1900/3000, Total Loss: 20.6885, Cost Loss: -0.0935, Constraint Loss: 0.0380, Integrality Loss: 0.0000, Positivity Loss: 0.0010, Avg Binary Var: 0.1667\n",
      "Iteration 2000/3000, Total Loss: 18.3151, Cost Loss: -0.0618, Constraint Loss: 0.0365, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1667\n",
      "Iteration 2100/3000, Total Loss: 26.8989, Cost Loss: -0.0246, Constraint Loss: 0.0013, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 2200/3000, Total Loss: 17.4648, Cost Loss: -0.0872, Constraint Loss: 0.0428, Integrality Loss: 0.0000, Positivity Loss: 0.0009, Avg Binary Var: 0.1667\n",
      "Iteration 2300/3000, Total Loss: 14.0585, Cost Loss: -0.0355, Constraint Loss: 0.0553, Integrality Loss: 0.0315, Positivity Loss: 0.0001, Avg Binary Var: 0.1743\n",
      "Iteration 2400/3000, Total Loss: 15.5146, Cost Loss: -0.0840, Constraint Loss: 0.0599, Integrality Loss: 0.0000, Positivity Loss: 0.0009, Avg Binary Var: 0.1333\n",
      "Iteration 2500/3000, Total Loss: 11.5432, Cost Loss: -0.0667, Constraint Loss: 0.0179, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1333\n",
      "Iteration 2600/3000, Total Loss: 8.2649, Cost Loss: -0.0556, Constraint Loss: 0.0045, Integrality Loss: 0.0009, Positivity Loss: 0.0003, Avg Binary Var: 0.1323\n",
      "Iteration 2700/3000, Total Loss: 14.7149, Cost Loss: 0.0117, Constraint Loss: 0.0185, Integrality Loss: 0.0130, Positivity Loss: 0.0000, Avg Binary Var: 0.1337\n",
      "Iteration 2800/3000, Total Loss: 11.6743, Cost Loss: -0.0379, Constraint Loss: 0.0047, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 2900/3000, Total Loss: 8.2279, Cost Loss: -0.0583, Constraint Loss: 0.0010, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1667\n",
      "Iteration 3000/3000, Total Loss: 16.3151, Cost Loss: -0.0463, Constraint Loss: 0.0024, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1666\n",
      "\n",
      "Continuous Variables (first 30): [ 0.011  0.011  0.076  0.011  0.011  0.011  0.011  0.406  0.011  0.405\n",
      "  0.011  0.011  0.011  0.018  0.011  0.011  0.011 -0.003 -0.002 -0.002\n",
      " -0.003 -0.003 -0.003 -0.003 -0.003 -0.002 -0.003 -0.003 -0.003 -0.003]\n",
      "Binary/Integer Variables (remaining): [0.    0.    0.757 0.    0.    0.    0.    1.    0.    1.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.   ]\n",
      "Optimized Cost: -0.031805169167011704\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-1.24299997  0.011       0.011      -0.68100003  0.011       0.011\n",
      "  0.011       0.011      -0.59400001  0.011      -0.595       0.011\n",
      "  0.011       0.011       0.018       0.011       0.011       0.011\n",
      " -0.003      -0.002      -1.002      -0.003      -0.003      -0.003\n",
      " -0.003      -0.003      -0.002      -0.003      -0.003      -0.003\n",
      " -0.003     ]\n",
      "Equality Violations (should be close to 0): [0.01199998]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.105  0.     0.     0.     0.     0.435  0.     0.434\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.027\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.    -0.     1.    -0.    -0.    -0.    -0.     1.    -0.     1.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.     1.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.06435037\n",
      "Starting run 21/25\n",
      "Iteration 1/3000, Total Loss: 177.1509, Cost Loss: 3.8651, Constraint Loss: 11.8959, Integrality Loss: 0.0008, Positivity Loss: 0.0000, Avg Binary Var: 0.1005\n",
      "Iteration 100/3000, Total Loss: 10.0598, Cost Loss: 0.1338, Constraint Loss: 0.0382, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0667\n",
      "Iteration 200/3000, Total Loss: 6.8379, Cost Loss: -0.0411, Constraint Loss: 0.0026, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 300/3000, Total Loss: 4.2488, Cost Loss: -0.0327, Constraint Loss: 0.0036, Integrality Loss: 0.0298, Positivity Loss: 0.0001, Avg Binary Var: 0.1074\n",
      "Iteration 400/3000, Total Loss: 4.5678, Cost Loss: -0.0463, Constraint Loss: 0.0010, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 500/3000, Total Loss: 5.3322, Cost Loss: -0.0387, Constraint Loss: 0.0046, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 600/3000, Total Loss: 5.3277, Cost Loss: -0.0344, Constraint Loss: 0.0035, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 700/3000, Total Loss: 3.5005, Cost Loss: -0.0397, Constraint Loss: 0.0021, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 800/3000, Total Loss: 1.4243, Cost Loss: -0.0399, Constraint Loss: 0.0054, Integrality Loss: 0.0003, Positivity Loss: 0.0002, Avg Binary Var: 0.1328\n",
      "Iteration 900/3000, Total Loss: 6.1683, Cost Loss: -0.0293, Constraint Loss: 0.0037, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 1000/3000, Total Loss: 6.2701, Cost Loss: -0.0476, Constraint Loss: 0.0008, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 1100/3000, Total Loss: 8.7376, Cost Loss: -0.0491, Constraint Loss: 0.0035, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 1200/3000, Total Loss: 5.1782, Cost Loss: -0.0150, Constraint Loss: 0.0142, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0667\n",
      "Iteration 1300/3000, Total Loss: 15.7259, Cost Loss: -0.0547, Constraint Loss: 0.0038, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1667\n",
      "Iteration 1400/3000, Total Loss: 8.8972, Cost Loss: -0.0722, Constraint Loss: 0.0130, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1333\n",
      "Iteration 1500/3000, Total Loss: 18.2381, Cost Loss: -0.0350, Constraint Loss: 0.1339, Integrality Loss: 0.0031, Positivity Loss: 0.0001, Avg Binary Var: 0.1019\n",
      "Iteration 1600/3000, Total Loss: 14.5660, Cost Loss: -0.0927, Constraint Loss: 0.0291, Integrality Loss: 0.0000, Positivity Loss: 0.0010, Avg Binary Var: 0.1333\n",
      "Iteration 1700/3000, Total Loss: 17.7386, Cost Loss: -0.0902, Constraint Loss: 0.0414, Integrality Loss: 0.0000, Positivity Loss: 0.0009, Avg Binary Var: 0.1667\n",
      "Iteration 1800/3000, Total Loss: 17.9779, Cost Loss: -0.0245, Constraint Loss: 0.0074, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 1900/3000, Total Loss: 25.4945, Cost Loss: -0.0795, Constraint Loss: 0.8759, Integrality Loss: 0.0052, Positivity Loss: 0.0007, Avg Binary Var: 0.1974\n",
      "Iteration 2000/3000, Total Loss: 12.6983, Cost Loss: -0.0668, Constraint Loss: 0.0051, Integrality Loss: 0.0031, Positivity Loss: 0.0004, Avg Binary Var: 0.1020\n",
      "Iteration 2100/3000, Total Loss: 14.8625, Cost Loss: -0.0803, Constraint Loss: 0.0321, Integrality Loss: 0.0007, Positivity Loss: 0.0007, Avg Binary Var: 0.1324\n",
      "Iteration 2200/3000, Total Loss: 15.0232, Cost Loss: -0.0351, Constraint Loss: 0.0047, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 2300/3000, Total Loss: 15.9405, Cost Loss: -0.0674, Constraint Loss: 0.0204, Integrality Loss: 0.0546, Positivity Loss: 0.0005, Avg Binary Var: 0.1209\n",
      "Iteration 2400/3000, Total Loss: 11.8356, Cost Loss: 0.0116, Constraint Loss: 0.0088, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 2500/3000, Total Loss: 11.6483, Cost Loss: -0.0281, Constraint Loss: 0.0007, Integrality Loss: 0.0005, Positivity Loss: 0.0001, Avg Binary Var: 0.1659\n",
      "Iteration 2600/3000, Total Loss: 11.9887, Cost Loss: -0.0006, Constraint Loss: 0.0078, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1665\n",
      "Iteration 2700/3000, Total Loss: 14.4363, Cost Loss: -0.0966, Constraint Loss: 0.0569, Integrality Loss: 0.0504, Positivity Loss: 0.0013, Avg Binary Var: 0.1103\n",
      "Iteration 2800/3000, Total Loss: 13.3512, Cost Loss: -0.0264, Constraint Loss: 0.0025, Integrality Loss: 0.0004, Positivity Loss: 0.0001, Avg Binary Var: 0.0993\n",
      "Iteration 2900/3000, Total Loss: 16.7294, Cost Loss: 0.0001, Constraint Loss: 0.0205, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 3000/3000, Total Loss: 11.5730, Cost Loss: -0.0380, Constraint Loss: 0.0020, Integrality Loss: 0.0492, Positivity Loss: 0.0001, Avg Binary Var: 0.1556\n",
      "\n",
      "Continuous Variables (first 30): [ 0.012  0.012  0.011  0.012  0.012  0.012  0.012  0.379  0.012  0.012\n",
      "  0.012  0.013  0.144  0.013  0.012  0.012  0.338 -0.004 -0.002 -0.002\n",
      " -0.004 -0.004 -0.004 -0.004 -0.004 -0.003 -0.004 -0.004 -0.004 -0.004]\n",
      "Binary/Integer Variables (remaining): [0.    0.    0.    0.    0.    0.    0.    0.998 0.    0.    0.    0.\n",
      " 1.    0.007 0.    0.    1.    0.    0.    0.    0.    1.    0.    1.\n",
      " 0.    0.    0.    0.    0.    0.   ]\n",
      "Optimized Cost: -0.041583674722774994\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [ 0.00500003  0.012       0.012       0.011       0.012       0.012\n",
      "  0.012       0.012      -0.61900002  0.012       0.012       0.012\n",
      "  0.013      -0.85600001  0.006       0.012       0.012      -0.662\n",
      " -0.004      -0.002      -0.002      -0.004      -1.004      -0.004\n",
      " -1.004      -0.004      -0.003      -0.004      -0.004      -0.004\n",
      " -0.004     ]\n",
      "Equality Violations (should be close to 0): [-0.017]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.     0.     0.     0.     0.     0.408  0.     0.\n",
      "  0.     0.     0.173  0.     0.     0.     0.367  0.     0.     0.\n",
      "  0.     0.025  0.     0.025  0.     0.     0.     0.     0.     0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.     1.    -0.    -0.\n",
      " -0.    -0.     1.    -0.    -0.    -0.     1.    -0.    -0.    -0.\n",
      " -0.     1.    -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.00656271\n",
      "Starting run 22/25\n",
      "Iteration 1/3000, Total Loss: 226.8700, Cost Loss: 3.8269, Constraint Loss: 16.8311, Integrality Loss: 0.0317, Positivity Loss: 0.0000, Avg Binary Var: 0.0927\n",
      "Iteration 100/3000, Total Loss: 10.1992, Cost Loss: -0.0230, Constraint Loss: 0.0153, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 200/3000, Total Loss: 6.9618, Cost Loss: 0.0016, Constraint Loss: 0.0464, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 300/3000, Total Loss: 8.4520, Cost Loss: -0.0290, Constraint Loss: 0.1124, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 400/3000, Total Loss: 5.8097, Cost Loss: -0.0245, Constraint Loss: 0.0104, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 500/3000, Total Loss: 4.2694, Cost Loss: -0.0268, Constraint Loss: 0.0074, Integrality Loss: 0.0594, Positivity Loss: 0.0001, Avg Binary Var: 0.1193\n",
      "Iteration 600/3000, Total Loss: 4.7072, Cost Loss: -0.0404, Constraint Loss: 0.0051, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 700/3000, Total Loss: 4.6738, Cost Loss: -0.0483, Constraint Loss: 0.0005, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 800/3000, Total Loss: 7.0432, Cost Loss: -0.0500, Constraint Loss: 0.0009, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 900/3000, Total Loss: 11.6156, Cost Loss: -0.0396, Constraint Loss: 0.0023, Integrality Loss: 0.0527, Positivity Loss: 0.0002, Avg Binary Var: 0.1119\n",
      "Iteration 1000/3000, Total Loss: 9.0466, Cost Loss: -0.0428, Constraint Loss: 0.0013, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1100/3000, Total Loss: 7.4980, Cost Loss: -0.0443, Constraint Loss: 0.0015, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1200/3000, Total Loss: 8.3979, Cost Loss: -0.0476, Constraint Loss: 0.0007, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1300/3000, Total Loss: 11.4712, Cost Loss: -0.0510, Constraint Loss: 0.0003, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1400/3000, Total Loss: 8.8932, Cost Loss: -0.0442, Constraint Loss: 0.0012, Integrality Loss: 0.0193, Positivity Loss: 0.0002, Avg Binary Var: 0.1611\n",
      "Iteration 1500/3000, Total Loss: 10.0456, Cost Loss: -0.0664, Constraint Loss: 0.0052, Integrality Loss: 0.0027, Positivity Loss: 0.0004, Avg Binary Var: 0.1315\n",
      "Iteration 1600/3000, Total Loss: 11.9605, Cost Loss: -0.0562, Constraint Loss: 0.0040, Integrality Loss: 0.0624, Positivity Loss: 0.0003, Avg Binary Var: 0.1504\n",
      "Iteration 1700/3000, Total Loss: 17.9451, Cost Loss: -0.0574, Constraint Loss: 0.0054, Integrality Loss: 0.0620, Positivity Loss: 0.0003, Avg Binary Var: 0.1510\n",
      "Iteration 1800/3000, Total Loss: 12.7333, Cost Loss: 0.0471, Constraint Loss: 0.0365, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 1900/3000, Total Loss: 9.1163, Cost Loss: -0.0217, Constraint Loss: 0.0104, Integrality Loss: 0.0005, Positivity Loss: 0.0000, Avg Binary Var: 0.1659\n",
      "Iteration 2000/3000, Total Loss: 14.1380, Cost Loss: -0.0121, Constraint Loss: 0.1561, Integrality Loss: 0.0777, Positivity Loss: 0.0000, Avg Binary Var: 0.1795\n",
      "Iteration 2100/3000, Total Loss: 14.9210, Cost Loss: -0.1061, Constraint Loss: 0.0173, Integrality Loss: 0.0000, Positivity Loss: 0.0012, Avg Binary Var: 0.1333\n",
      "Iteration 2200/3000, Total Loss: 11.9694, Cost Loss: -0.0285, Constraint Loss: 0.0057, Integrality Loss: 0.0021, Positivity Loss: 0.0001, Avg Binary Var: 0.1651\n",
      "Iteration 2300/3000, Total Loss: 7.5825, Cost Loss: -0.0464, Constraint Loss: 0.0027, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 2400/3000, Total Loss: 11.3540, Cost Loss: -0.0144, Constraint Loss: 0.0198, Integrality Loss: 0.0242, Positivity Loss: 0.0001, Avg Binary Var: 0.0731\n",
      "Iteration 2500/3000, Total Loss: 4.5793, Cost Loss: 0.0951, Constraint Loss: 0.0032, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.0667\n",
      "Iteration 2600/3000, Total Loss: 5.2059, Cost Loss: -0.0440, Constraint Loss: 0.0010, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 2700/3000, Total Loss: 7.3647, Cost Loss: -0.0486, Constraint Loss: 0.0017, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 2800/3000, Total Loss: 4.2037, Cost Loss: -0.0743, Constraint Loss: 0.0222, Integrality Loss: 0.0001, Positivity Loss: 0.0006, Avg Binary Var: 0.1664\n",
      "Iteration 2900/3000, Total Loss: 4.0095, Cost Loss: -0.0671, Constraint Loss: 0.0163, Integrality Loss: 0.0061, Positivity Loss: 0.0005, Avg Binary Var: 0.1638\n",
      "Iteration 3000/3000, Total Loss: 6.7658, Cost Loss: -0.0285, Constraint Loss: 0.0077, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "\n",
      "Continuous Variables (first 30): [ 0.007  0.223  0.007  0.163  0.28   0.276  0.007  0.007  0.007  0.007\n",
      "  0.007  0.007  0.007  0.007  0.007  0.007  0.007 -0.006 -0.005 -0.005\n",
      " -0.006 -0.006 -0.006 -0.006 -0.006 -0.006 -0.006 -0.006 -0.006 -0.006]\n",
      "Binary/Integer Variables (remaining): [0.    0.994 0.    1.    1.    1.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    1.    0.    0.   ]\n",
      "Optimized Cost: -0.06666726358647823\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-0.00599998  0.007      -0.77100001  0.007      -0.837      -0.72\n",
      " -0.72400001  0.007       0.007       0.007       0.007       0.007\n",
      "  0.007       0.007       0.007       0.007       0.007       0.007\n",
      " -0.006      -0.005      -0.005      -0.006      -0.006      -0.006\n",
      " -0.006      -0.006      -0.006      -0.006      -1.006      -0.006\n",
      " -0.006     ]\n",
      "Equality Violations (should be close to 0): [-0.043]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.236  0.     0.176  0.293  0.289  0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.007  0.     0.\n",
      " -0.     1.    -0.     1.     1.     1.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.     1.    -0.    -0.   ]\n",
      "Projection Objective value: 0.0019016266\n",
      "Starting run 23/25\n",
      "Iteration 1/3000, Total Loss: 175.9160, Cost Loss: 3.1620, Constraint Loss: 11.7832, Integrality Loss: 0.0615, Positivity Loss: 0.0002, Avg Binary Var: 0.0517\n",
      "Iteration 100/3000, Total Loss: 10.8675, Cost Loss: 0.0011, Constraint Loss: 0.0852, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 200/3000, Total Loss: 5.9885, Cost Loss: -0.0002, Constraint Loss: 0.0221, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 300/3000, Total Loss: 8.4315, Cost Loss: -0.0272, Constraint Loss: 0.0087, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 400/3000, Total Loss: 7.2647, Cost Loss: -0.0373, Constraint Loss: 0.0028, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 500/3000, Total Loss: 8.3005, Cost Loss: -0.0421, Constraint Loss: 0.1508, Integrality Loss: 0.0722, Positivity Loss: 0.0002, Avg Binary Var: 0.1796\n",
      "Iteration 600/3000, Total Loss: 12.3350, Cost Loss: -0.0393, Constraint Loss: 0.0024, Integrality Loss: 0.0001, Positivity Loss: 0.0002, Avg Binary Var: 0.1670\n",
      "Iteration 700/3000, Total Loss: 8.1406, Cost Loss: -0.0437, Constraint Loss: 0.0020, Integrality Loss: 0.0102, Positivity Loss: 0.0002, Avg Binary Var: 0.1629\n",
      "Iteration 800/3000, Total Loss: 4.9002, Cost Loss: -0.0367, Constraint Loss: 0.0014, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1666\n",
      "Iteration 900/3000, Total Loss: 5.7883, Cost Loss: -0.0536, Constraint Loss: 0.0003, Integrality Loss: 0.0009, Positivity Loss: 0.0003, Avg Binary Var: 0.1344\n",
      "Iteration 1000/3000, Total Loss: 6.3939, Cost Loss: -0.0552, Constraint Loss: 0.0004, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1667\n",
      "Iteration 1100/3000, Total Loss: 13.7109, Cost Loss: -0.0318, Constraint Loss: 0.0304, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 1200/3000, Total Loss: 8.9644, Cost Loss: -0.0328, Constraint Loss: 0.0055, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1333\n",
      "Iteration 1300/3000, Total Loss: 6.9779, Cost Loss: -0.0616, Constraint Loss: 0.0049, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1000\n",
      "Iteration 1400/3000, Total Loss: 7.6398, Cost Loss: -0.0218, Constraint Loss: 0.0124, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1335\n",
      "Iteration 1500/3000, Total Loss: 14.1402, Cost Loss: -0.0628, Constraint Loss: 0.0023, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1336\n",
      "Iteration 1600/3000, Total Loss: 8.6478, Cost Loss: -0.0732, Constraint Loss: 0.0064, Integrality Loss: 0.0022, Positivity Loss: 0.0005, Avg Binary Var: 0.1330\n",
      "Iteration 1700/3000, Total Loss: 7.9853, Cost Loss: 0.0429, Constraint Loss: 0.0355, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 1800/3000, Total Loss: 5.1388, Cost Loss: -0.0151, Constraint Loss: 0.0094, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 1900/3000, Total Loss: 14.5168, Cost Loss: -0.0527, Constraint Loss: 0.9537, Integrality Loss: 0.0006, Positivity Loss: 0.0003, Avg Binary Var: 0.1992\n",
      "Iteration 2000/3000, Total Loss: 8.7129, Cost Loss: 0.0254, Constraint Loss: 0.0039, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 2100/3000, Total Loss: 6.5067, Cost Loss: -0.0693, Constraint Loss: 0.0189, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1333\n",
      "Iteration 2200/3000, Total Loss: 5.3016, Cost Loss: -0.0855, Constraint Loss: 0.0118, Integrality Loss: 0.0000, Positivity Loss: 0.0007, Avg Binary Var: 0.1000\n",
      "Iteration 2300/3000, Total Loss: 6.5250, Cost Loss: -0.0932, Constraint Loss: 0.0099, Integrality Loss: 0.0000, Positivity Loss: 0.0009, Avg Binary Var: 0.1333\n",
      "Iteration 2400/3000, Total Loss: 7.5630, Cost Loss: -0.0714, Constraint Loss: 0.0113, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1667\n",
      "Iteration 2500/3000, Total Loss: 6.9612, Cost Loss: -0.0104, Constraint Loss: 0.0181, Integrality Loss: 0.0075, Positivity Loss: 0.0000, Avg Binary Var: 0.1635\n",
      "Iteration 2600/3000, Total Loss: 4.4338, Cost Loss: -0.0068, Constraint Loss: 0.0098, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1000\n",
      "Iteration 2700/3000, Total Loss: 2.1379, Cost Loss: -0.0763, Constraint Loss: 0.0202, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.0667\n",
      "Iteration 2800/3000, Total Loss: 2.1729, Cost Loss: -0.0645, Constraint Loss: 0.0113, Integrality Loss: 0.0001, Positivity Loss: 0.0004, Avg Binary Var: 0.1330\n",
      "Iteration 2900/3000, Total Loss: 3.9615, Cost Loss: -0.0236, Constraint Loss: 0.0111, Integrality Loss: 0.0180, Positivity Loss: 0.0001, Avg Binary Var: 0.1613\n",
      "Iteration 3000/3000, Total Loss: 6.0800, Cost Loss: -0.0213, Constraint Loss: 0.0060, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "\n",
      "Continuous Variables (first 30): [ 0.012  0.012  0.012  0.012  0.75   0.012  0.013  0.012  0.012  0.012\n",
      "  0.015  0.012  0.08   0.012  0.012  0.012  0.012 -0.006 -0.004 -0.004\n",
      " -0.006 -0.005 -0.006 -0.006 -0.005 -0.005 -0.005 -0.005 -0.005 -0.005]\n",
      "Binary/Integer Variables (remaining): [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.97  0.\n",
      " 1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.999\n",
      " 0.    0.    0.    0.    1.    0.   ]\n",
      "Optimized Cost: -0.0578446819214364\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-0.03099996  0.012       0.012       0.012       0.012      -0.25\n",
      "  0.012       0.013       0.012       0.012       0.012      -0.95500003\n",
      "  0.012      -0.92        0.012       0.012       0.012       0.012\n",
      " -0.006      -0.004      -0.004      -0.006      -0.005      -0.006\n",
      " -1.00500001 -0.005      -0.005      -0.005      -0.005      -1.005\n",
      " -0.005     ]\n",
      "Equality Violations (should be close to 0): [-0.053]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.     0.     0.783  0.     0.     0.     0.     0.\n",
      "  0.048  0.     0.113  0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.027  0.     0.     0.     0.     0.028  0.\n",
      " -0.    -0.    -0.    -0.     1.    -0.    -0.    -0.    -0.    -0.\n",
      "  1.    -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.     1.    -0.    -0.    -0.    -0.     1.    -0.   ]\n",
      "Projection Objective value: 0.008743286\n",
      "Starting run 24/25\n",
      "Iteration 1/3000, Total Loss: 123.6663, Cost Loss: 2.5589, Constraint Loss: 6.5693, Integrality Loss: 0.0550, Positivity Loss: 0.0070, Avg Binary Var: 0.0807\n",
      "Iteration 100/3000, Total Loss: 9.1475, Cost Loss: 0.0668, Constraint Loss: 0.0371, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1333\n",
      "Iteration 200/3000, Total Loss: 7.4253, Cost Loss: -0.0293, Constraint Loss: 0.0065, Integrality Loss: 0.0624, Positivity Loss: 0.0001, Avg Binary Var: 0.1504\n",
      "Iteration 300/3000, Total Loss: 6.9684, Cost Loss: -0.0241, Constraint Loss: 0.0099, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.0999\n",
      "Iteration 400/3000, Total Loss: 5.3551, Cost Loss: -0.0456, Constraint Loss: 0.0116, Integrality Loss: 0.0596, Positivity Loss: 0.0002, Avg Binary Var: 0.1141\n",
      "Iteration 500/3000, Total Loss: 3.0443, Cost Loss: -0.0498, Constraint Loss: 0.0005, Integrality Loss: 0.0002, Positivity Loss: 0.0002, Avg Binary Var: 0.1328\n",
      "Iteration 600/3000, Total Loss: 4.4648, Cost Loss: -0.0412, Constraint Loss: 0.0017, Integrality Loss: 0.0001, Positivity Loss: 0.0002, Avg Binary Var: 0.1671\n",
      "Iteration 700/3000, Total Loss: 3.9481, Cost Loss: -0.0441, Constraint Loss: 0.0020, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 800/3000, Total Loss: 3.2928, Cost Loss: -0.0282, Constraint Loss: 0.0044, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 900/3000, Total Loss: 5.8504, Cost Loss: -0.0388, Constraint Loss: 0.0023, Integrality Loss: 0.0083, Positivity Loss: 0.0002, Avg Binary Var: 0.1367\n",
      "Iteration 1000/3000, Total Loss: 5.0777, Cost Loss: -0.0424, Constraint Loss: 0.0025, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1100/3000, Total Loss: 4.0640, Cost Loss: -0.0455, Constraint Loss: 0.0013, Integrality Loss: 0.0004, Positivity Loss: 0.0002, Avg Binary Var: 0.1007\n",
      "Iteration 1200/3000, Total Loss: 3.7973, Cost Loss: -0.0534, Constraint Loss: 0.0066, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1667\n",
      "Iteration 1300/3000, Total Loss: 10.0679, Cost Loss: -0.0164, Constraint Loss: 0.0167, Integrality Loss: 0.0625, Positivity Loss: 0.0000, Avg Binary Var: 0.0834\n",
      "Iteration 1400/3000, Total Loss: 3.9338, Cost Loss: -0.0214, Constraint Loss: 0.0007, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 1500/3000, Total Loss: 3.5139, Cost Loss: -0.0454, Constraint Loss: 0.0715, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1667\n",
      "Iteration 1600/3000, Total Loss: 5.1825, Cost Loss: 0.0077, Constraint Loss: 0.0656, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1667\n",
      "Iteration 1700/3000, Total Loss: 18.4193, Cost Loss: -0.0165, Constraint Loss: 0.0266, Integrality Loss: 0.0013, Positivity Loss: 0.0000, Avg Binary Var: 0.1654\n",
      "Iteration 1800/3000, Total Loss: 10.8130, Cost Loss: -0.0485, Constraint Loss: 0.0078, Integrality Loss: 0.0557, Positivity Loss: 0.0003, Avg Binary Var: 0.1206\n",
      "Iteration 1900/3000, Total Loss: 10.6409, Cost Loss: -0.0599, Constraint Loss: 0.0035, Integrality Loss: 0.0185, Positivity Loss: 0.0003, Avg Binary Var: 0.1279\n",
      "Iteration 2000/3000, Total Loss: 15.1320, Cost Loss: -0.0254, Constraint Loss: 0.0035, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1666\n",
      "Iteration 2100/3000, Total Loss: 13.1636, Cost Loss: -0.0244, Constraint Loss: 0.0062, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 2200/3000, Total Loss: 10.0080, Cost Loss: -0.0074, Constraint Loss: 0.0192, Integrality Loss: 0.0004, Positivity Loss: 0.0000, Avg Binary Var: 0.1673\n",
      "Iteration 2300/3000, Total Loss: 8.5843, Cost Loss: 0.0014, Constraint Loss: 0.0247, Integrality Loss: 0.0145, Positivity Loss: 0.0000, Avg Binary Var: 0.0714\n",
      "Iteration 2400/3000, Total Loss: 7.7428, Cost Loss: 0.0337, Constraint Loss: 0.0112, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1332\n",
      "Iteration 2500/3000, Total Loss: 6.9157, Cost Loss: 0.0266, Constraint Loss: 0.0857, Integrality Loss: 0.0481, Positivity Loss: 0.0000, Avg Binary Var: 0.0775\n",
      "Iteration 2600/3000, Total Loss: 9.0722, Cost Loss: 0.0477, Constraint Loss: 0.0256, Integrality Loss: 0.0529, Positivity Loss: 0.0000, Avg Binary Var: 0.1547\n",
      "Iteration 2700/3000, Total Loss: 16.3288, Cost Loss: -0.0664, Constraint Loss: 0.0394, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1666\n",
      "Iteration 2800/3000, Total Loss: 9.1160, Cost Loss: -0.0808, Constraint Loss: 0.0106, Integrality Loss: 0.0556, Positivity Loss: 0.0007, Avg Binary Var: 0.0682\n",
      "Iteration 2900/3000, Total Loss: 12.7874, Cost Loss: -0.0677, Constraint Loss: 0.0162, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1000\n",
      "Iteration 3000/3000, Total Loss: 9.3669, Cost Loss: -0.1077, Constraint Loss: 0.0201, Integrality Loss: 0.0019, Positivity Loss: 0.0012, Avg Binary Var: 0.1015\n",
      "\n",
      "Continuous Variables (first 30): [ 0.011  0.011  0.011  0.189  0.011  0.011  0.011  0.011  0.011  0.011\n",
      "  0.469  0.011  0.297  0.011  0.011  0.011  0.011 -0.003 -0.002 -0.003\n",
      " -0.003 -0.003 -0.003 -0.003 -0.003 -0.002 -0.003 -0.003 -0.003 -0.003]\n",
      "Binary/Integer Variables (remaining): [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Optimized Cost: -0.034456956833156756\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-2.          0.011       0.011       0.011      -0.811       0.011\n",
      "  0.011       0.011       0.011       0.011       0.011      -0.53099999\n",
      "  0.011      -0.70300001  0.011       0.011       0.011       0.011\n",
      " -0.003      -0.002      -0.003      -0.003      -0.003      -0.003\n",
      " -0.003      -0.003      -0.002      -0.003      -0.003      -0.003\n",
      " -0.003     ]\n",
      "Equality Violations (should be close to 0): [0.072]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.     0.     0.204  0.     0.     0.     0.     0.     0.\n",
      "  0.484  0.     0.312  0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.    -0.    -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      "  1.    -0.     1.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.002475977\n",
      "Starting run 25/25\n",
      "Iteration 1/3000, Total Loss: 163.8452, Cost Loss: 2.9795, Constraint Loss: 10.6027, Integrality Loss: 0.0763, Positivity Loss: 0.0000, Avg Binary Var: 0.0207\n",
      "Iteration 100/3000, Total Loss: 10.0834, Cost Loss: -0.0290, Constraint Loss: 0.0088, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1000\n",
      "Iteration 200/3000, Total Loss: 6.2116, Cost Loss: -0.0449, Constraint Loss: 0.0011, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 300/3000, Total Loss: 5.6526, Cost Loss: -0.0469, Constraint Loss: 0.0008, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1666\n",
      "Iteration 400/3000, Total Loss: 6.4802, Cost Loss: -0.0420, Constraint Loss: 0.0018, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1333\n",
      "Iteration 500/3000, Total Loss: 4.0602, Cost Loss: -0.0438, Constraint Loss: 0.0013, Integrality Loss: 0.0003, Positivity Loss: 0.0002, Avg Binary Var: 0.1328\n",
      "Iteration 600/3000, Total Loss: 2.4845, Cost Loss: -0.0441, Constraint Loss: 0.0018, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 700/3000, Total Loss: 9.6825, Cost Loss: -0.0345, Constraint Loss: 0.0202, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1335\n",
      "Iteration 800/3000, Total Loss: 6.1323, Cost Loss: -0.0189, Constraint Loss: 0.0026, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1002\n",
      "Iteration 900/3000, Total Loss: 5.7389, Cost Loss: -0.0443, Constraint Loss: 0.0043, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1000/3000, Total Loss: 5.5482, Cost Loss: -0.0457, Constraint Loss: 0.0010, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1667\n",
      "Iteration 1100/3000, Total Loss: 10.1250, Cost Loss: -0.0498, Constraint Loss: 0.1183, Integrality Loss: 0.0510, Positivity Loss: 0.0002, Avg Binary Var: 0.1781\n",
      "Iteration 1200/3000, Total Loss: 10.7827, Cost Loss: -0.0439, Constraint Loss: 0.0007, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 1300/3000, Total Loss: 7.4596, Cost Loss: -0.0647, Constraint Loss: 0.0065, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1332\n",
      "Iteration 1400/3000, Total Loss: 7.3807, Cost Loss: -0.0656, Constraint Loss: 0.0460, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1333\n",
      "Iteration 1500/3000, Total Loss: 9.7703, Cost Loss: -0.0513, Constraint Loss: 0.0009, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1333\n",
      "Iteration 1600/3000, Total Loss: 9.6397, Cost Loss: -0.0076, Constraint Loss: 0.0200, Integrality Loss: 0.0000, Positivity Loss: 0.0000, Avg Binary Var: 0.1665\n",
      "Iteration 1700/3000, Total Loss: 11.8684, Cost Loss: -0.0723, Constraint Loss: 0.0307, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1333\n",
      "Iteration 1800/3000, Total Loss: 6.1817, Cost Loss: -0.0557, Constraint Loss: 0.0449, Integrality Loss: 0.0000, Positivity Loss: 0.0004, Avg Binary Var: 0.1000\n",
      "Iteration 1900/3000, Total Loss: 3.5680, Cost Loss: -0.0645, Constraint Loss: 0.0100, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1000\n",
      "Iteration 2000/3000, Total Loss: 7.8872, Cost Loss: -0.0499, Constraint Loss: 0.0030, Integrality Loss: 0.0000, Positivity Loss: 0.0002, Avg Binary Var: 0.1000\n",
      "Iteration 2100/3000, Total Loss: 8.2176, Cost Loss: -0.0369, Constraint Loss: 0.0005, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.1667\n",
      "Iteration 2200/3000, Total Loss: 12.4659, Cost Loss: -0.0671, Constraint Loss: 0.0089, Integrality Loss: 0.0000, Positivity Loss: 0.0005, Avg Binary Var: 0.1333\n",
      "Iteration 2300/3000, Total Loss: 7.1106, Cost Loss: -0.0795, Constraint Loss: 0.0084, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1333\n",
      "Iteration 2400/3000, Total Loss: 6.2738, Cost Loss: -0.0520, Constraint Loss: 0.0077, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1666\n",
      "Iteration 2500/3000, Total Loss: 11.1131, Cost Loss: -0.0778, Constraint Loss: 0.0076, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1333\n",
      "Iteration 2600/3000, Total Loss: 6.5276, Cost Loss: -0.0534, Constraint Loss: 0.0033, Integrality Loss: 0.0000, Positivity Loss: 0.0003, Avg Binary Var: 0.1333\n",
      "Iteration 2700/3000, Total Loss: 5.4912, Cost Loss: -0.0665, Constraint Loss: 0.0072, Integrality Loss: 0.0466, Positivity Loss: 0.0005, Avg Binary Var: 0.1106\n",
      "Iteration 2800/3000, Total Loss: 3.5279, Cost Loss: -0.0337, Constraint Loss: 0.0072, Integrality Loss: 0.0000, Positivity Loss: 0.0001, Avg Binary Var: 0.0667\n",
      "Iteration 2900/3000, Total Loss: 4.3544, Cost Loss: -0.0791, Constraint Loss: 0.0440, Integrality Loss: 0.0000, Positivity Loss: 0.0008, Avg Binary Var: 0.1666\n",
      "Iteration 3000/3000, Total Loss: 13.6571, Cost Loss: -0.0755, Constraint Loss: 0.0244, Integrality Loss: 0.0000, Positivity Loss: 0.0006, Avg Binary Var: 0.1333\n",
      "\n",
      "Continuous Variables (first 30): [ 0.009  0.264  0.009  0.009  0.294  0.009  0.398  0.009  0.009  0.009\n",
      "  0.009  0.009  0.009  0.03   0.009  0.009  0.009 -0.     0.003  0.003\n",
      " -0.    -0.    -0.    -0.     0.     0.001 -0.    -0.    -0.    -0.   ]\n",
      "Binary/Integer Variables (remaining): [0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Optimized Cost: 0.007815111562159749\n",
      "Feasible: False\n",
      "Inequality Violations (should be <= 0): [-1.     0.009 -0.736  0.009  0.009 -0.706  0.009 -0.602  0.009  0.009\n",
      "  0.009  0.009  0.009  0.009  0.03   0.009  0.009  0.009 -1.     0.003\n",
      "  0.003  0.     0.     0.     0.     0.     0.001  0.     0.     0.\n",
      "  0.   ]\n",
      "Equality Violations (should be close to 0): [0.10999999]\n",
      "Set parameter LogToConsole to value 0\n",
      "Projected solution: [ 0.     0.275  0.     0.     0.305  0.     0.409  0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.011  0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -0.     1.    -0.    -0.     1.    -0.     1.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.     1.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.   ]\n",
      "Projection Objective value: 0.0024557114\n",
      "\n",
      "All runs complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume these are defined:\n",
    "# model, Q, A, E, b_vector, d_vector, variable_types_tensor\n",
    "# mean_x_var_tensor, mean_x_cons_constraints_tensor\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 10.0\n",
    "beta = 0.1\n",
    "gamma = 0.1\n",
    "zeta = 10.0  # integrality penalty weight (reduced from before)\n",
    "pos_weight = 100.0\n",
    "num_iterations = 3000\n",
    "\n",
    "Q_tensor = torch.tensor(Q, dtype=torch.float32, device=device)\n",
    "A_tensor = torch.tensor(A, dtype=torch.float32, device=device)\n",
    "b_tensor = torch.tensor(b_vector, dtype=torch.float32, device=device)\n",
    "E_tensor = torch.tensor(E, dtype=torch.float32, device=device)\n",
    "d_tensor = torch.tensor(d_vector, dtype=torch.float32, device=device)\n",
    "\n",
    "binary_mask = (variable_types_tensor == 1).to(device)\n",
    "continuous_mask = ~binary_mask\n",
    "\n",
    "# Gumbel-Softmax temperature\n",
    "temp = 0.1  # Try reducing this over time if needed\n",
    "\n",
    "def sample_gumbel_like(x):\n",
    "    # Sample gumbel noise\n",
    "    # Ensure x has no zeros to avoid NaN in logs\n",
    "    u = torch.rand_like(x)\n",
    "    return -torch.log(-torch.log(u + 1e-10) + 1e-10)\n",
    "\n",
    "def gumbel_sigmoid(p, temp):\n",
    "    # Convert probability p to logits\n",
    "    # logits = log(p/(1-p))\n",
    "    logits = torch.log(p + 1e-10) - torch.log(1 - p + 1e-10)\n",
    "    g = sample_gumbel_like(p)\n",
    "    return torch.sigmoid((logits + g) / temp)\n",
    "\n",
    "def gradient_optimization_run(initial_x_var, initial_x_cons_constraints):\n",
    "    x_var = nn.Parameter(initial_x_var.detach().clone().to(device))\n",
    "    x_cons_constraints = nn.Parameter(initial_x_cons_constraints.detach().clone().to(device))\n",
    "    \n",
    "    optimizer = optim.Adam([x_var, x_cons_constraints], lr=0.01)\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Decode predictions (continuous approximations)\n",
    "        x_hat_raw = model.decoder_x(x_var).squeeze()\n",
    "        \n",
    "        # Apply Gumbel-Softmax to binary variables\n",
    "        x_bin_prob = torch.clamp(x_hat_raw[binary_mask], 1e-5, 1-1e-5)\n",
    "        x_bin_gumbel = gumbel_sigmoid(x_bin_prob, temp)\n",
    "\n",
    "        # For continuous variables, just use x_hat_raw directly\n",
    "        x_cont = x_hat_raw[continuous_mask]\n",
    "\n",
    "        # Reconstruct x_hat with gumbelized binary variables\n",
    "        x_hat = torch.zeros_like(x_hat_raw)\n",
    "        x_hat[binary_mask] = x_bin_gumbel\n",
    "        x_hat[continuous_mask] = x_cont\n",
    "\n",
    "        # Encourage integrality: we can still use (x*(1-x))^2 to push towards 0 or 1\n",
    "        integrality_loss = ((x_bin_gumbel * (1 - x_bin_gumbel))**2).sum()\n",
    "\n",
    "        # Positivity Loss (for binary variables): discourage negatives (shouldn't be needed after sigmoid)\n",
    "        positivity_loss = torch.relu(-x_hat).pow(2).sum()\n",
    "\n",
    "        # Cost loss\n",
    "        cost_loss = 0.5 * x_hat @ Q_tensor @ x_hat\n",
    "\n",
    "        # Constraint violations\n",
    "        inequality_violations = A_tensor @ x_hat - b_tensor\n",
    "        inequality_constraint_loss = torch.relu(inequality_violations).pow(2).sum()\n",
    "\n",
    "        equality_violations = E_tensor @ x_hat - d_tensor\n",
    "        equality_constraint_loss = equality_violations.pow(2).sum()\n",
    "\n",
    "        constraint_loss = inequality_constraint_loss + 2 * equality_constraint_loss\n",
    "\n",
    "        penalty_var = torch.norm(x_var - mean_x_var_tensor.to(device), p=2)**2\n",
    "        penalty_cons = torch.norm(x_cons_constraints - mean_x_cons_constraints_tensor.to(device), p=2)**2\n",
    "\n",
    "        total_loss = (cost_loss \n",
    "                      + alpha * constraint_loss \n",
    "                      + beta * penalty_var \n",
    "                      + gamma * penalty_cons\n",
    "                      + zeta * integrality_loss\n",
    "                      + pos_weight * positivity_loss)\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if ((iteration + 1) % 100 == 0) or iteration == 0:\n",
    "            print(f\"Iteration {iteration + 1}/{num_iterations}, \"\n",
    "                  f\"Total Loss: {total_loss.item():.4f}, \"\n",
    "                  f\"Cost Loss: {cost_loss.item():.4f}, \"\n",
    "                  f\"Constraint Loss: {constraint_loss.item():.4f}, \"\n",
    "                  f\"Integrality Loss: {integrality_loss.item():.4f}, \"\n",
    "                  f\"Positivity Loss: {positivity_loss.item():.4f}, \"\n",
    "                  f\"Avg Binary Var: {x_bin_gumbel.mean().item():.4f}\")\n",
    "\n",
    "    # Return the optimized x_hat (sampling again at the end)\n",
    "    with torch.no_grad():\n",
    "        # Re-sample once more or just decode final x_hat\n",
    "        x_hat_raw = model.decoder_x(x_var).squeeze()\n",
    "        x_bin_prob = torch.clamp(x_hat_raw[binary_mask], 1e-5, 1-1e-5)\n",
    "        x_bin_gumbel = gumbel_sigmoid(x_bin_prob, temp)\n",
    "        x_cont = x_hat_raw[continuous_mask]\n",
    "\n",
    "        x_final = torch.zeros_like(x_hat_raw)\n",
    "        x_final[binary_mask] = x_bin_gumbel\n",
    "        x_final[continuous_mask] = x_cont\n",
    "        return x_final.cpu().numpy()\n",
    "\n",
    "def solve_projection(A, b, E, d, x_hat, variable_types):\n",
    "    \"\"\"\n",
    "    Solves the projection problem:\n",
    "    min_x || x - x_hat ||_2^2\n",
    "    s.t. A x <= b\n",
    "         E x = d\n",
    "         x_j in R or Z depending on variable_types\n",
    "    \"\"\"\n",
    "    n = x_hat.shape[0]\n",
    "    m_ineq = A.shape[0] if A is not None else 0\n",
    "    m_eq = E.shape[0] if E is not None else 0\n",
    "\n",
    "    model = gp.Model(\"projection\")\n",
    "    model.Params.LogToConsole = 0  # Turn off logging if desired\n",
    "\n",
    "    x_vars = []\n",
    "    for j in range(n):\n",
    "        if variable_types[j] == 1:\n",
    "            vtype = GRB.BINARY\n",
    "        else:\n",
    "            vtype = GRB.CONTINUOUS\n",
    "        x_vars.append(model.addVar(vtype=vtype, name=f\"x_{j}\"))\n",
    "    model.update()\n",
    "\n",
    "    # Add inequality constraints: A x <= b\n",
    "    if m_ineq > 0:\n",
    "        for i in range(m_ineq):\n",
    "            expr = gp.quicksum(A[i, j]*x_vars[j] for j in range(n))\n",
    "            model.addConstr(expr <= b[i], name=f\"ineq_{i}\")\n",
    "\n",
    "    # Add equality constraints: E x = d\n",
    "    if m_eq > 0:\n",
    "        for i in range(m_eq):\n",
    "            expr = gp.quicksum(E[i, j]*x_vars[j] for j in range(n))\n",
    "            model.addConstr(expr == d[i], name=f\"eq_{i}\")\n",
    "\n",
    "    obj = gp.QuadExpr()\n",
    "    for j in range(n):\n",
    "        obj.add(x_vars[j]*x_vars[j], 1.0)\n",
    "        obj.add(-2 * x_hat[j] * x_vars[j], 1.0)\n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "    model.optimize()\n",
    "\n",
    "    if model.status != GRB.OPTIMAL:\n",
    "        print(\"No optimal solution found. Status:\", model.status)\n",
    "        return None, None\n",
    "\n",
    "    x_opt = np.array([var.x for var in x_vars])\n",
    "    obj_value = model.objVal + np.sum(x_hat**2)\n",
    "    return x_opt, obj_value\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Running the optimization from 10 different starting values\n",
    "#########################################\n",
    "\n",
    "num_starts = 25\n",
    "solutions = []\n",
    "projection_solutions = []\n",
    "\n",
    "for i in range(num_starts):\n",
    "    print(f\"Starting run {i+1}/{num_starts}\")\n",
    "    perturbed_x_var = mean_x_var_tensor + 0.1 * torch.randn_like(mean_x_var_tensor)\n",
    "    perturbed_x_cons = mean_x_cons_constraints_tensor + 0.1 * torch.randn_like(mean_x_cons_constraints_tensor)\n",
    "\n",
    "    x_optimized = gradient_optimization_run(perturbed_x_var, perturbed_x_cons)\n",
    "    optimized_solution = np.round(x_optimized, 3)\n",
    "\n",
    "    # Evaluate actual cost and feasibility\n",
    "    actual_cost = 0.5 * optimized_solution.T @ Q @ optimized_solution\n",
    "    inequality_violations = A @ optimized_solution - b_vector\n",
    "    equality_violations = E @ optimized_solution - d_vector\n",
    "    is_feasible = np.all(inequality_violations <= 1e-3) and np.allclose(equality_violations, 0, atol=1e-4)\n",
    "\n",
    "    print(\"\\nContinuous Variables (first 30):\", optimized_solution[:30])\n",
    "    print(\"Binary/Integer Variables (remaining):\", optimized_solution[30:])\n",
    "    print(f\"Optimized Cost: {actual_cost}\")\n",
    "    print(f\"Feasible: {is_feasible}\")\n",
    "    print(\"Inequality Violations (should be <= 0):\", inequality_violations)\n",
    "    print(\"Equality Violations (should be close to 0):\", equality_violations)\n",
    "\n",
    "    # Solve the projection problem\n",
    "    x_opt_proj, obj_val_proj = solve_projection(A, b_vector, E, d_vector, optimized_solution, variable_types_tensor)\n",
    "    print(\"Projected solution:\", np.round(x_opt_proj, 3))\n",
    "    print(\"Projection Objective value:\", obj_val_proj)\n",
    "\n",
    "    solutions.append(optimized_solution)\n",
    "    projection_solutions.append(x_opt_proj)\n",
    "\n",
    "print(\"\\nAll runs complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1338397270915549\n",
      "0.01867235740487037\n",
      "0.004543973569268459\n",
      "0.08876149329617194\n",
      "0.004570547079828793\n",
      "0.004078537850301397\n",
      "0.2152577033409095\n",
      "0.004521638027038667\n",
      "0.004504850025162002\n",
      "0.1386145436534758\n",
      "0.02637033895253179\n",
      "0.3003346524856814\n",
      "0.004536810547857764\n",
      "0.03450343912297493\n",
      "0.016041523061295145\n",
      "0.005316993280464461\n",
      "0.12708486939478178\n",
      "0.045503665469985105\n",
      "0.09582713491112015\n",
      "0.03629149544850988\n",
      "0.10149474911531496\n",
      "0.017201524700387435\n",
      "0.11000330167012792\n",
      "0.0041048588057269395\n",
      "0.026399163018038053\n"
     ]
    }
   ],
   "source": [
    "projected = []\n",
    "\n",
    "for i in range(len(projection_solutions)):\n",
    "\n",
    "    print(projection_solutions[i].T @ Q @ projection_solutions[i])\n",
    "\n",
    "    projected.append(projection_solutions[i].T @ Q @ projection_solutions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.06273519565293519)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(projected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5186636193049586\n",
      "0.7157708975243896\n",
      "0.49213344929882136\n",
      "0.8753039068485481\n",
      "0.9477576714983407\n",
      "0.012211350757721309\n",
      "0.5408177774662047\n",
      "0.00758093706489434\n",
      "0.9596022920536481\n",
      "0.7867790444212563\n",
      "0.6367734705107952\n",
      "0.9214436379944309\n",
      "0.006075243184777736\n",
      "0.007225632311167893\n",
      "0.37263950922923417\n",
      "0.8432042069898658\n",
      "0.9627674083772737\n",
      "0.005573218720424675\n",
      "0.954180692607723\n",
      "0.898522221157742\n",
      "0.9524992113246662\n",
      "0.004773727267767728\n",
      "0.9482085542427131\n",
      "0.8158846538865803\n",
      "0.005427895819516281\n",
      "0.9526839092728414\n",
      "0.9417715410087029\n",
      "0.004490512969705882\n",
      "0.004597113256493507\n",
      "0.0058631191694359245\n"
     ]
    }
   ],
   "source": [
    "random_sols = []\n",
    "\n",
    "for i in range(30):\n",
    "\n",
    "    print(feasible_solutions[i].T @ Q @ feasible_solutions[i])\n",
    "\n",
    "    random_sols.append(feasible_solutions[i].T @ Q @ feasible_solutions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5367075475180214)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(random_sols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05646500053958228"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.003875233981588879 - 0.0036681139267364556)/0.0036681139267364556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0036681139267364556)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_solution = np.array(optimal_solution)\n",
    "optimal_solution.T @ Q @ optimal_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.49055482,  0.        ,  0.        ,\n",
       "        0.09207045,  0.        ,  0.        ,  0.06558349,  0.20634722,\n",
       "        0.        ,  0.14544402,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  1.        , -0.        , -0.        ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "       -0.        ,  1.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.20040007, 0.1993999 , 0.        ,\n",
       "       0.1993999 , 0.        , 0.        , 0.20040007, 0.        ,\n",
       "       0.        , 0.20040007, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection_solutions[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
